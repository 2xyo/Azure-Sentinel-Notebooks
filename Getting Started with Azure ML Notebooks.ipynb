{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Azure ML Notebooks and Azure Sentinel\n",
    "**Notebook Version:** 1.0<br>\n",
    " **Python Version:** Python 3.6 (including Python 3.6 - AzureML)<br>\n",
    " **Required Packages**: <br>\n",
    " **Platforms Supported**:\n",
    " - Azure Notebooks Free Compute\n",
    " - Azure Notebooks DSVM\n",
    " - OS Independent\n",
    "\n",
    "**Data Sources Required**:\n",
    " - Log Analytics - SiginLogs (Optional)\n",
    " - VirusTotal\n",
    " - MaxMind\n",
    " \n",
    " \n",
    "This notebook takes you through the basics needed to get started with Azure Notebooks and Azure Sentinel, and how to perform the basic actions of data acquisition, data enrichment, data analysis, and data visualization. These actions are the building blocks of threat hunting with notebooks and are useful to understand before running more complex notebooks. This notebook only lightly covers each topic but includes 'learn more' sections to provide you with the resource to deep dive into each of these topics. \n",
    "\n",
    "This notebook assumes that you are running this in an Azure Notebooks environment, however it will work in other Jupyter environments.\n",
    "\n",
    "**Note:**\n",
    "This notebooks uses SigninLogs from your Azure Sentinel Workspace. If you are not yet collecting SigninLogs configure this connector in the Azure Sentinel portal before running this notebook.\n",
    "This notebook also uses the VirusTotal API for data enrichment, for this you will require an API key which can be obtained by signing up for a free [VirusTotal community account](\"https://www.virustotal.com/gui/join-us\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## What is a Jupyter notebook?\n",
    "You are currently reading a Jupyter notebook. [Jupyter](http://jupyter.org/) is an interactive development and data manipulation environment presented in a browser. Using Jupyter you can create documents, called Notebooks. These documents are made up of cells that contain interactive code, alongside that code's output, and other items such as text and images (what you are looking at now is a cell of Markdown text).\n",
    "\n",
    "The name, Jupyter, comes from the core supported programming languages that it supports: Julia, Python, and R. Whilst you can use any of these languages we are going to use Python in this notebook, in addition the notebooks that come with Azure Sentinel are all written in Python. Whilst there are pros, and cons to each language Python is a well-established language that has a large number of materials and libraries well suited for data analysis and security investigation, making it ideal for our needs.\n",
    "\n",
    "### Learn more:\n",
    " - The [Infosec Jupyter Book](\"https://infosecjupyterbook.com/introduction.html\") has more details on the technical working of Jupyter.\n",
    " - [The Jupyter Project documentation](\"https://jupyter.org/documentation\")\n",
    "\n",
    "---\n",
    "## How to use a Jupyter notebook?\n",
    "To use a Jupyter notebook you need a Jupyter server that will render the notebook and execute the code within it. This can take the form of a local [Jupyter installation](https://pypi.org/project/jupyter/), or a remotely hosted version such as [Azure Notebooks](https://notebooks.azure.com/). If you are reading this it is highly likely that you already have a Jupyter server that this notebook is using.\n",
    "You can learn more about installing and running your own Jupyter server [here](https://realpython.com/jupyter-notebook-introduction/).\n",
    "\n",
    "### Using Azure Notebooks\n",
    "If you accessed this notebook from Azure Sentinel,  you are probably using Azure Notebooks to run this notebook. Azure Notebooks runs in the same way that a local Jupyter server with, except with the additional feature of integrated project management and file storage. When you open a notebook in Azure Notebooks the user interface is nearly identical to a standard Jupyter notebook experience.\n",
    "\n",
    "Before you can start running code in a notebook you need to make sure that it is connected to a Jupyter server and you have the correct type of kernel configured. For this notebook we are going to be using Python 3.6, hopefully Azure Notebooks has already loaded this kernel for you - you can check this by looking at the top left corner of the screen where you should see the currently connected kernel. \n",
    "\n",
    "![KernelIssue](https://github.com/Azure/Azure-Sentinel-Notebooks/raw/master/images/nb_img1.png)\n",
    "\n",
    "If this does not read Python 3.6 you can select the correct kernel by selecting Kernel > Change kernel from the top menu and clicking Python 3.6.\n",
    "\n",
    "> **Note**: the notebook works with Python 3.6, 3.7 or later. If you are using this notebook in Azure ML or another Jupyter environment you can choose any kernel that supports Python 3.6 or later\n",
    "\n",
    "![KernelPicker](https://github.com/Azure/Azure-Sentinel-Notebooks/raw/master/images/nb_img2.png)\n",
    "\n",
    "Once you have done this you should be ready to move onto a code cell.\n",
    "> **Tip**: You can identify which cells are code by selecting them and looking at the drop down box at the center of the top menu. It will either read 'Code' (for interactive code cells), 'Markdown' (for Markdown text cells like this one), or RawNBConvert (these are just raw data and not interpreted by Jupyter - they can be used by tools that process notebook files, such as *nbconvert* to render the data into HTML or LaTeX). \n",
    "\n",
    "If you click on the cell below you should see this box change to 'Code'.\n",
    "\n",
    "### Learn More:\n",
    "More details on Azure Notebooks can be found in the [Azure Notebooks documentation](https://docs.microsoft.com/en-us/azure/notebooks/) and the [Azure Sentinel documentation](https://docs.microsoft.com/en-us/azure/sentinel/notebooks).\n",
    "\n",
    "---\n",
    "## Running code\n",
    "Once you have selected a code cell you can run it by clicking the run button at the menu bar at the top, or by pressing Ctrl+Enter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our first code cell, it contains basic Python code.\n",
    "# You can run a code cell by selecting it and clicking the Run button in the top menu, or by pressing Shift + Enter.\n",
    "# Once you run a code cell any output from that code will be displayed directly below it.\n",
    "print(\"Congratulations you just ran this code cell\")\n",
    "y = 2+2\n",
    "print(\"2 + 2 =\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables set within a code cell persist between cells meaning you can chain cells together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn More : \n",
    " - The [Infosec Jupyter Book](\"https://infosecjupyterbook.com/\") provides an infosec specific intro to Python.\n",
    " - [Real Pyhton](\"https://realpython.com/\") is a comprehensive set of Python learnings and tutorials.\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you understand the basics we can move onto more complex code.\n",
    "\n",
    "---\n",
    "## Setting up the environment\n",
    "Code cells behave in the same way your code would in other environments, so you need to remember about common coding practices such as variable initialization and library imports. \n",
    "Before we execute more complex code we need to make sure the required packages are installed and libraries imported. At the top of many of the Azure Sentinel notebooks you will see large cells that will check kernel versions and then install and import all the libraries we are going to be using in the notebook, make sure you run this before running other cells in the notebook.\n",
    "If you are running notebooks locally or via dedicated compute in Azure Notebooks library installs will persist but this is not the case with Azure Notebooks free tier, so you will need to install each time you run. Even if running in a static environment imports are required for each run so make sure you run this cell regardless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Starting Notebook setup...</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Checking Python kernel version..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Python kernel version 3.8.3 OK"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Checking msticpy version..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <h3><font color='orange'>The package '<b>msticpy</b>' is not \n",
       "    installed or has an incorrect version</font></h3>\n",
       "    <h4>Please install this now</h4>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Install? (y/n)y\n",
      "Collecting msticpy\n",
      "  Using cached msticpy-0.5.1-py3-none-any.whl (337 kB)\n",
      "Collecting pandas>=0.25.0\n",
      "  Downloading pandas-1.0.5-cp38-cp38-win_amd64.whl (8.9 MB)\n",
      "Collecting Kqlmagic>=0.1.106\n",
      "  Using cached Kqlmagic-0.1.113.post1-py3-none-any.whl (197 kB)\n",
      "Collecting pytz>=2019.2\n",
      "  Using cached pytz-2020.1-py2.py3-none-any.whl (510 kB)\n",
      "Collecting matplotlib>=3.0.2\n",
      "  Downloading matplotlib-3.2.2-cp38-cp38-win_amd64.whl (9.2 MB)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=40.6.3 in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from msticpy) (47.3.1.post20200622)\n",
      "Collecting requests>=2.21.1\n",
      "  Using cached requests-2.24.0-py2.py3-none-any.whl (61 kB)\n",
      "Collecting msrest>=0.6.0\n",
      "  Using cached msrest-0.6.16-py2.py3-none-any.whl (84 kB)\n",
      "Collecting tldextract>=2.2.2\n",
      "  Using cached tldextract-2.2.2-py2.py3-none-any.whl (48 kB)\n",
      "Collecting deprecated>=1.2.4\n",
      "  Using cached Deprecated-1.2.10-py2.py3-none-any.whl (8.7 kB)\n",
      "Requirement already satisfied, skipping upgrade: ipython>=7.2.0 in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from msticpy) (7.15.0)\n",
      "Collecting azure-cli-core==2.5.0\n",
      "  Using cached azure_cli_core-2.5.0-py3-none-any.whl (140 kB)\n",
      "Collecting urllib3>=1.24.1\n",
      "  Using cached urllib3-1.25.9-py2.py3-none-any.whl (126 kB)\n",
      "Collecting azure-mgmt-subscription>=0.2.0\n",
      "  Using cached azure_mgmt_subscription-0.6.0-py2.py3-none-any.whl (25 kB)\n",
      "Collecting geoip2>=2.9.0\n",
      "  Using cached geoip2-3.0.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting folium>=0.9.0\n",
      "  Using cached folium-0.11.0-py2.py3-none-any.whl (93 kB)\n",
      "Collecting azure-mgmt-compute>=4.6.2\n",
      "  Using cached azure_mgmt_compute-12.1.0-py2.py3-none-any.whl (1.6 MB)\n",
      "Collecting numpy>=1.15.4\n",
      "  Downloading numpy-1.19.0-cp38-cp38-win_amd64.whl (13.0 MB)\n",
      "Collecting azure-mgmt-resource>=2.2.0\n",
      "  Using cached azure_mgmt_resource-10.0.0-py2.py3-none-any.whl (809 kB)\n",
      "Collecting azure-keyvault-secrets>=4.0.0\n",
      "  Using cached azure_keyvault_secrets-4.1.0-py2.py3-none-any.whl (157 kB)\n",
      "Collecting pyyaml>=3.13\n",
      "  Downloading PyYAML-5.3.1-cp38-cp38-win_amd64.whl (219 kB)\n",
      "Collecting azure-mgmt-network>=2.7.0\n",
      "  Using cached azure_mgmt_network-10.2.0-py2.py3-none-any.whl (8.6 MB)\n",
      "Collecting tqdm>=4.36.1\n",
      "  Using cached tqdm-4.46.1-py2.py3-none-any.whl (63 kB)\n",
      "Collecting cryptography>=2.8\n",
      "  Downloading cryptography-2.9.2-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "Collecting seaborn>=0.9.0\n",
      "  Using cached seaborn-0.10.1-py3-none-any.whl (215 kB)\n",
      "Collecting bokeh>=1.4.0\n",
      "  Using cached bokeh-2.1.1.tar.gz (19.3 MB)\n",
      "Collecting scikit-learn>=0.20.2\n",
      "  Downloading scikit_learn-0.23.1-cp38-cp38-win_amd64.whl (6.8 MB)\n",
      "Collecting typing>=3.6.6\n",
      "  Using cached typing-3.7.4.1-py3-none-any.whl (25 kB)\n",
      "Collecting azure-mgmt-monitor>=0.5.2\n",
      "  Using cached azure_mgmt_monitor-0.10.0-py2.py3-none-any.whl (348 kB)\n",
      "Collecting azure-mgmt-keyvault>=2.0.0\n",
      "  Using cached azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\n",
      "Collecting ipwhois>=1.1.0\n",
      "  Using cached ipwhois-1.1.0-py2.py3-none-any.whl (74 kB)\n",
      "Collecting msal~=1.0.0\n",
      "  Using cached msal-1.0.0-py2.py3-none-any.whl (43 kB)\n",
      "Collecting azure-common>=1.1.18\n",
      "  Using cached azure_common-1.1.25-py2.py3-none-any.whl (12 kB)\n",
      "Collecting adal>=1.2.2\n",
      "  Using cached adal-1.2.4-py2.py3-none-any.whl (55 kB)\n",
      "Collecting dnspython>=1.16.0\n",
      "  Using cached dnspython-1.16.0-py2.py3-none-any.whl (188 kB)\n",
      "Collecting keyring>=18.0.0\n",
      "  Using cached keyring-21.2.1-py3-none-any.whl (31 kB)\n",
      "Collecting msrestazure>=0.6.0\n",
      "  Using cached msrestazure-0.6.3-py2.py3-none-any.whl (40 kB)\n",
      "Collecting networkx>=2.2\n",
      "  Using cached networkx-2.4-py3-none-any.whl (1.6 MB)\n",
      "Requirement already satisfied, skipping upgrade: ipywidgets>=7.4.2 in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from msticpy) (7.5.1)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=18.2.0 in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from msticpy) (19.3.0)\n",
      "Collecting azure-core>=1.2.2\n",
      "  Using cached azure_core-1.6.0-py2.py3-none-any.whl (120 kB)\n",
      "Collecting azure-identity>=1.3.0\n",
      "  Using cached azure_identity-1.3.1-py2.py3-none-any.whl (61 kB)\n",
      "Collecting beautifulsoup4>=4.8.0\n",
      "  Using cached beautifulsoup4-4.9.1-py3-none-any.whl (115 kB)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from pandas>=0.25.0->msticpy) (2.8.1)\n",
      "Collecting plotly>=3.10.0\n",
      "  Downloading plotly-4.8.1-py2.py3-none-any.whl (11.5 MB)\n",
      "Requirement already satisfied, skipping upgrade: traitlets>=4.3.2 in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from Kqlmagic>=0.1.106->msticpy) (4.3.3)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.11.0 in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from Kqlmagic>=0.1.106->msticpy) (1.15.0)\n",
      "Collecting Markdown>=3.0.1\n",
      "  Downloading Markdown-3.2.2-py3-none-any.whl (88 kB)\n",
      "Collecting lxml>=4.2.5\n",
      "  Downloading lxml-4.5.1-cp38-cp38-win_amd64.whl (3.5 MB)\n",
      "Collecting pyperclip>=1.7.0\n",
      "  Using cached pyperclip-1.8.0.tar.gz (16 kB)\n",
      "Requirement already satisfied, skipping upgrade: ipykernel>=5.1.1 in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from Kqlmagic>=0.1.106->msticpy) (5.3.0)\n",
      "Collecting isodate>=0.6.0\n",
      "  Using cached isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
      "Requirement already satisfied, skipping upgrade: Pygments>=2.2.0 in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from Kqlmagic>=0.1.106->msticpy) (2.6.1)\n",
      "Collecting psutil>=5.4.7\n",
      "  Downloading psutil-5.7.0-cp38-cp38-win_amd64.whl (235 kB)\n",
      "Collecting flask>=1.1.1\n",
      "  Using cached Flask-1.1.2-py2.py3-none-any.whl (94 kB)\n",
      "Collecting prettytable>=0.7.2\n",
      "  Using cached prettytable-0.7.2.tar.bz2 (21 kB)\n",
      "Collecting pyjwt>=1.7.1\n",
      "  Using cached PyJWT-1.7.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.2.0-cp38-none-win_amd64.whl (58 kB)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from matplotlib>=3.0.2->msticpy) (2.4.7)\n",
      "Collecting idna<3,>=2.5\n",
      "  Using cached idna-2.9-py2.py3-none-any.whl (58 kB)\n",
      "Collecting chardet<4,>=3.0.2\n",
      "  Using cached chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from requests>=2.21.1->msticpy) (2020.6.20)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting requests-file>=1.4\n",
      "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
      "Collecting wrapt<2,>=1.10\n",
      "  Using cached wrapt-1.12.1.tar.gz (27 kB)\n",
      "Requirement already satisfied, skipping upgrade: colorama; sys_platform == \"win32\" in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from ipython>=7.2.0->msticpy) (0.4.3)\n",
      "Requirement already satisfied, skipping upgrade: backcall in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from ipython>=7.2.0->msticpy) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from ipython>=7.2.0->msticpy) (3.0.5)\n",
      "Requirement already satisfied, skipping upgrade: pickleshare in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from ipython>=7.2.0->msticpy) (0.7.5)\n",
      "Requirement already satisfied, skipping upgrade: decorator in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from ipython>=7.2.0->msticpy) (4.4.2)\n",
      "Requirement already satisfied, skipping upgrade: jedi>=0.10 in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from ipython>=7.2.0->msticpy) (0.17.1)\n",
      "Collecting msal-extensions~=0.1.3\n",
      "  Using cached msal_extensions-0.1.3-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting azure-cli-nspkg>=2.0.0\n",
      "  Using cached azure_cli_nspkg-3.0.4-py2.py3-none-any.whl (1.8 kB)\n",
      "Collecting argcomplete~=1.8\n",
      "  Using cached argcomplete-1.11.1-py2.py3-none-any.whl (36 kB)\n",
      "Collecting pkginfo\n",
      "  Using cached pkginfo-1.5.0.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting humanfriendly<9.0,>=4.7\n",
      "  Using cached humanfriendly-8.2-py2.py3-none-any.whl (86 kB)\n",
      "Collecting azure-cli-telemetry\n",
      "  Using cached azure_cli_telemetry-1.0.4-py2.py3-none-any.whl (11 kB)\n",
      "Collecting knack==0.7.0rc4\n",
      "  Using cached knack-0.7.0rc4-py3-none-any.whl (57 kB)\n",
      "Collecting wheel==0.30.0\n",
      "  Using cached wheel-0.30.0-py2.py3-none-any.whl (49 kB)\n",
      "Collecting azure-mgmt-core==1.0.0\n",
      "  Using cached azure_mgmt_core-1.0.0-py2.py3-none-any.whl (21 kB)\n",
      "Collecting paramiko<3.0.0,>=2.0.8\n",
      "  Using cached paramiko-2.7.1-py2.py3-none-any.whl (206 kB)\n",
      "Collecting jmespath\n",
      "  Using cached jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting pyopenssl>=17.1.0\n",
      "  Using cached pyOpenSSL-19.1.0-py2.py3-none-any.whl (53 kB)\n",
      "Collecting maxminddb>=1.5.2\n",
      "  Using cached maxminddb-1.5.4.tar.gz (282 kB)\n",
      "Requirement already satisfied, skipping upgrade: jinja2>=2.9 in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from folium>=0.9.0->msticpy) (2.11.2)\n",
      "Collecting branca>=0.3.0\n",
      "  Downloading branca-0.4.1-py3-none-any.whl (24 kB)\n",
      "Collecting cffi!=1.11.3,>=1.8\n",
      "  Downloading cffi-1.14.0-cp38-cp38-win_amd64.whl (177 kB)\n",
      "Collecting scipy>=1.0.1\n",
      "  Downloading scipy-1.5.0-cp38-cp38-win_amd64.whl (31.4 MB)\n",
      "Collecting pillow>=4.0\n",
      "  Downloading Pillow-7.1.2-cp38-cp38-win_amd64.whl (2.0 MB)\n",
      "Requirement already satisfied, skipping upgrade: packaging>=16.8 in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from bokeh>=1.4.0->msticpy) (20.4)\n",
      "Requirement already satisfied, skipping upgrade: tornado>=5.1 in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from bokeh>=1.4.0->msticpy) (6.0.4)\n",
      "Collecting typing_extensions>=3.7.4\n",
      "  Using cached typing_extensions-3.7.4.2-py3-none-any.whl (22 kB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-0.15.1-py3-none-any.whl (298 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting pywin32-ctypes!=0.1.0,!=0.1.1; sys_platform == \"win32\"\n",
      "  Using cached pywin32_ctypes-0.2.0-py2.py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied, skipping upgrade: widgetsnbextension~=3.5.0 in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from ipywidgets>=7.4.2->msticpy) (3.5.1)\n",
      "Requirement already satisfied, skipping upgrade: nbformat>=4.2.0 in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from ipywidgets>=7.4.2->msticpy) (5.0.7)\n",
      "Collecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.0.1-py3-none-any.whl (32 kB)\n",
      "Collecting retrying>=1.3.3\n",
      "  Using cached retrying-1.3.3.tar.gz (10 kB)\n",
      "Requirement already satisfied, skipping upgrade: ipython-genutils in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from traitlets>=4.3.2->Kqlmagic>=0.1.106->msticpy) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-client in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from ipykernel>=5.1.1->Kqlmagic>=0.1.106->msticpy) (6.1.3)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Using cached itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting click>=5.1\n",
      "  Using cached click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting Werkzeug>=0.15\n",
      "  Using cached Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Requirement already satisfied, skipping upgrade: wcwidth in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.2.0->msticpy) (0.2.4)\n",
      "Requirement already satisfied, skipping upgrade: parso<0.8.0,>=0.7.0 in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from jedi>=0.10->ipython>=7.2.0->msticpy) (0.7.0)\n",
      "Collecting portalocker~=1.0\n",
      "  Using cached portalocker-1.7.0-py2.py3-none-any.whl (14 kB)\n",
      "Collecting azure-nspkg>=2.0.0\n",
      "  Using cached azure_nspkg-3.0.2-py3-none-any.whl (1.5 kB)\n",
      "Collecting pyreadline; sys_platform == \"win32\"\n",
      "  Using cached pyreadline-2.1.zip (109 kB)\n",
      "Collecting applicationinsights<0.12,>=0.11.1\n",
      "  Using cached applicationinsights-0.11.9-py2.py3-none-any.whl (58 kB)\n",
      "Collecting tabulate\n",
      "  Using cached tabulate-0.8.7-py3-none-any.whl (24 kB)\n",
      "Collecting bcrypt>=3.1.3\n",
      "  Downloading bcrypt-3.1.7-cp38-cp38-win_amd64.whl (28 kB)\n",
      "Collecting pynacl>=1.0.1\n",
      "  Downloading PyNaCl-1.4.0-cp38-cp38-win_amd64.whl (206 kB)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from jinja2>=2.9->folium>=0.9.0->msticpy) (1.1.1)\n",
      "Collecting pycparser\n",
      "  Using cached pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Requirement already satisfied, skipping upgrade: notebook>=4.4.1 in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.4.2->msticpy) (6.0.3)\n",
      "Requirement already satisfied, skipping upgrade: jsonschema!=2.5.0,>=2.4 in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets>=7.4.2->msticpy) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-core in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets>=7.4.2->msticpy) (4.6.3)\n",
      "Requirement already satisfied, skipping upgrade: pyzmq>=13 in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from jupyter-client->ipykernel>=5.1.1->Kqlmagic>=0.1.106->msticpy) (19.0.1)\n",
      "Requirement already satisfied, skipping upgrade: pywin32!=226; platform_system == \"Windows\" in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from portalocker~=1.0->msal-extensions~=0.1.3->azure-cli-core==2.5.0->msticpy) (227)\n",
      "Requirement already satisfied, skipping upgrade: Send2Trash in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.4.2->msticpy) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: terminado>=0.8.1 in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.4.2->msticpy) (0.8.3)\n",
      "Requirement already satisfied, skipping upgrade: prometheus-client in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.4.2->msticpy) (0.8.0)\n",
      "Requirement already satisfied, skipping upgrade: nbconvert in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.4.2->msticpy) (5.6.1)\n",
      "Requirement already satisfied, skipping upgrade: pyrsistent>=0.14.0 in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.4.2->msticpy) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: testpath in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.4.2->msticpy) (0.4.4)\n",
      "Requirement already satisfied, skipping upgrade: entrypoints>=0.2.2 in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.4.2->msticpy) (0.3)\n",
      "Requirement already satisfied, skipping upgrade: defusedxml in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.4.2->msticpy) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: mistune<2,>=0.8.1 in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.4.2->msticpy) (0.8.4)\n",
      "Requirement already satisfied, skipping upgrade: bleach in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.4.2->msticpy) (3.1.5)\n",
      "Requirement already satisfied, skipping upgrade: pandocfilters>=1.4.1 in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.4.2->msticpy) (1.4.2)\n",
      "Requirement already satisfied, skipping upgrade: webencodings in c:\\users\\pebryan\\anaconda3\\envs\\clean\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.4.2->msticpy) (0.5.1)\n",
      "Building wheels for collected packages: bokeh, pyperclip, prettytable, wrapt, maxminddb, retrying, pyreadline\n",
      "  Building wheel for bokeh (setup.py): started\n",
      "  Building wheel for bokeh (setup.py): finished with status 'done'\n",
      "  Created wheel for bokeh: filename=bokeh-2.1.1-py3-none-any.whl size=9257201 sha256=c1ab9aa18445c86f1411ac42a040fdd8a4defb4117c41836de9209b7e2dce694\n",
      "  Stored in directory: c:\\users\\pebryan\\appdata\\local\\pip\\cache\\wheels\\6f\\1b\\bc\\5add06a501c46e8aee615a089555beffdad8030aa5d6d35830\n",
      "  Building wheel for pyperclip (setup.py): started\n",
      "  Building wheel for pyperclip (setup.py): finished with status 'done'\n",
      "  Created wheel for pyperclip: filename=pyperclip-1.8.0-py3-none-any.whl size=8696 sha256=d1edd1a416ad2c884ebae3bc7ae6daae410a9eb88e0a882246ef1098bdec990f\n",
      "  Stored in directory: c:\\users\\pebryan\\appdata\\local\\pip\\cache\\wheels\\03\\79\\58\\ab51f0f590281b0f4f6046d9271eb98cc50565afb9200f155a\n",
      "  Building wheel for prettytable (setup.py): started\n",
      "  Building wheel for prettytable (setup.py): finished with status 'done'\n",
      "  Created wheel for prettytable: filename=prettytable-0.7.2-py3-none-any.whl size=13704 sha256=771798335e0b9c0807189b84daf3df6c124b34df37caf2f61c78b2c7ebcf3917\n",
      "  Stored in directory: c:\\users\\pebryan\\appdata\\local\\pip\\cache\\wheels\\46\\60\\6c\\bb25d05df22906786206e901e9354bb3061061191116768bee\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-cp38-cp38-win_amd64.whl size=33675 sha256=1f3f8b55cbd53fdff102c5d54273d36c74856d9fd74f6513d3b35b5bdc622227\n",
      "  Stored in directory: c:\\users\\pebryan\\appdata\\local\\pip\\cache\\wheels\\5f\\fd\\9e\\b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\n",
      "  Building wheel for maxminddb (setup.py): started\n",
      "  Building wheel for maxminddb (setup.py): finished with status 'done'\n",
      "  Created wheel for maxminddb: filename=maxminddb-1.5.4-py3-none-any.whl size=14872 sha256=ba40a7377c26ce1d851e0636d91b5c7a22ed8c4997a5d3169248fac641c68ccc\n",
      "  Stored in directory: c:\\users\\pebryan\\appdata\\local\\pip\\cache\\wheels\\a7\\11\\8e\\613147a683234875ef661d65011614cf46bcccf9fee7ab1a79\n",
      "  Building wheel for retrying (setup.py): started\n",
      "  Building wheel for retrying (setup.py): finished with status 'done'\n",
      "  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=11435 sha256=bda3ccd94925d138381df9818eaca96fa816be9c4b60e7930bae7391cc8dd456\n",
      "  Stored in directory: c:\\users\\pebryan\\appdata\\local\\pip\\cache\\wheels\\c4\\a7\\48\\0a434133f6d56e878ca511c0e6c38326907c0792f67b476e56\n",
      "  Building wheel for pyreadline (setup.py): started\n",
      "  Building wheel for pyreadline (setup.py): finished with status 'done'\n",
      "  Created wheel for pyreadline: filename=pyreadline-2.1-py3-none-any.whl size=93844 sha256=3c3a5d6c5640250d1e143d05b4cd16bae04db03e85be2d6fa8febef1914905d5\n",
      "  Stored in directory: c:\\users\\pebryan\\appdata\\local\\pip\\cache\\wheels\\0e\\6e\\9d\\402aa64e362e59c7032231a2e6942e647a6c12508d2c77fc4d\n",
      "Successfully built bokeh pyperclip prettytable wrapt maxminddb retrying pyreadline\n",
      "Installing collected packages: pytz, numpy, pandas, retrying, plotly, idna, chardet, urllib3, requests, pyjwt, pycparser, cffi, cryptography, adal, Markdown, lxml, pyperclip, soupsieve, beautifulsoup4, isodate, psutil, itsdangerous, click, Werkzeug, flask, oauthlib, requests-oauthlib, msrest, msrestazure, cycler, kiwisolver, matplotlib, scipy, seaborn, msal, portalocker, msal-extensions, azure-nspkg, azure-cli-nspkg, argcomplete, pkginfo, pyreadline, humanfriendly, applicationinsights, azure-cli-telemetry, jmespath, tabulate, pyyaml, knack, wheel, azure-core, azure-mgmt-core, bcrypt, pynacl, paramiko, pyopenssl, azure-common, azure-mgmt-resource, azure-cli-core, prettytable, Kqlmagic, requests-file, tldextract, wrapt, deprecated, azure-mgmt-subscription, maxminddb, geoip2, branca, folium, azure-mgmt-compute, azure-keyvault-secrets, azure-mgmt-network, tqdm, pillow, typing-extensions, bokeh, joblib, threadpoolctl, scikit-learn, typing, azure-mgmt-monitor, azure-mgmt-keyvault, dnspython, ipwhois, pywin32-ctypes, keyring, networkx, azure-identity, msticpy\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.34.2\n",
      "    Uninstalling wheel-0.34.2:\n",
      "      Successfully uninstalled wheel-0.34.2\n",
      "Successfully installed Kqlmagic-0.1.113.post1 Markdown-3.2.2 Werkzeug-1.0.1 adal-1.2.4 applicationinsights-0.11.9 argcomplete-1.11.1 azure-cli-core-2.5.0 azure-cli-nspkg-3.0.4 azure-cli-telemetry-1.0.4 azure-common-1.1.25 azure-core-1.6.0 azure-identity-1.3.1 azure-keyvault-secrets-4.1.0 azure-mgmt-compute-12.1.0 azure-mgmt-core-1.0.0 azure-mgmt-keyvault-2.2.0 azure-mgmt-monitor-0.10.0 azure-mgmt-network-10.2.0 azure-mgmt-resource-10.0.0 azure-mgmt-subscription-0.6.0 azure-nspkg-3.0.2 bcrypt-3.1.7 beautifulsoup4-4.9.1 bokeh-2.1.1 branca-0.4.1 cffi-1.14.0 chardet-3.0.4 click-7.1.2 cryptography-2.9.2 cycler-0.10.0 deprecated-1.2.10 dnspython-1.16.0 flask-1.1.2 folium-0.11.0 geoip2-3.0.0 humanfriendly-8.2 idna-2.9 ipwhois-1.1.0 isodate-0.6.0 itsdangerous-1.1.0 jmespath-0.10.0 joblib-0.15.1 keyring-21.2.1 kiwisolver-1.2.0 knack-0.7.0rc4 lxml-4.5.1 matplotlib-3.2.2 maxminddb-1.5.4 msal-1.0.0 msal-extensions-0.1.3 msrest-0.6.16 msrestazure-0.6.3 msticpy-0.5.1 networkx-2.4 numpy-1.19.0 oauthlib-3.1.0 pandas-1.0.5 paramiko-2.7.1 pillow-7.1.2 pkginfo-1.5.0.1 plotly-4.8.1 portalocker-1.7.0 prettytable-0.7.2 psutil-5.7.0 pycparser-2.20 pyjwt-1.7.1 pynacl-1.4.0 pyopenssl-19.1.0 pyperclip-1.8.0 pyreadline-2.1 pytz-2020.1 pywin32-ctypes-0.2.0 pyyaml-5.3.1 requests-2.24.0 requests-file-1.5.1 requests-oauthlib-1.3.0 retrying-1.3.3 scikit-learn-0.23.1 scipy-1.5.0 seaborn-0.10.1 soupsieve-2.0.1 tabulate-0.8.7 threadpoolctl-2.1.0 tldextract-2.2.2 tqdm-4.46.1 typing-3.7.4.1 typing-extensions-3.7.4.2 urllib3-1.25.9 wheel-0.30.0 wrapt-1.12.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: azure-cli-core 2.5.0 has requirement azure-mgmt-resource==9.0.0, but you'll have azure-mgmt-resource 10.0.0 which is incompatible.\n",
      "ERROR: kqlmagic 0.1.113.post1 has requirement azure-cli-core>=2.6.0, but you'll have azure-cli-core 2.5.0 which is incompatible.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Checking msticpy version..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "msticpy version 0.5.1 OK"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing imports....\n",
      "Checking configuration....\n",
      "Setting options....\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Notebook setup complete</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "REQ_PYTHON_VER=(3, 6)\n",
    "REQ_MSTICPY_VER=(0, 5, 0)\n",
    "\n",
    "display(HTML(\"<h3>Starting Notebook setup...</h3>\"))\n",
    "# If you did not clone the entire Azure-Sentinel-Notebooks repo you may not have this file\n",
    "if Path(\"./utils/nb_check.py\").is_file():\n",
    "    from utils.nb_check import check_python_ver, check_mp_ver\n",
    "\n",
    "    check_python_ver(min_py_ver=REQ_PYTHON_VER)\n",
    "    try:\n",
    "        check_mp_ver(min_msticpy_ver=REQ_MSTICPY_VER)\n",
    "    except ImportError:\n",
    "        !pip install --upgrade msticpy\n",
    "        if \"msticpy\" in sys.modules:\n",
    "            importlib.reload(sys.modules[\"msticpy\"])\n",
    "        else:\n",
    "            import msticpy\n",
    "        check_mp_ver(REQ_MSTICPY_VER)\n",
    "            \n",
    "from msticpy.nbtools import nbinit\n",
    "nbinit.init_notebook(\n",
    "    namespace=globals(),\n",
    "    extra_imports=[\"ipwhois, IPWhois, pyyaml\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Configuration\n",
    "Once we have set up our Jupyter environment with the libraries that we'll use in the notebook, we need to make sure we have some configuration in place. Some of the notebook components need addtional configuration to connect to external services (e.g. API keys to retrieve Threat Intelligence data). This includes configuration for connection to our Azure Sentinel workspace, as well as some threat intelligence providers we will use later.\n",
    "The easiest way to handle the configuration for these services is to store them in a msticpyconfig file (`msticpyconfig.yaml`). More details on msticpyconfig can be found here: https://msticpy.readthedocs.io/en/latest/getting_started/msticpyconfig.html\n",
    "\n",
    "### Learn more: \n",
    "- In this notebook we will setup the basic config we need to get started. If you need a more complete walk-through we have a separate notebook to help you: https://github.com/Azure/Azure-Sentinel-Notebooks/blob/master/ConfiguringNotebookEnvironment.ipynb\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Azure-Sentinel-Notebooks GitHub repo contains an template msticpyconfig file ready to be populated. If you have run this notebook before you may have a msticpyconfig file already populated, the cell below allows you to checks if this file. If your config file does not contain details under Azure Sentinel > Workspaces, or TIProviders the following cells will populate these for you.<br>\n",
    "If you want to see an example of what a populated msticpyconfig file should look like a samples is included in the repo as msticpyconfig-sample.yaml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pfile msticpyconfig.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not have and msticpyconfig file we can populate one for you. Before you do this you will need a few things.\n",
    "\n",
    "The first is the Workspace ID and Tenant ID of the Azure Sentinel Workspace you wish to connect to.\n",
    "\n",
    " - You can get the workspace ID by opening Azure Sentinel in the [Azure Portal](\"https://portal.azure.com\") and selecting Settings > Workspace Settings. Your Workspace ID is displayed near the top of this page.\n",
    "\n",
    "- You can get your tenant ID (also referred to organization or directory ID) via [Azure Active Directory](\"https://docs.microsoft.com/en-us/onedrive/find-your-office-365-tenant-id\")\n",
    "\n",
    "We are going to use [VirusTotal](\"https://www.virustotal.com\") to enrich our Azure Sentinel data. For this you will need a VirusTotal API key, one of these can be obtained for free (as a personnal key) via the [VirusTotal](\"https://developers.virustotal.com/v3.0/reference#getting-started\") website.\n",
    "We are using VirusTotal for this notebook but we also support a range of other threat intelligence providers: https://msticpy.readthedocs.io/en/latest/data_acquisition/TIProviders.html\n",
    "<br><br>\n",
    "In addition we are going to plot IP address locations on a map, in order to do this we are going to use [MaxMind](\"https://www.maxmind.com\") to geolocate IP addresses which requires an API key. You can sign up for a free account and API key at https://www.maxmind.com/en/geolite2/signup. \n",
    "<br><br>\n",
    "Once you have these required items run the cell below and you will prompted to enter these elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ws_id = nbwidgets.GetEnvironmentKey(env_var='WORKSPACE_ID',\n",
    "                                        prompt='Please enter your Log Analytics Workspace Id:', auto_display=True)\n",
    "ten_id = nbwidgets.GetEnvironmentKey(env_var='TENANT_ID',\n",
    "                                         prompt='Please enter your Log Analytics Tenant Id:', auto_display=True)\n",
    "vt_key = nbwidgets.GetEnvironmentKey(env_var='VT_KEY',\n",
    "                                        prompt='Please enter your VirusTotal API Key:', auto_display=True)\n",
    "mm_key = nbwidgets.GetEnvironmentKey(env_var='MM_KEY',\n",
    "                                        prompt='Please enter your MaxMind API Key:', auto_display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The cell below will now populate a msticpyconfig file with these values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(\"msticpyconfig.yaml\") as config:\n",
    "    data = yaml.load(config, Loader=yaml.Loader)\n",
    "data['AzureSentinel']\n",
    "\n",
    "workspace = {\"Default\":{\"WorkspaceId\": ws_id.value, \"TenantId\": ten_id.value}}\n",
    "ti = {\"VirusTotal\":{\"Args\": {\"AuthKey\" : vt_key.value}, \"Primary\" : True, \"Provider\": \"VirusTotal\"}}\n",
    "other_prov = {\"GeoIPLite\" : {\"Args\" : {\"AuthKey\" : mm_key.value, \"DBFolder\" : \"~/msticpy\"}, \"Provider\" : \"GeoLiteLookup\"}}\n",
    "data['AzureSentinel']['Workspaces'] = workspace\n",
    "data['TIProviders'] = ti\n",
    "data['OtherProviders'] = other_prov\n",
    "\n",
    "with open(\"msticpyconfig.yaml\", 'w') as config:\n",
    "    yaml.dump(data, config)\n",
    "    \n",
    "print(\"msticpyconfig.yaml updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now validate our configuration is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from msticpy.common.pkg_config import refresh_config, validate_config\n",
    "refresh_config()\n",
    "validate_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note** you may see warnings for missing providers when running this cell.\n",
    "> This is not an issue as we will not be using all providers in this notebook\n",
    "> so long as you get thie message \"No errors found.\" you are OK to proceed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Getting Data\n",
    "Now that we have configured the details necessary to connect to Azure Sentinel we can go ahead and get some data. We will do this with `QueryProvider()` from MSTICpy. \n",
    "You can use the `QueryProvider` class to connect to different data sources such as MDATP, the Security Graph API, and the one we will use here, Azure Sentinel. \n",
    "\n",
    "### Learn more:\n",
    " - More details on configuring and using QueryProviders can be found in the [MSTICpy Documentation](\"https://msticpy.readthedocs.io/en/latest/data_acquisition/DataProviders.html#instantiating-a-query-provider\").\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we are going to set up a QueryProvider for Azure Sentinel, pass it the details for our workspace that we just stored in the msticpyconfig file, and connect. The connection process will ask us to authenticate to our Azure Sentinel workspace via [device authorization](\"https://docs.microsoft.com/en-us/azure/active-directory/develop/v2-oauth2-device-code\") with our Azure credentials. You can do this by clicking the device login code button that appears as the output of the next cell, or by navigating to https://microsoft.com/devicelogin and manually entering the code. Note that this authentication persists with the kernel you are using with the notebook, so if you restart the kernel you will need to re-authenticate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalize a QueryProvider for Azure Sentinel\n",
    "qry_prov = QueryProvider(\"LogAnalytics\")\n",
    "\n",
    "# Get the Azure Sentinel workspace details from msticpyconfig\n",
    "try:\n",
    "    ws_config = WorkspaceConfig()\n",
    "    md(\"Workspace details collected from config file\")\n",
    "except:\n",
    "    raise(\"No workspace settings are configured, please run the cells above to configure these.\")\n",
    "    \n",
    "# Connect to Azure Sentinel with our QueryProvider and config details\n",
    "# ws_config.code_connect_str is a feature of MSTICpy that creates the required connection string from details in our msticpyconfig\n",
    "qry_prov.connect(connection_str=ws_config.code_connect_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have connected we can query Azure Sentinel for data, but before we do that we need to understand what data is avalaible to query. The QueryProvider object provides a way to get a list of tables as well as tables and table columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of tables in our Workspace\n",
    "display(qry_prov.schema_tables [:5]) # We are outputting only the first 5 tables for brevity\n",
    "# Get list of tables and thier columns\n",
    "qry_prov.schema['SigninLogs'] # We are only displaying the columns for SigninLogs for brevity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSTICpy includes a number of built in queries that you can run.<br>\n",
    "You can list available queries with .list_queries() and get specific details about a query by calling it with \"?\" as a parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of avaliable queries\n",
    "qry_prov.list_queries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get details about a query\n",
    "qry_prov.Azure.list_all_signins_geo(\"?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then run the query by calling it with the required parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "# set our query end time as now\n",
    "end = datetime.now()\n",
    "# set our query start time as 1 hour ago\n",
    "start = end - timedelta(hours=1)\n",
    "# run query with specified start and end times\n",
    "logons_df = qry_prov.Azure.list_all_signins_geo(start=start, end=end)\n",
    "# display first 5 rows of any results\n",
    "logons_df.head() # If you have no data you will just see the column headings displayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to run queries is to pass a string format of a KQL query to the query provider, this will run the query against the workspace connected to above, and will return the data in a [Pandas DataFrame](\"https://pandas.pydata.org/\"). We will look at working with Pandas in a bit more detail later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our query\n",
    "test_query = \"\"\"\n",
    "SigninLogs\n",
    "| where TimeGenerated > ago(7d)\n",
    "| take 10\n",
    "\"\"\"\n",
    "\n",
    "# Pass that query to our QueryProvider\n",
    "test_df = qry_prov.exec_query(test_query)\n",
    "\n",
    "# Check that we have some data\n",
    "if isinstance(test_df, pd.DataFrame) and not test_df.empty:\n",
    "    # .head() returns the first 5 rows of our results DataFrame\n",
    "    display(test_df.head())\n",
    "# If where is no data load some sample data to use instead\n",
    "else:\n",
    "    md(\"You don't appear to have any SigninLogs - we will load sample data for you to use.\")\n",
    "    qry_prov = QueryProvider(\"LocalData\", data_paths=[\"nbdemo/data/\"], query_paths=[\"nbdemo/data/\"])\n",
    "    logons_df = qry_prov.Azure.list_all_signins_geo()\n",
    "    display(logons_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn more:\n",
    " - You can learn more about the MSTICpy pre-defined queries in the [MSTICpy Documentation](\"https://msticpy.readthedocs.io/en/latest/data_acquisition/DataProviders.html#running-an-pre-defined-queryl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Pandas\n",
    "Our query results are returned in the form of a Pandas DataFrame. DataFrames are a core component of the Azure Sentinel notebooks and of MSTICpy and is used for both input and output formats.\n",
    "Pandas DataFrames are incredibly versitile data structures with a lot of useful features, we will cover a small number of them here and we recommend that you check out the Learn more section to learn more about Pandas features.\n",
    "<br>\n",
    "<br>\n",
    "### Displaying a DataFrame:\n",
    "The first thing we want to do is display our DataFrame. You can either just run it or explicity display it by calling `display(df)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this section we are going to create a DataFrame from data we have saved in a csv file\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/microsoft/msticpy/master/tests/testdata/host_logons.csv\", index_col=[0] )\n",
    "# Display our DataFrame\n",
    "df  # or display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note** if the dataframe variable (`df` in the example above) is the last statement in a \n",
    "> code cell, Jupyter will automatically display it without using the `display()` function. \n",
    "> However, if you want to display a DataFrame in the middle of \n",
    "> other code in a cell you must use the `display()` function.\n",
    "\n",
    "You may not want to display the whole DataFrame and instead display only a selection of items. There are numerous ways to do this and the cell below shows some of the most widely used functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md(\"Display the first 2 rows using head(): \", \"bold\")\n",
    "display(df.head(2))  # we don't need to call display here but just for illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md(\"Display the 3rd row using iloc[]: \", \"bold\")\n",
    "df.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md(\"Show the column names in the DataFrame \", \"bold\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md(\"Display just the TimeGenerated and TenantId columnns: \", \"bold\")\n",
    "df[[\"TimeGenerated\", \"TenantId\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also choose to select a subsection of our DataFrame based on the contents of the DataFrame:\n",
    "\n",
    "> **Tip**: the syntax in these examples is using a technique called *boolean indexing*. \n",
    "> <br>`df[<boolean expression>]`\n",
    "> returns all rows in the dataframe where the boolean expression is True\n",
    "> <br>In the first example we telling pandas to return all rows where the column value of\n",
    "> 'TargetUserName' matches 'MSTICAdmin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md(\"Display only rows where TargetUserName value is 'MSTICAdmin': \", \"bold\")\n",
    "df[df['TargetUserName']==\"MSTICAdmin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md(\"Display rows where TargetUserName is either MSTICAdmin or adm1nistratror:\", \"bold\")\n",
    "display(df[df['TargetUserName'].isin(['adm1nistrator', 'MSTICAdmin'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our DataFrame call also be extended to add new columns with additional data if reqired:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"NewCol\"] = \"Look at my new data!\"\n",
    "display(df[[\"TenantId\",\"Account\", \"TimeGenerated\", \"NewCol\"]].head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn more:\n",
    "There is a lot more you can do with Pandas, the links below provide some useful resources:\n",
    " - [Getting starting with Pandas](\"https://pandas.pydata.org/pandas-docs/stable/getting_started/index.html\")\n",
    " - [Infosec Jupyerbook intro to Pandas](\"https://infosecjupyterbook.com/notebooks/tutorials/03_intro_to_pandas.html\")\n",
    " - [A great list of Pandas hints and tricks](\"https://www.dataschool.io/python-pandas-tips-and-tricks/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Enriching data\n",
    "\n",
    "Now that we have seen how to query for data, and do some basic manipulation we can look at enriching this data with additional data sources. For this we are going to use an external threat intelligence provider to give us some more details about an IP address we have in our dataset using the [MSTICpy TIProvider](\"https://msticpy.readthedocs.io/en/latest/data_acquisition/TIProviders.html\") feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "# Check if we have logon data already and if not get some\n",
    "if not isinstance(logons_df, pd.DataFrame) or logons_df.empty:\n",
    "    # set our query end time as now\n",
    "    end = datetime.now()\n",
    "    # set our query start time as 1 hour ago\n",
    "    start = end - timedelta(days=1)\n",
    "    # run query with specified start and end times\n",
    "    logons_df = qry_prov.Azure.list_all_signins_geo(start=start, end=end)\n",
    "    \n",
    "# Create our TI provider\n",
    "ti = TILookup()\n",
    "# Get the first logon IP address from our dataset\n",
    "ip = logons_df.iloc[1]['IPAddress']\n",
    "# Look up the IP in VirusTotal\n",
    "ti_resp = ti.lookup_ioc(ip, providers=[\"VirusTotal\"])\n",
    "\n",
    "# Format our results as a DataFrame\n",
    "ti_resp = ti.result_to_df(ti_resp)\n",
    "display(ti_resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the [Pandas apply()](\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html\") feature we can get results for all the IP addresses in our data set and add the lookup severity score as a new column in our DataFrame for easier reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the IP address in each row, look it up against TI and return the seveirty score\n",
    "def lookup_res(row):\n",
    "    ip = row['IPAddress']\n",
    "    resp = ti.lookup_ioc(ip, providers=[\"VirusTotal\"])\n",
    "    resp = ti.result_to_df(resp)\n",
    "    return resp[\"Severity\"].iloc[0]\n",
    "\n",
    "# Take the first 3 rows of data and copy they into a new DataFrame\n",
    "enrich_logons_df = logons_df.iloc[:3].copy()\n",
    "# Create a new column called TIRisk and populate that with the TI severity score of the IP Address in that row\n",
    "enrich_logons_df['TIRisk'] = enrich_logons_df.apply(lookup_res, axis=1)\n",
    "# Display a subset of columns from our DataFrame\n",
    "enrich_logons_df[[\"TimeGenerated\", \"ResultType\", \"UserPrincipalName\", \"IPAddress\", \"TIRisk\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn more:\n",
    "MSTICpy includes further threat intelligence capabilities as well as other data enrichment options. More details on these can be found in the [documentation](\"https://msticpy.readthedocs.io/en/latest/DataEnrichment.html\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Analyzing data\n",
    "With the data we have collected we may wish to perform some analysis on it in order to better understand it. MSTICpy includes a number of features to help with this, and there are a vast array of other data analysis capabilities available via Python ranging from simple processes to complex ML models. We will start here by keeping it simple and look at how we can decode some Base64 encoded command line strings we have in order to allow us to understand their content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from msticpy.sectools import base64unpack as b64\n",
    "# Take our encoded Powershell Command\n",
    "b64_cmd = \"powershell.exe -encodedCommand SW52b2tlLVdlYlJlcXVlc3QgaHR0cHM6Ly9jb250b3NvLmNvbS9tYWx3YXJlIC1PdXRGaWxlIEM6XG1hbHdhcmUuZXhl\"\n",
    "# Unpack the Base64 encoded elements\n",
    "unpack_txt = b64.unpack(input_string=b64_cmd)\n",
    "# Display our results and transform for easier reading\n",
    "unpack_txt[1].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use MSTICpy to extract Indicators of Compromise (IoCs) from a dataset, this makes it easy to extract and match on a set of IoCs within our data. In the example below we take a US Cybersecurity & Infrastructure Security Agency (CISA) report and extract all domains listed in the report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# Set up our IoCExtract oject\n",
    "ioc_extractor = iocextract.IoCExtract()\n",
    "# Download our threat report\n",
    "data = requests.get(\"https://www.us-cert.gov/sites/default/files/publications/AA20-099A_WHITE.stix.xml\")\n",
    "# Extract domains listed in our report\n",
    "iocs = ioc_extractor.extract(data.text, ioc_types=\"dns\")['dns']\n",
    "# Display the first 5 iocs found in our report\n",
    "list(iocs)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn more:\n",
    "There are a wide range of options when it comes to data analysis in notebooks using Python. Here are some useful resources to get you started:\n",
    " - [MSITCpy DataAnalysis documentation](\"https://msticpy.readthedocs.io/en/latest/DataAnalysis.html\")\n",
    " - Scikit-Learn is a popular Python ML data analysis library, which has a useful [tutorial](\"https://scikit-learn.org/stable/tutorial/basic/tutorial.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Visualizing data\n",
    "Visualizing data can provide an excellent way to analyse data, identify patterns and anomalies. Python has a wide range of data visualization capabilities each of which have thier own benefits and drawbacks. We will look at some basic capabilities as well as the in-build visualizations in MSTICpy.\n",
    "<br><br><br>\n",
    "**Basic Graphs**<br>\n",
    "Pandas and Matplotlib provide the easiest and simplest way to produce simple plots of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_q = \"\"\"\n",
    "SigninLogs\n",
    "| where TimeGenerated > ago(7d)\n",
    "| sample 5\"\"\"\n",
    "\n",
    "# Try and query for data but if using sample data load that instead\n",
    "try:\n",
    "    vis_data = qry_prov.exec_query(vis_q)\n",
    "except FileNotFoundError:\n",
    "    vis_data = logons_df\n",
    "\n",
    "# Check we have some data in our results and if not use previously used dataset\n",
    "if not isinstance(vis_data, pd.DataFrame) or vis_data.empty:\n",
    "    vis_data = logons_df\n",
    "\n",
    "# Plot up to the first 5 IP addresses\n",
    "vis_data.head()['IPAddress'].value_counts().plot.bar(title=\"IP prevelence\", legend=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_df = vis_data.copy()\n",
    " # If we have lots of data just plot the first 5 rows\n",
    "pie_df.head()['IPAddress'].value_counts().plot.pie(legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn more:\n",
    " - The [Infosec Jupyterbook](\"https://infosecjupyterbook.com/\") includes a section on data visualization.\n",
    " - [Bokeh Library Documentation](\"https://bokeh.org/\")\n",
    " - [Matplotlib tutorial](\"https://matplotlib.org/3.2.0/tutorials/index.html\")\n",
    " - [Seaborn visualization library tutorial](\"https://seaborn.pydata.org/tutorial.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Conclusion\n",
    "This notebook has showed you the basics of using notebooks and Azure Sentinel for security investigaitons. There are many more things possible using notebooks and it is stronly encouraged to read the material we have referenced in the learn more sections in this notebook. You can also explore the other Azure Sentinel notebooks in order to take advantage of the pre-built hunting logic, and understand other analysis techniques that are possible. </br>\n",
    "### Appendix:\n",
    " - [Jupyter Notebooks: An Introduction](\"https://realpython.com/jupyter-notebook-introduction/\")\n",
    " - [Threat Hunting in the cloud with Azure Notebooks](\"https://medium.com/@maarten.goet/threat-hunting-in-the-cloud-with-azure-notebooks-supercharge-your-hunting-skills-using-jupyter-8d69218e7ca0\")\n",
    " - [MSTICpy documentation](\"https://msticpy.readthedocs.io/\")\n",
    " - [Azure Sentinel Notebooks documentation](\"https://docs.microsoft.com/en-us/azure/sentinel/notebooks\")\n",
    " - [The Infosec Jupyterbook](\"https://infosecjupyterbook.com/introduction.html\")\n",
    " - [Linux Host Explorer Notebook walkthrough](\"https://techcommunity.microsoft.com/t5/azure-sentinel/explorer-notebook-series-the-linux-host-explorer/ba-p/1138273\")\n",
    " - [Why use Jupyter for Security Investigations](\"https://techcommunity.microsoft.com/t5/azure-sentinel/why-use-jupyter-for-security-investigations/ba-p/475729\")\n",
    " - [Security Investigtions with Azure Sentinel & Notebooks](\"https://techcommunity.microsoft.com/t5/azure-sentinel/security-investigation-with-azure-sentinel-and-jupyter-notebooks/ba-p/432921\")\n",
    " - [Pandas Documentation](\"https://pandas.pydata.org/pandas-docs/stable/user_guide/index.html\")\n",
    " - [Bokeh Documentation](\"https://docs.bokeh.org/en/latest/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
