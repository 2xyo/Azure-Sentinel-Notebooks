{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  MITRE ATT&CK for Azure Sentinel\n",
    " <details>\n",
    "     <summary>Â <u>Details...</u></summary>\n",
    "\n",
    " **Notebook Version:** 1.0<br>\n",
    " **Python Version:** Python 3.6 (including Python 3.6 - AzureML)<br>\n",
    " **Required Packages**: msticpy, plotly, ruamel.yaml, requests_html, attackcti, pandas, numpy, matplotlib, ipywidgets, ipython<br>\n",
    " **Platforms Supported**:\n",
    " - Azure Notebooks ML Studio\n",
    " - Azure Notebooks DSVM\n",
    " - OS Independent\n",
    "\n",
    " <br> \n",
    "\n",
    " </details>\n",
    "\n",
    "This Notebooks brings together analysis and visualization of all analytics queries (hunting and detection) in Azure Sentinel community Github. Optionally, you can also connect to your own workspace to gather similar data enabled in your environment using REST API. The notebook further clean, process and enrich the data and convert into structured tabular data. The final data can be visualized no of ways with example visualization such as Heatmaps, Radar charts, embeeded ATT&CK Navigator as demonstrated in this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:29.244607Z",
     "start_time": "2020-10-05T10:51:24.531655Z"
    }
   },
   "outputs": [],
   "source": [
    "#imports \n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import re\n",
    "import glob\n",
    "import IPython\n",
    "import pandas as pd\n",
    "from ipywidgets import widgets, Layout\n",
    "from IPython.display import display, HTML\n",
    "from pathlib import Path\n",
    "\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "\n",
    "REQ_PYTHON_VER=(3, 6)\n",
    "REQ_MSTICPY_VER=(0, 6, 0)\n",
    "\n",
    "display(HTML(\"<h3>Starting Notebook setup...</h3>\"))\n",
    "if Path(\"./utils/nb_check.py\").is_file():\n",
    "    from utils.nb_check import check_python_ver, check_mp_ver\n",
    "\n",
    "    check_python_ver(min_py_ver=REQ_PYTHON_VER)\n",
    "    try:\n",
    "        check_mp_ver(min_msticpy_ver=REQ_MSTICPY_VER)\n",
    "    except ImportError:\n",
    "        !pip install --upgrade msticpy\n",
    "        if \"msticpy\" in sys.modules:\n",
    "            importlib.reload(sys.modules[\"msticpy\"])\n",
    "        else:\n",
    "            import msticpy\n",
    "        check_mp_ver(REQ_MSTICPY_VER)\n",
    "\n",
    "# If not using Azure Notebooks, install msticpy with\n",
    "# !pip install msticpy\n",
    "\n",
    "from msticpy.nbtools import nbinit\n",
    "extra_imports = [\n",
    "    \"msticpy.data.uploaders.loganalytics_uploader, LAUploader\",\n",
    "    \"plotly.subplots, make_subplots\",\n",
    "    \"pandas, json_normalize\",\n",
    "    \"ruamel.yaml, YAML\",\n",
    "    \"requests_html, HTMLSession\",\n",
    "    \"datetime, date\",\n",
    "    \"attackcti, attack_client\",\n",
    "]\n",
    "nbinit.init_notebook(\n",
    "    namespace=globals(),\n",
    "    additional_packages=[\"plotly\", \"ruamel.yaml\", \"requests_html\", \"attackcti\", \"qgrid\"],\n",
    "    extra_imports=extra_imports,\n",
    ");\n",
    "\n",
    "WIDGET_DEFAULTS = {\n",
    "    \"layout\": Layout(width=\"95%\"),\n",
    "    \"style\": {\"description_width\": \"initial\"},\n",
    "}\n",
    "\n",
    "#Set pandas options\n",
    "pd.get_option('max_rows',10)\n",
    "pd.set_option('max_colwidth',50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acqusition\n",
    "\n",
    "You can retrieve Detections and hunting Queries via below 2 methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download From Github\n",
    "In the first method, you can directly download from public Azure Sentinel GitHub to download templates. The templates are available withing Analytics pane and must be explicitly enabled and onboarded. \n",
    "\n",
    "Alternatively, you can also point it to your private GitHub repository if available. If you want to read more about Azure Sentinel DevOps process, refer the blog Deploying and Managing Azure Sentinel as Code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:29.290348Z",
     "start_time": "2020-10-05T10:51:29.247315Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_sentinel_queries_from_github(git_url, outputdir):\n",
    "    r = requests.get(git_url)\n",
    "\n",
    "    repo_zip = io.BytesIO(r.content)\n",
    "\n",
    "    archive = zipfile.ZipFile(repo_zip, mode=\"r\")\n",
    "\n",
    "    # Only extract Detections and Hunting Queries Folder\n",
    "    for file in archive.namelist():\n",
    "        if file.startswith(\n",
    "            (\n",
    "                \"Azure-Sentinel-master/Detections/\",\n",
    "                \"Azure-Sentinel-master/Hunting Queries/\",\n",
    "            )\n",
    "        ):\n",
    "            archive.extract(file, path=outputdir)\n",
    "    print(\"Downloaded and Extracted Files successfully\")\n",
    "\n",
    "\n",
    "def parse_yaml(parent_dir, child_dir):\n",
    "\n",
    "    sentinel_repourl = \"https://github.com/Azure/Azure-Sentinel/blob/master\"\n",
    "\n",
    "    # Collect list of files recusrively uinder a folder\n",
    "    yaml_queries = glob.glob(f\"{parent_dir}/{child_dir}/**/*.yaml\", recursive=True)\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # Parse and load yaml\n",
    "    parsed_yaml = YAML(typ=\"safe\")\n",
    "\n",
    "    # Recursively load yaml Files and append to dataframe\n",
    "    for query in yaml_queries:\n",
    "        with open(query, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            parsed_yaml_df = json_normalize(parsed_yaml.load(f))\n",
    "            parsed_yaml_df[\"GithubURL\"] = query.replace(parent_dir, sentinel_repourl)\n",
    "            df = df.append(parsed_yaml_df, ignore_index=True, sort=True)\n",
    "\n",
    "    df[\"DetectionType\"] = child_dir\n",
    "    df[\"DetectionService\"] = \"Azure Sentinel Community Github\"\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_and_preprocess_data(df):\n",
    "\n",
    "    columns = [\n",
    "        \"DetectionType\",\n",
    "        \"DetectionService\",\n",
    "        \"id\",\n",
    "        \"name\",\n",
    "        \"description\",\n",
    "        \"query\",\n",
    "        \"queryFrequency\",\n",
    "        \"queryPeriod\",\n",
    "        \"triggerOperator\",\n",
    "        \"triggerThreshold\",\n",
    "        \"tactics\",\n",
    "        \"relevantTechniques\",\n",
    "        \"requiredDataConnectors\",\n",
    "        \"severity\",\n",
    "        \"GithubURL\",\n",
    "        \"IngestedDate\",\n",
    "    ]\n",
    "\n",
    "    # Reording columns\n",
    "    df = df[columns]\n",
    "\n",
    "    # Inserting additional columns to list at specific index for later use\n",
    "    columns.insert(5, \"connectorId\")\n",
    "    columns.insert(6, \"dataTypes\")\n",
    "\n",
    "    # Separate dataframes for Built-in and Custom DataConnectors\n",
    "    builtin_dataconnectors = (\n",
    "        df[df.requiredDataConnectors.notnull()].reset_index().drop(\"index\", axis=1)\n",
    "    )\n",
    "    custom_dataconnectors = (\n",
    "        df[df.requiredDataConnectors.isnull()].reset_index().drop(\"index\", axis=1)\n",
    "    )\n",
    "\n",
    "    ## Pre-Processing Built-in Data Connectors dataframe\n",
    "    # Exploding columns to flatten the table\n",
    "    columns_to_expand = [\"tactics\", \"relevantTechniques\", \"requiredDataConnectors\"]\n",
    "    for column in columns_to_expand:\n",
    "        builtin_dataconnectors = builtin_dataconnectors.explode(column).reset_index(\n",
    "            drop=True\n",
    "        )\n",
    "    # Apply Data wrangling to derive columns from Json response\n",
    "    builtin_dataconn_expanded = pd.DataFrame(\n",
    "        builtin_dataconnectors[\"requiredDataConnectors\"].values.tolist()\n",
    "    )\n",
    "    # Concatenate 2 dataframs vertically to create Final Dataframe\n",
    "    builtin_dataconn_df = pd.concat(\n",
    "        [builtin_dataconnectors, builtin_dataconn_expanded], axis=1\n",
    "    )\n",
    "    # Exploding dataTypes column\n",
    "    builtin_dataconn_df = builtin_dataconn_df.explode(\"dataTypes\").reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "    builtin_dataconn_df = builtin_dataconn_df[columns]\n",
    "\n",
    "    # Populate new column Platform based on custom mapping\n",
    "    builtin_dataconn_df[\"Platform\"] = builtin_dataconn_df.connectorId.map(\n",
    "        platform_mapping\n",
    "    )\n",
    "    builtin_dataconn_df = builtin_dataconn_df.explode(\"Platform\").reset_index(drop=True)\n",
    "\n",
    "    ## Pre-Processing Custom or Missing Data Connectors dataframe\n",
    "    # Exploding columns to flatten the table\n",
    "    columns_to_expand = [\"tactics\", \"relevantTechniques\"]\n",
    "    for column in columns_to_expand:\n",
    "        custom_dataconnectors = custom_dataconnectors.explode(column).reset_index(\n",
    "            drop=True\n",
    "        )\n",
    "\n",
    "    custom_dataconnectors[\"connectorId\"] = [\n",
    "        x.split(\"/\")[-2] for x in custom_dataconnectors.GithubURL\n",
    "    ]\n",
    "    custom_dataconnectors[\"dataTypes\"] = (\n",
    "        custom_dataconnectors.connectorId.map(str) + \"_CL\"\n",
    "    )\n",
    "\n",
    "    # Populate new column Platform based on custom mapping\n",
    "    custom_dataconnectors[\"Platform\"] = custom_dataconnectors.connectorId.map(\n",
    "        platform_mapping\n",
    "    )\n",
    "    custom_dataconnectors = custom_dataconnectors.explode(\"Platform\").reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "\n",
    "    custom_dataconn_df = custom_dataconnectors[columns]\n",
    "\n",
    "    # Concatenate 2 dataframs vertically\n",
    "    result = pd.concat([builtin_dataconn_df, custom_dataconn_df], axis=0)\n",
    "    result = result.drop([\"requiredDataConnectors\"], axis=1)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_mitre_matrix_flat():\n",
    "    # Create the client\n",
    "    lift = attack_client()\n",
    "\n",
    "    # Pull all the techniques without STIX Format\n",
    "    all_techniques = lift.get_techniques(stix_format=False)\n",
    "    techniques_normalized = json_normalize(all_techniques)\n",
    "\n",
    "    # Selecting specific columns of output dataset and reindex the dataframe\n",
    "    techniques = techniques_normalized.reindex(\n",
    "        [\"matrix\", \"tactic\", \"technique\", \"technique_id\"], axis=1\n",
    "    )\n",
    "    mitre_attack = techniques[\"matrix\"] == \"mitre-attack\"\n",
    "    mitre_attack_df = techniques[mitre_attack]\n",
    "    mitre_attack_df = mitre_attack_df.reset_index(drop=True)\n",
    "\n",
    "    # Exploding Platform and Tactic Columns to flatten the table\n",
    "    mitre_attack_df = mitre_attack_df.explode(\"tactic\").reset_index(drop=True)\n",
    "\n",
    "    # Creae a new column by removing subtechniques\n",
    "    mitre_attack_df[\"technique_id_parsed\"] = mitre_attack_df[\"technique_id\"].str.split(\n",
    "        \".\", n=1, expand=True\n",
    "    )[0]\n",
    "\n",
    "    return mitre_attack_df\n",
    "\n",
    "\n",
    "platform_mapping = {\n",
    "    \"AWS\": [\"AWS\"],\n",
    "    \"AWSS3\": [\"AWS\", \"SaaS\"],\n",
    "    \"AzureActiveDirectory\": [\"Azure\", \"Azure AD\"],\n",
    "    \"AzureActivity\": [\"Azure\", \"SaaS\"],\n",
    "    \"AzureDevOpsAuditing\": [\"Azure\", \"SaaS\"],\n",
    "    \"AzureMonitor\": [\"SaaS\"],\n",
    "    \"AzureMonitor(IIS)\": [\"Azure\"],\n",
    "    \"AzureMonitor(Keyvault)\": [\"Azure\"],\n",
    "    \"AzureMonitor(Query Audit)\": [\"Azure\"],\n",
    "    \"AzureMonitor(VMInsights)\": [\"Azure\", \"Windows\", \"Linux\"],\n",
    "    \"AzureMonitor(WindowsEventLogs)\": [\"Azure\", \"Windows\"],\n",
    "    \"AzureMonitor(WireData)\": [\"Azure\", \"Windows\", \"Linux\"],\n",
    "    \"AzureNetworkWatcher\": [\"Azure\"],\n",
    "    \"AzureSecurityCenter\": [\"Azure\", \"SaaS\"],\n",
    "    \"Barracuda\": [\"Azure\", \"Windows\", \"Linux\"],\n",
    "    \"BehaviorAnalytics\": [\"Azure AD\", \"Azure\", \"Windows\"],\n",
    "    \"CEF\": [\"Azure\", \"Windows\", \"Linux\"],\n",
    "    \"CheckPoint\": [\"Azure\", \"Windows\", \"Linux\"],\n",
    "    \"CiscoASA\": [\"Azure\", \"Windows\", \"Linux\"],\n",
    "    \"CustomConnector\": [\"Unknown\"],\n",
    "    \"DNS\": [\"Azure\", \"Windows\", \"Linux\"],\n",
    "    \"EsetSMC\": [\"Azure\", \"Windows\", \"Linux\"],\n",
    "    \"F5\": [\"Azure\", \"Windows\", \"Linux\"],\n",
    "    \"Fortinet\": [\"Azure\", \"Windows\", \"Linux\"],\n",
    "    \"GitHub\": [\"SaaS\", \"Windows\", \"Linux\"],\n",
    "    \"InfobloxNIOS\": [\"Azure\", \"Windows\", \"Linux\"],\n",
    "    \"MicrosoftCloudAppSecurity\": [\"Azure\", \"AWS\", \"GCP\", \"SaaS\"],\n",
    "    \"MicrosoftDefenderAdvancedThreatProtection\": [\"Windows\", \"Linux\"],\n",
    "    \"Office365\": [\"Office 365\"],\n",
    "    \"OktaSSO\": [\"Azure AD\", \"AWS\", \"GCP\", \"SaaS\"],\n",
    "    \"PaloAltoNetworks\": [\"Azure\", \"Windows\", \"Linux\"],\n",
    "    \"ProofpointTAP\": [\"Office 365\"],\n",
    "    \"PulseConnectSecure\": [\"Azure\", \"Windows\", \"Linux\"],\n",
    "    \"QualysVulnerabilityManagement\": [\"Azure\", \"Windows\", \"Linux\", \"macOS\"],\n",
    "    \"SecurityEvents\": [\"Windows\"],\n",
    "    \"SophosXGFirewall\": [\"Azure\", \"Windows\", \"Linux\"],\n",
    "    \"SymantecProxySG\": [\"Azure\", \"Windows\", \"Linux\"],\n",
    "    \"SymantecVIP\": [\"Azure\", \"Windows\", \"Linux\"],\n",
    "    \"Syslog\": [\"Linux\"],\n",
    "    \"ThreatIntelligence\": [\n",
    "        \"Windows\",\n",
    "        \"Linux\",\n",
    "        \"macOS\",\n",
    "        \"Azure\",\n",
    "        \"AWS\",\n",
    "        \"Azure AD\",\n",
    "        \"Office 365\",\n",
    "    ],\n",
    "    \"ThreatIntelligenceTaxii\": [\n",
    "        \"Windows\",\n",
    "        \"Linux\",\n",
    "        \"macOS\",\n",
    "        \"Azure\",\n",
    "        \"AWS\",\n",
    "        \"Azure AD\",\n",
    "        \"Office 365\",\n",
    "    ],\n",
    "    \"TeamsLogs\": [\"Windows\", \"Linux\", \"macOS\"],\n",
    "    \"TrendMicro\": [\"Azure\", \"Windows\", \"Linux\", \"macOS\"],\n",
    "    \"VMwareCarbonBlack\": [\"Windows\", \"Linux\", \"macOS\"],\n",
    "    \"WAF\": [\"Azure\", \"SaaS\"],\n",
    "    \"Zscaler\": [\"Azure\", \"Windows\", \"Linux\"],\n",
    "    \"ZoomLogs\": [\"SaaS\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:29.312809Z",
     "start_time": "2020-10-05T10:51:29.293105Z"
    }
   },
   "outputs": [],
   "source": [
    "def_path = Path.joinpath(Path(os.getcwd()), \"mitre-attack\")\n",
    "path_wgt = widgets.Text(value=str(def_path), \n",
    "                        description='Path to extract to zipped repo files: ', \n",
    "                        layout=Layout(width='50%'),\n",
    "                        style={'description_width': 'initial'})\n",
    "path_wgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:38.011130Z",
     "start_time": "2020-10-05T10:51:29.315718Z"
    }
   },
   "outputs": [],
   "source": [
    "# Download the Azure Sentinel Github repo as ZIP\n",
    "azsentinel_git_url = 'https://github.com/Azure/Azure-Sentinel/archive/master.zip'\n",
    "\n",
    "get_sentinel_queries_from_github(git_url=azsentinel_git_url, outputdir=path_wgt.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:39.083278Z",
     "start_time": "2020-10-05T10:51:38.016176Z"
    }
   },
   "outputs": [],
   "source": [
    "QUERIES_PATH = 'Azure-Sentinel-master'\n",
    "sentinel_root = Path(path_wgt.value) / QUERIES_PATH\n",
    "\n",
    "display(HTML(\"<h3>Listings under Detections...</h2>\"))\n",
    "%ls {sentinel_root}/Detections/\n",
    "\n",
    "display(HTML(\"<h3>Listings under Hunting Queries...</h2>\"))\n",
    "%ls {sentinel_root}/'Hunting Queries'/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve via Azure Sentinel API - Experimental\n",
    "\n",
    "**Known API Limitations:**\n",
    "- Hunting Query is currently not part of REST API which is GA, but you can use LogAnalytics REST API saved searches and then filter out Hunting Queries.\n",
    "- In both cases, the data retrieved from savedSearches and AlertRuleTemplates, only Tactics is available and not techniques. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:39.087805Z",
     "start_time": "2020-10-05T10:51:39.085098Z"
    }
   },
   "outputs": [],
   "source": [
    "#!az login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:39.098465Z",
     "start_time": "2020-10-05T10:51:39.091826Z"
    }
   },
   "outputs": [],
   "source": [
    "# from azure.identity import DefaultAzureCredential\n",
    "# from adal import AuthenticationContext\n",
    "# from azure.common.credentials import get_azure_cli_credentials\n",
    "# from datetime import datetime\n",
    "\n",
    "# # azure.mgmt.resource is an Azure SDK management library\n",
    "# from azure.mgmt.resource import SubscriptionClient\n",
    "\n",
    "# from azure.common.credentials import get_cli_profile \n",
    "\n",
    "# from urllib.parse import urlparse\n",
    "\n",
    "# az_creds, _ = get_azure_cli_credentials()\n",
    "\n",
    "# credential = DefaultAzureCredential()\n",
    "# subscription_client = SubscriptionClient(az_creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:39.107109Z",
     "start_time": "2020-10-05T10:51:39.102860Z"
    }
   },
   "outputs": [],
   "source": [
    "# url = urlparse('https://api.loganalytics.io')\n",
    "# _resource = f\"{url.scheme}://{url.hostname}\"\n",
    "\n",
    "# sub_info = {\n",
    "#     \"tenant_id\": \"<tenant-id>\",\n",
    "#     \"subscription_id\": \"<sub-id>\",\n",
    "#     \"resource_group\": \"<resource-group>\",\n",
    "#     \"workspace_id\": \"<workspace-id>\",\n",
    "#     \"workspace_name\": \"<workspace-name>\",\n",
    "# }\n",
    "\n",
    "# profile = get_cli_profile()\n",
    "# credential, _subscription, _tenant = profile.get_raw_token(resource=_resource, subscription=sub_info[\"subscription_id\"], tenant=None)\n",
    "# token_type, access_token, token = credential\n",
    "\n",
    "\n",
    "# subscription = sub_info[\"subscription_id\"]\n",
    "# tenant = sub_info[\"tenant_id\"]\n",
    "# rt = profile.get_refresh_token(resource=_resource, subscription=subscription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:39.124487Z",
     "start_time": "2020-10-05T10:51:39.110218Z"
    }
   },
   "outputs": [],
   "source": [
    "# Helper methods to refresh token if current one has expired\n",
    "# def get_token_refresh(credential, res_url):\n",
    "#     \"\"\"Get token closure - keeps az_api_creds cached\"\"\"\n",
    "#     az_api_creds = None\n",
    "#     context = AuthenticationContext(authority=f\"https://login.microsoftonline.com/{sub_info['tenant_id']}\")\n",
    "    \n",
    "#     def _get_token():\n",
    "#         nonlocal az_api_creds\n",
    "#         if (\n",
    "#             az_api_creds is None or\n",
    "#             pd.to_datetime(az_api_creds[\"expiresOn\"]) < datetime.now()\n",
    "#         ):\n",
    "#             az_api_creds = context.acquire_token_with_refresh_token(\n",
    "#                 credential[2][\"refreshToken\"],\n",
    "#                 credential[2][\"_clientId\"],\n",
    "#                 res_url\n",
    "#             )\n",
    "#         return az_api_creds.get(\"accessToken\")\n",
    "#     return _get_token\n",
    "\n",
    "\n",
    "# mgmt_url = 'https://management.azure.com/'\n",
    "# get_mgmt_token = get_token_refresh(credential, mgmt_url)\n",
    "\n",
    "# def get_api_headers():\n",
    "#     \"\"\"Return authorization header with current token.\"\"\"\n",
    "#     return {\n",
    "#         \"Authorization\": f\"Bearer {get_mgmt_token()}\",\n",
    "#         \"Content-Type\": \"application/json\",\n",
    "#     }\n",
    "                                    \n",
    "# def as_api_result_to_df(response):\n",
    "#     j_resp = response.json()\n",
    "#     if response.status_code != 200 or not j_resp or \"value\" not in j_resp:\n",
    "#         raise ValueError(\"No valid JSON result in response\")\n",
    "#     queries_raw_df = pd.DataFrame(j_resp[\"value\"])\n",
    "#     query_props_df = pd.json_normalize(queries_raw_df[\"properties\"])\n",
    "#     return pd.concat([queries_raw_df, query_props_df], axis=1).drop(columns=\"properties\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:39.140532Z",
     "start_time": "2020-10-05T10:51:39.128017Z"
    }
   },
   "outputs": [],
   "source": [
    "# res_group_url = f\"https://management.azure.com/subscriptions/{sub_info['subscription_id']}/resourceGroups/{sub_info['resource_group']}\"\n",
    "# prov_path = f\"/providers/Microsoft.OperationalInsights/workspaces/{sub_info['workspace_name']}\"\n",
    "# ss_path = \"/savedSearches\"\n",
    "# saved_searches_url = res_group_url + prov_path + ss_path\n",
    "\n",
    "# params = {'api-version': '2017-04-26-preview'}\n",
    "\n",
    "# r = requests.get(saved_searches_url, headers=get_api_headers(), params=params)\n",
    "\n",
    "# queries_df = as_api_result_to_df(r)\n",
    "# hunting_queries = queries_df[queries_df[\"Category\"] == \"Hunting Queries\"].copy()\n",
    "# invalid_chars = re.compile(r'[^A-Za-z0-9_]', flags=re.IGNORECASE)\n",
    "# hunting_queries[\"query_name\"] = hunting_queries[\"DisplayName\"].str.replace(invalid_chars, \"_\")\n",
    "\n",
    "# hunting_queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:39.151221Z",
     "start_time": "2020-10-05T10:51:39.144990Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# res_group_url = f\"https://management.azure.com/subscriptions/{sub_info['subscription_id']}/resourceGroups/{sub_info['resource_group']}\"\n",
    "# prov_path = f\"/providers/Microsoft.OperationalInsights/workspaces/{sub_info['workspace_name']}\"\n",
    "# ops_path = \"/providers/Microsoft.SecurityInsights/operations\"\n",
    "\n",
    "# alert_rules = \"/providers/Microsoft.SecurityInsights/alertRuleTemplates\"\n",
    "# alert_rules_url = res_group_url + prov_path + alert_rules\n",
    "# params = {'api-version': '2020-01-01'}\n",
    "\n",
    "# r = requests.get(alert_rules_url, headers=get_api_headers(), params=params)\n",
    "\n",
    "# alert_rules_df = as_api_result_to_df(r)\n",
    "# alert_rules_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Enrichment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YAML Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:40.685367Z",
     "start_time": "2020-10-05T10:51:39.153148Z"
    }
   },
   "outputs": [],
   "source": [
    "base_dir = path_wgt.value + \"/Azure-Sentinel-master\"\n",
    "detections_df = parse_yaml(parent_dir=base_dir, child_dir=\"Detections\")\n",
    "hunting_df = parse_yaml(parent_dir=base_dir, child_dir=\"Hunting Queries\")\n",
    "\n",
    "frames = [detections_df, hunting_df]\n",
    "sentinel_github_df = pd.concat(frames).reset_index()\n",
    "sentinel_github_df = sentinel_github_df.copy()\n",
    "sentinel_github_df[\"GithubURL\"] = sentinel_github_df[\"GithubURL\"].str.replace(\n",
    "    \" \", \"%20\", regex=True\n",
    ")\n",
    "sentinel_github_df[\"IngestedDate\"] = date.today()\n",
    "\n",
    "# Displaying basic statistics of yaml files\n",
    "display(HTML(\"<h3>Azure Sentinel Github Stats...</h3>\"))\n",
    "print(\n",
    "    f\"\"\"Total Queries in Azure Sentinel Github:: {len(sentinel_github_df)} \n",
    "    No of Detections :: {len(detections_df)} \n",
    "    No of Hunting Queries:: {len(hunting_df)}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:40.810509Z",
     "start_time": "2020-10-05T10:51:40.689632Z"
    }
   },
   "outputs": [],
   "source": [
    "result = clean_and_preprocess_data(df=sentinel_github_df)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrich with MITRE Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:44.924928Z",
     "start_time": "2020-10-05T10:51:40.814087Z"
    }
   },
   "outputs": [],
   "source": [
    "mitre_attack_df = get_mitre_matrix_flat()\n",
    "mitre_attack_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge preprocessed dataset with MITRE Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:44.982757Z",
     "start_time": "2020-10-05T10:51:44.927300Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "newdf = pd.merge(\n",
    "    result,\n",
    "    mitre_attack_df,\n",
    "    left_on=[\"relevantTechniques\"],\n",
    "    right_on=[\"technique_id_parsed\"],\n",
    "    how=\"outer\",\n",
    ")\n",
    "\n",
    "# Renaming columns\n",
    "newdf = newdf.rename(\n",
    "    columns={\n",
    "        \"matrix\": \"MITREMatrix\",\n",
    "        \"platform\": \"Platform\",\n",
    "        \"id\": \"DetectionId\",\n",
    "        \"name\": \"DetectionName\",\n",
    "        \"description\": \"DetectionDescription\",\n",
    "        \"connectorId\": \"ConnectorId\",\n",
    "        \"dataTypes\": \"DataTypes\",\n",
    "        \"severity\": \"DetectionSeverity\",\n",
    "        \"tactics\": \"Tactic\",\n",
    "        \"relevantTechniques\": \"TechniqueId\",\n",
    "        \"technique\": \"TechniqueName\",\n",
    "        \"query\": \"Query\",\n",
    "        \"queryFrequency\": \"QueryFrequency\",\n",
    "        \"queryPeriod\": \"QueryPeriod\",\n",
    "        \"triggerOperator\": \"TriggerOperator\",\n",
    "        \"triggerThreshold\": \"TriggerThreshold\",\n",
    "        \"GithubURL\": \"DetectionUrl\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Column Seletion and Ordering\n",
    "columns = [\n",
    "    \"MITREMatrix\",\n",
    "    \"Tactic\",\n",
    "    \"TechniqueId\",\n",
    "    \"TechniqueName\",\n",
    "    \"Platform\",\n",
    "    \"DetectionType\",\n",
    "    \"DetectionService\",\n",
    "    \"DetectionId\",\n",
    "    \"DetectionName\",\n",
    "    \"DetectionDescription\",\n",
    "    \"ConnectorId\",\n",
    "    \"DataTypes\",\n",
    "    \"Query\",\n",
    "    \"QueryFrequency\",\n",
    "    \"QueryPeriod\",\n",
    "    \"TriggerOperator\",\n",
    "    \"TriggerThreshold\",\n",
    "    \"DetectionSeverity\",\n",
    "    \"DetectionUrl\",\n",
    "    \"IngestedDate\",\n",
    "]\n",
    "newdf = newdf[columns]\n",
    "\n",
    "# Displaying top 10 records\n",
    "newdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:47.357724Z",
     "start_time": "2020-10-05T10:51:44.984952Z"
    }
   },
   "outputs": [],
   "source": [
    "#Export the whole dataset\n",
    "newdf.to_csv('output.csv', header=False, index=False)\n",
    "\n",
    "#Export the whole dataset with headers\n",
    "newdf.to_csv('output-with-header.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Detection list from Microsoft Platform Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:47.385942Z",
     "start_time": "2020-10-05T10:51:47.359861Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_azure_defender_alerts():\n",
    "    alerts_url = (\n",
    "        \"https://docs.microsoft.com/en-us/azure/security-center/alerts-reference\"\n",
    "    )\n",
    "    list_of_df = pd.read_html(alerts_url)\n",
    "    providers = [\n",
    "        \"Windows\",\n",
    "        \"Linux\",\n",
    "        \"Azure App Service\",\n",
    "        \"Azure Kubernetes Service clusters\",\n",
    "        \"Containers- Host Level\",\n",
    "        \"SQL Database and SQL Warehouse\",\n",
    "        \"Azure Storage\",\n",
    "        \"Azure Cosmos DB (Preview)\",\n",
    "        \"Azure Network Layer\",\n",
    "        \"Azure Resource Manager (Preview)\",\n",
    "        \"Azure Key Vault (Preview)\",\n",
    "        \"Azure DDoS Protection\",\n",
    "    ]\n",
    "    for i in range(12):\n",
    "        list_of_df[i][\"Provider\"] = providers[i]\n",
    "\n",
    "    # Clean-up dataset by renaming some columns\n",
    "    list_of_df[1] = list_of_df[1].rename(columns={\"Alert (Alert Type)\": \"Alert\"})\n",
    "    list_of_df[2] = list_of_df[2].rename(columns={\"Alert (Alert Type)\": \"Alert\"})\n",
    "\n",
    "    # Merge all the tables\n",
    "    frames = [\n",
    "        list_of_df[0],\n",
    "        list_of_df[1],\n",
    "        list_of_df[2],\n",
    "        list_of_df[3],\n",
    "        list_of_df[4],\n",
    "        list_of_df[5],\n",
    "        list_of_df[6],\n",
    "        list_of_df[7],\n",
    "        list_of_df[8],\n",
    "        list_of_df[9],\n",
    "        list_of_df[10],\n",
    "        list_of_df[11],\n",
    "    ]\n",
    "\n",
    "    azdefender_df = pd.concat(frames).reset_index().dropna().drop(\"index\", axis=1)\n",
    "\n",
    "    # Add and Rename columns\n",
    "    azdefender_df[\"Detection Service\"] = \"Azure Defender\"\n",
    "    azdefender_df = azdefender_df.rename(columns={\"Intent(Learn more)\": \"Tactic\"})\n",
    "    azdefender_df[[\"Alert\", \"Description\", \"Severity\", \"Provider\", \"Tactic\"]]\n",
    "\n",
    "    return azdefender_df\n",
    "\n",
    "\n",
    "def get_azure_ipc_alerts():\n",
    "    alerts_url = \"https://docs.microsoft.com/en-us/azure/active-directory/identity-protection/concept-identity-protection-risks\"\n",
    "    list_of_df = pd.read_html(alerts_url)\n",
    "\n",
    "    # Merge All dataframes\n",
    "    frames = (list_of_df[0], list_of_df[1], list_of_df[2])\n",
    "    aip_df = pd.concat(frames).reset_index().dropna().drop(\"index\", axis=1)\n",
    "\n",
    "    # Add and Rename columns\n",
    "    aip_df[\"Tactic\"] = \"N.A.\"\n",
    "    aip_df[\"Severity\"] = \"N.A.\"\n",
    "    aip_df[\"Provider\"] = \"N.A.\"\n",
    "    aip_df[\"Detection Service\"] = \"Azure Identity Proptection Center (IPC)\"\n",
    "    aip_df = aip_df.rename(columns={\"Risk detection\": \"Alert\"}).drop(\n",
    "        \"Detection type\", axis=1\n",
    "    )\n",
    "\n",
    "    return aip_df\n",
    "\n",
    "\n",
    "def get_azure_defender_identity_alerts():\n",
    "    alerts_url = \"https://docs.microsoft.com/en-us/azure-advanced-threat-protection/suspicious-activity-guide?tabs=external\"\n",
    "\n",
    "    list_of_df = pd.read_html(alerts_url)\n",
    "    atp_df = list_of_df[0].reset_index().dropna().drop(\"index\", axis=1)\n",
    "    atp_df[\"Description\"] = \"N.A.\"\n",
    "    atp_df[\"Provider\"] = \"N.A.\"\n",
    "\n",
    "    atp_df = atp_df.rename(\n",
    "        columns={\"Security alert name\": \"Alert\", \"MITRE ATT&CK Matrixâ¢\": \"Tactic\"}\n",
    "    ).drop(\"Unique external ID\", axis=1)\n",
    "    atp_df[\"Detection Service\"] = \"Microsoft Defender for Identity\"\n",
    "\n",
    "    atp_df = atp_df[\n",
    "        [\"Alert\", \"Description\", \"Tactic\", \"Severity\", \"Provider\", \"Detection Service\"]\n",
    "    ]\n",
    "\n",
    "    return atp_df\n",
    "\n",
    "\n",
    "def get_mcas_alerts():\n",
    "    alerts_url = (\n",
    "        \"https://docs.microsoft.com/en-us/cloud-app-security/investigate-anomaly-alerts\"\n",
    "    )\n",
    "\n",
    "    session = HTMLSession()\n",
    "\n",
    "    r = session.get(alerts_url)\n",
    "    mcas_df = pd.DataFrame(\n",
    "        re.findall(r\"<h3 id=.*>(.*)</h3>\", r.text), columns=[\"Alert\"]\n",
    "    )\n",
    "\n",
    "    mcas_df[\"Description\"] = \"N.A.\"\n",
    "\n",
    "    mcas_df[\"Tactic\"] = \"N.A.\"\n",
    "\n",
    "    for i in range(6):\n",
    "        mcas_df[\"Tactic\"][i] = \"InitialAccess\"\n",
    "    for i in range(6, 9):\n",
    "        mcas_df[\"Tactic\"][i] = \"Execution\"\n",
    "    for i in range(9, 13):\n",
    "        mcas_df[\"Tactic\"][i] = \"Persistence\"\n",
    "    mcas_df[\"Tactic\"][13] = \"PrivilegeEscalation\"\n",
    "    mcas_df[\"Tactic\"][14] = \"CredentialAccess\"\n",
    "    for i in range(15, 18):\n",
    "        mcas_df[\"Tactic\"][i] = \"Collection\"\n",
    "    for i in range(18, 21):\n",
    "        mcas_df[\"Tactic\"][i] = \"Exfiltration\"\n",
    "    for i in range(21, 24):\n",
    "        mcas_df[\"Tactic\"][i] = \"Impact\"\n",
    "\n",
    "    mcas_df[\"Severity\"] = \"N.A.\"\n",
    "    mcas_df[\"Provider\"] = \"N.A.\"\n",
    "    mcas_df[\"Detection Service\"] = \"Microsoft Cloud Application Security (MCAS)\"\n",
    "\n",
    "    return mcas_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure Defender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:48.347777Z",
     "start_time": "2020-10-05T10:51:47.387525Z"
    }
   },
   "outputs": [],
   "source": [
    "az_defender_alerts = get_azure_defender_alerts()\n",
    "az_defender_alerts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure Identity Protection Center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:48.643050Z",
     "start_time": "2020-10-05T10:51:48.349672Z"
    }
   },
   "outputs": [],
   "source": [
    "az_ipc_alerts = get_azure_ipc_alerts()\n",
    "az_ipc_alerts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure Defender for Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:48.895806Z",
     "start_time": "2020-10-05T10:51:48.644947Z"
    }
   },
   "outputs": [],
   "source": [
    "az_defender_for_identity_alerts = get_azure_defender_identity_alerts()\n",
    "az_defender_for_identity_alerts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Microsoft Cloud Application Security (MCAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:49.125173Z",
     "start_time": "2020-10-05T10:51:48.897620Z"
    }
   },
   "outputs": [],
   "source": [
    "mcas_df = get_mcas_alerts()\n",
    "mcas_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:49.144205Z",
     "start_time": "2020-10-05T10:51:49.127109Z"
    }
   },
   "outputs": [],
   "source": [
    "frames = [az_defender_alerts, az_ipc_alerts, az_defender_for_identity_alerts, mcas_df]\n",
    "msft_df = pd.concat(frames)\n",
    "msft_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:49.152713Z",
     "start_time": "2020-10-05T10:51:49.149613Z"
    }
   },
   "outputs": [],
   "source": [
    "Tactics = [\n",
    "    \"InitialAccess\",\n",
    "    \"Execution\",\n",
    "    \"Persistence\",\n",
    "    \"PrivilegeEscalation\",\n",
    "    \"DefenseEvasion\",\n",
    "    \"CredentialAccess\",\n",
    "    \"Discovery\",\n",
    "    \"LateralMovement\",\n",
    "    \"Collection\",\n",
    "    \"CommandAndControl\",\n",
    "    \"Exfiltration\",\n",
    "    \"Impact\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure Sentinel Alerts Table Viewer - Jupyter Widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:49.236012Z",
     "start_time": "2020-10-05T10:51:49.155799Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import qgrid\n",
    "\n",
    "columns = [\n",
    "    \"Tactic\",\n",
    "    \"TechniqueId\",\n",
    "    \"Platform\",\n",
    "    \"DetectionType\",\n",
    "    \"DetectionName\",\n",
    "    \"ConnectorId\",\n",
    "    \"DataTypes\",\n",
    "]\n",
    "\n",
    "df = newdf[columns].rename_axis(None)\n",
    "qgrid_widget = qgrid.show_grid(df, show_toolbar=True)\n",
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HeatMap - Tactics vs DataTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:49.570709Z",
     "start_time": "2020-10-05T10:51:49.239129Z"
    }
   },
   "outputs": [],
   "source": [
    "# Subset selection for valid Tactic valuies\n",
    "heatmap = newdf[newdf[\"Tactic\"].isin(Tactics)]\n",
    "\n",
    "# Plot HeatMap\n",
    "pd.crosstab(heatmap[\"ConnectorId\"], heatmap[\"Tactic\"]).style.background_gradient(\n",
    "    cmap=\"PuBuGn\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HeatMap - Tactics vs Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:50.345567Z",
     "start_time": "2020-10-05T10:51:49.572587Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot HeatMap\n",
    "pd.crosstab(heatmap[\"TechniqueName\"], heatmap[\"Tactic\"]).style.background_gradient(\n",
    "    cmap=\"PuBuGn\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATT&CK Navigator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Navigator Layer Json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:51.062844Z",
     "start_time": "2020-10-05T10:51:50.347862Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read csv file as input\n",
    "with open(\"output-with-header.csv\", \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    a = list(reader)\n",
    "\n",
    "# Creating set of Platforms and list of platforms\n",
    "platforms = []\n",
    "\n",
    "for t in a:\n",
    "    if t[\"Platform\"] not in platforms:\n",
    "        platforms.append(t[\"Platform\"])\n",
    "\n",
    "# remove empty platforms\n",
    "platforms.remove(\"\")\n",
    "\n",
    "# Empty Platform Data structure for Layer json file\n",
    "platforms_list = []\n",
    "\n",
    "for item in platforms:\n",
    "    platform_dict = dict()\n",
    "    platform_dict[item] = []\n",
    "    platforms_list.append(platform_dict)\n",
    "\n",
    "# Creating list of techniques per platfdorm and create Techniques data strcuture to iterate further\n",
    "for aplatform in platforms_list:\n",
    "    for ap, techniques_list in aplatform.items():\n",
    "        for t in a:\n",
    "            if ap == t[\"Platform\"]:\n",
    "                technique_dict = dict()\n",
    "                technique_dict[\"techniqueId\"] = t[\"TechniqueId\"]\n",
    "                technique_dict[\"DetectionName\"] = t[\"DetectionName\"]\n",
    "                technique_dict[\"DataTypes\"] = t[\"DataTypes\"]\n",
    "                if technique_dict not in techniques_list:\n",
    "                    techniques_list.append(technique_dict)\n",
    "\n",
    "# Code to Generate ATT&CK navigator Layer json file using Data Structures - Platforms and Techniques used\n",
    "for platform in platforms_list:\n",
    "    for k, v in platform.items():\n",
    "        technique_mappings = dict()\n",
    "        for technique in v:\n",
    "            metadata = dict()\n",
    "            metadata[\"name\"] = technique[\"DetectionName\"]\n",
    "            metadata[\"value\"] = technique[\"DataTypes\"]\n",
    "            if technique[\"techniqueId\"] not in technique_mappings:\n",
    "                technique_mappings[technique[\"techniqueId\"]] = []\n",
    "            if metadata not in technique_mappings[technique[\"techniqueId\"]]:\n",
    "                technique_mappings[technique[\"techniqueId\"]].append(metadata)\n",
    "\n",
    "        VERSION = \"3.0\"\n",
    "        NAME = \"{} Layer Json File for Azure Sentinel\".format(k)\n",
    "        DESCRIPTION = \"{} ATT&CK Matrix Coverage for Azure Sentinel\".format(k)\n",
    "        DOMAIN = \"mitre-enterprise\"\n",
    "        platform_layer = {\n",
    "            \"description\": DESCRIPTION,\n",
    "            \"name\": NAME,\n",
    "            \"domain\": DOMAIN,\n",
    "            \"version\": VERSION,\n",
    "            \"filters\": {\"stages\": [\"act\"], \"platforms\": [k]},\n",
    "            \"techniques\": [\n",
    "                {\"score\": 1, \"techniqueID\": k, \"metadata\": v}\n",
    "                for k, v in technique_mappings.items()\n",
    "            ],\n",
    "            \"gradient\": {\n",
    "                \"colors\": [\"#ffffff\", \"#66fff3\"],\n",
    "                \"minValue\": 0,\n",
    "                \"maxValue\": 1,\n",
    "            },\n",
    "            \"legendItems\": [{\"label\": \"Techniques researched\", \"color\": \"#66fff3\"}],\n",
    "        }\n",
    "        with open((\"./Json/{0}.json\".format(k)), \"w\") as f:\n",
    "            f.write(json.dumps(platform_layer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-09-09T16:36:21.494Z"
    }
   },
   "source": [
    "####  ATT&CK Navigator Embedded View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:51.070414Z",
     "start_time": "2020-10-05T10:51:51.064666Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# AWS ATT&CK Coverage\n",
    "import IPython\n",
    "\n",
    "iframe = '<iframe src=\"https://mitre-attack.github.io/attack-navigator/enterprise/#layerURL=https://raw.githubusercontent.com/ashwin-patil/msft-mitreattack/main/Azure%20Sentinel/ATT%26CK-Navigator-layers/Azure.json&tabs=false&selecting_techniques=false\" width=\"1000\" height=\"400\"></iframe>'\n",
    "IPython.display.HTML(iframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radar Plots using Plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:51.246643Z",
     "start_time": "2020-10-05T10:51:51.071898Z"
    }
   },
   "outputs": [],
   "source": [
    "output_df = pd.read_csv(\"output-with-header.csv\")\n",
    "\n",
    "Tactics = [\n",
    "    \"InitialAccess\",\n",
    "    \"Execution\",\n",
    "    \"Persistence\",\n",
    "    \"PrivilegeEscalation\",\n",
    "    \"DefenseEvasion\",\n",
    "    \"CredentialAccess\",\n",
    "    \"Discovery\",\n",
    "    \"LateralMovement\",\n",
    "    \"Collection\",\n",
    "    \"CommandAndControl\",\n",
    "    \"Exfiltration\",\n",
    "    \"Impact\",\n",
    "]\n",
    "\n",
    "df_plot = (\n",
    "    output_df[[\"Tactic\", \"DetectionType\", \"DetectionName\"]]\n",
    "    .dropna()\n",
    "    .groupby([\"Tactic\", \"DetectionType\"])[\"DetectionName\"]\n",
    "    .nunique()\n",
    "    .reset_index(level=[0, 1])\n",
    ")\n",
    "df_plot = df_plot.rename(columns={\"DetectionName\": \"Count\"})\n",
    "df_plot = df_plot[df_plot[\"Tactic\"].isin(Tactics)]\n",
    "df_stats = df_plot.pivot(index=\"Tactic\", columns=\"DetectionType\", values=\"Count\")\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:51.254523Z",
     "start_time": "2020-10-05T10:51:51.248596Z"
    }
   },
   "outputs": [],
   "source": [
    "hunting_count=[]\n",
    "detection_count=[]\n",
    "for tactic in Tactics:\n",
    "    detection_count.append(df_stats.loc[tactic,'Detections'])\n",
    "    hunting_count.append(df_stats.loc[tactic,'Hunting Queries'])\n",
    "    \n",
    "print(detection_count)\n",
    "print(hunting_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Radar Plot Per Detection Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:52.956374Z",
     "start_time": "2020-10-05T10:51:51.256605Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatterpolar(\n",
    "      r=detection_count,\n",
    "      theta=Tactics,\n",
    "      fill='toself',\n",
    "      name='Detections'\n",
    "))\n",
    "fig.add_trace(go.Scatterpolar(\n",
    "      r=hunting_count,\n",
    "      theta=Tactics,\n",
    "      fill='toself',\n",
    "      name='Hunting Queries'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "  polar=dict(\n",
    "    radialaxis=dict(\n",
    "      visible=True\n",
    "    )),\n",
    "    height=600, width=800,\n",
    "  showlegend=True,\n",
    "  title=\"MITRE ATT&CK Coverage for Azure Sentinel\", title_x=0.5\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MITRE ATT&CK Stats by Platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:52.984903Z",
     "start_time": "2020-10-05T10:51:52.957865Z"
    }
   },
   "outputs": [],
   "source": [
    "df_platform = (\n",
    "    output_df[[\"Tactic\", \"Platform\", \"DetectionName\"]]\n",
    "    .dropna()\n",
    "    .groupby([\"Tactic\", \"Platform\"])[\"DetectionName\"]\n",
    "    .nunique()\n",
    "    .reset_index(level=[0, 1])\n",
    ")\n",
    "df_platform = df_platform.rename(columns={\"DetectionName\": \"Count\"})\n",
    "df_platform = df_platform[df_platform[\"Tactic\"].isin(Tactics)]\n",
    "df_platform = (\n",
    "    df_platform.pivot(index=\"Tactic\", columns=\"Platform\", values=\"Count\")\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    ")\n",
    "df_platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:52.996347Z",
     "start_time": "2020-10-05T10:51:52.986446Z"
    }
   },
   "outputs": [],
   "source": [
    "aws=[]\n",
    "azure=[]\n",
    "azuread=[]\n",
    "o365=[]\n",
    "windows=[]\n",
    "linux=[]\n",
    "for tactic in Tactics:\n",
    "    aws.append(df_platform.loc[tactic,'AWS'])\n",
    "    azure.append(df_platform.loc[tactic,'Azure'])\n",
    "    azuread.append(df_platform.loc[tactic,'Azure AD'])\n",
    "    o365.append(df_platform.loc[tactic,'Office 365'])\n",
    "    windows.append(df_platform.loc[tactic,'Windows'])\n",
    "    linux.append(df_platform.loc[tactic,'Linux'])\n",
    "print(detection_count)\n",
    "print(hunting_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Radar plot with Subplots per Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:53.426553Z",
     "start_time": "2020-10-05T10:51:52.998084Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "\n",
    "fig = make_subplots(rows=3, cols=2,\n",
    "                    specs=[[{'type': 'polar'},    {'type': 'polar'}],\n",
    "                           [{'type': 'polar'}, {'type': 'polar'}],\n",
    "                          [{'type': 'polar'}, {'type': 'polar'}]])\n",
    "\n",
    "fig.add_traces(\n",
    "    [go.Scatterpolar(r=aws, theta=Tactics, fill='toself', name='AWS'),\n",
    "    go.Scatterpolar(r=azure, theta=Tactics, fill='toself', name='Azure'),\n",
    "    go.Scatterpolar(r=azuread, theta=Tactics, fill='toself', name='Azure AD'),\n",
    "    go.Scatterpolar(r=o365, theta=Tactics, fill='toself', name='Office 365'),\n",
    "    go.Scatterpolar(r=windows, theta=Tactics, fill='toself', name='AWS'),\n",
    "    go.Scatterpolar(r=linux, theta=Tactics, fill='toself', name='AWS')\n",
    "    ],\n",
    "    rows=[1, 1, 2, 2, 3, 3],\n",
    "    cols=[1, 2, 1, 2, 1, 2]\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "  polar=dict(\n",
    "    radialaxis=dict(\n",
    "      visible=True\n",
    "    )),\n",
    "  height=1200, width=1000,\n",
    "  showlegend=True,\n",
    "  title=\"MITRE ATT&CK Coverage Per Platform\", title_x=0.5\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Radar plot (Consolidated for All Platforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:53.593929Z",
     "start_time": "2020-10-05T10:51:53.428461Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatterpolar(\n",
    "      r=aws,\n",
    "      theta=Tactics,\n",
    "      fill='toself',\n",
    "      name='AWS'\n",
    "     ))\n",
    "\n",
    "fig.add_trace(go.Scatterpolar(\n",
    "      r=azure,\n",
    "      theta=Tactics,\n",
    "      fill='toself',\n",
    "      name='Azure'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatterpolar(\n",
    "      r=azuread,\n",
    "      theta=Tactics,\n",
    "      fill='toself',\n",
    "      name='Azure AD'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatterpolar(\n",
    "      r=o365,\n",
    "      theta=Tactics,\n",
    "      fill='toself',\n",
    "      name='Office 365'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatterpolar(\n",
    "      r=windows,\n",
    "      theta=Tactics,\n",
    "      fill='toself',\n",
    "      name='Windows'\n",
    "\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatterpolar(\n",
    "      r=linux,\n",
    "      theta=Tactics,\n",
    "      fill='toself',\n",
    "      name='Linux'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "  polar=dict(\n",
    "    radialaxis=dict(\n",
    "      visible=True\n",
    "    )),\n",
    "  height=600, width=800,\n",
    "  showlegend=True,\n",
    "  title=\"MITRE ATT&CK Coverage Per Platform\", title_x=0.5\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Detections from Microsoft Platform Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:53.721018Z",
     "start_time": "2020-10-05T10:51:53.595628Z"
    }
   },
   "outputs": [],
   "source": [
    "msft_df_tactics = (\n",
    "    msft_df.groupby(\"Detection Service\")[\"Alert\"]\n",
    "    .nunique()\n",
    "    .to_frame(name=\"count\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "labels = msft_df_tactics[\"Detection Service\"]\n",
    "values = msft_df_tactics[\"count\"]\n",
    "\n",
    "# Use `hole` to create a donut-like pie chart\n",
    "fig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=0.4)])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:53.860770Z",
     "start_time": "2020-10-05T10:51:53.722523Z"
    }
   },
   "outputs": [],
   "source": [
    "msft_df_providers = (\n",
    "    msft_df[msft_df[\"Provider\"] != \"N.A.\"]\n",
    "    .groupby(\"Provider\")[\"Alert\"]\n",
    "    .nunique()\n",
    "    .to_frame(name=\"count\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "labels = msft_df_providers[\"Provider\"]\n",
    "values = msft_df_providers[\"count\"]\n",
    "\n",
    "fig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=0.3)])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:53.876191Z",
     "start_time": "2020-10-05T10:51:53.862910Z"
    }
   },
   "outputs": [],
   "source": [
    "#export the final results\n",
    "msft_df.to_csv('msft-consolidated.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Results to Azure Sentinel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:53.886480Z",
     "start_time": "2020-10-05T10:51:53.878153Z"
    }
   },
   "outputs": [],
   "source": [
    "la_ws_id = widgets.Text(description='Workspace ID:')\n",
    "la_ws_key = widgets.Password(description='Workspace Key:')\n",
    "display(la_ws_id)\n",
    "display(la_ws_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T10:51:53.893554Z",
     "start_time": "2020-10-05T10:51:53.888375Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate our Uploader\n",
    "la_up = LAUploader(workspace=la_ws_id.value, workspace_secret=la_ws_key.value, debug=True)\n",
    "\n",
    "# Upload dataframe\n",
    "la_up.upload_df(data=newdf, table_name='AzSentinelMITRE')\n",
    "la_up.upload_df(data=msft_df, table_name='MSFTAlerts')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "422px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
