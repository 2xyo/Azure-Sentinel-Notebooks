{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title: Office 365 Explorer\n",
    "&lt;details&gt;\n",
    "    <summary> <u>Details...</u></summary>\n",
    "**Notebook Version:** 1.0<br>\n",
    "**Python Version:** Python 3.6 (including Python 3.6 - AzureML)<br>\n",
    "**Required Packages**: kqlmagic, msticpy, pandas, numpy, matplotlib, seaborn, ipywidgets, ipython, scikit_learn, folium, maxminddb_geolite2<br>\n",
    "**Platforms Supported**:\n",
    "- Azure Notebooks Free Compute\n",
    "- Azure Notebooks DSVM\n",
    "- OS Independent\n",
    "\n",
    "**Data Sources Required**:\n",
    "- Log Analytics - OfficeActivity, IPLocation, Azure Network Analytics\n",
    "\n",
    "&lt;/details&gt;\n",
    "\n",
    "Brings together a series of queries and visualizations to help you investigate the security status of Office 365 subscription and individual user activities.\n",
    "- The first section focuses on Tenant-Wide data queries and analysis\n",
    "- The second section allows you to focus on individial accounts and examine them for any suspicious activity.\n",
    "\n",
    "This notebook is intended to be illustrative of the types of data available in Office 365 Activity data and how to query and use them. It is not meant to be used as a prescriptive guide to how to navigate through the data. \n",
    "<br> Feel free to experiment and submit anything interesting you find to the community."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>\n",
    "# Table of Contents\n",
    "- [Setup and Authenticate](#setup)\n",
    "- [Office 365 Activity](#o365)\n",
    "  - [Tenant-wide Information](#tenant_info)\n",
    "    - [AAD Operations - Account Modifications](#aad_ops)\n",
    "    - [Logon Anomalies](#logon_anomalies)\n",
    "    - [Activity Summary](#activity_summary)\n",
    "    - [Variability of IP Address for users](#ip_variability)\n",
    "    - [Accounts with multiple IPs and Geolocations](#acct_multi_geo)\n",
    "    - [User Logons with &gt; N IP Address](#acct_multi_ips)\n",
    "    - [Operation Types by Location and IP](#ip_op_matrix)\n",
    "    - [Geolocation Map of Client IPs](#geo_map_tenant)\n",
    "    - [Distinct User Agent Strings in Use](#distinct_uas)\n",
    "    - [Graphical Activity Timeline](#op_timeline)\n",
    "    - [Users With largest Activity Type Count](#user_activity_counts)\n",
    "  - [Office User Investigation](#o365_user_inv)\n",
    "    - [Activity Summary](#user_act_summary)\n",
    "    - [Operation Breakdown for User](#user_op_count)\n",
    "    - [IP Count for Different User Operations](#user_ip_counts)\n",
    "    - [Activity Timeline](#user_act_timeline)\n",
    "    - [User IP GeoMap](#user_geomap)\n",
    "    - [Check for User IPs in Azure Network Flow Data](#ips_in_azure)\n",
    "  - [Rare Combinations of Country/UserAgent/Operation Type](#o365_cluster)\n",
    "- [Appendices](#appendices)\n",
    "  - [Saving data to Excel](#appendices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Notebook initialization\n",
    "The next cell:\n",
    "- Checks for the correct Python version\n",
    "- Checks versions and optionally installs required packages\n",
    "- Imports the required packages into the notebook\n",
    "- Sets a number of configuration options.\n",
    "\n",
    "This should complete without errors. If you encounter errors or warnings look at the following two notebooks:\n",
    "- [TroubleShootingNotebooks](https://github.com/Azure/Azure-Sentinel-Notebooks/blob/master/TroubleShootingNotebooks.ipynb)\n",
    "- [ConfiguringNotebookEnvironment](https://github.com/Azure/Azure-Sentinel-Notebooks/blob/master/ConfiguringNotebookEnvironment.ipynb)\n",
    "\n",
    "If you are running in the Azure Sentinel Notebooks environment (Azure Notebooks or Azure ML) you can run live versions of these notebooks:\n",
    "- [Run TroubleShootingNotebooks](./TroubleShootingNotebooks.ipynb)\n",
    "- [Run ConfiguringNotebookEnvironment](./ConfiguringNotebookEnvironment.ipynb)\n",
    "\n",
    "You may also need to do some additional configuration to successfully use functions such as Threat Intelligence service lookup and Geo IP lookup. \n",
    "There are more details about this in the `ConfiguringNotebookEnvironment` notebook and in these documents:\n",
    "- [msticpy configuration](https://msticpy.readthedocs.io/en/latest/getting_started/msticpyconfig.html)\n",
    "- [Threat intelligence provider configuration](https://msticpy.readthedocs.io/en/latest/data_acquisition/TIProviders.html#configuration-file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T00:58:22.794036Z",
     "start_time": "2020-05-16T00:58:18.510870Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "REQ_PYTHON_VER=(3, 6)\n",
    "REQ_MSTICPY_VER=(0, 5, 0)\n",
    "\n",
    "display(HTML(\"<h3>Starting Notebook setup...</h3>\"))\n",
    "if Path(\"./utils/nb_check.py\").is_file():\n",
    "    from utils.nb_check import check_python_ver, check_mp_ver\n",
    "\n",
    "    check_python_ver(min_py_ver=REQ_PYTHON_VER)\n",
    "    try:\n",
    "        check_mp_ver(min_msticpy_ver=REQ_MSTICPY_VER)\n",
    "    except ImportError:\n",
    "        !pip install --upgrade msticpy\n",
    "        if \"msticpy\" in sys.modules:\n",
    "            importlib.reload(msticpy)\n",
    "        else:\n",
    "            import msticpy\n",
    "        check_mp_ver(REQ_PYTHON_VER)\n",
    "            \n",
    "from msticpy.nbtools import nbinit\n",
    "extra_imports = [\n",
    "    \"dns, reversename\",\n",
    "    \"dns, resolver\",\n",
    "    \"ipwhois, IPWhois\",\n",
    "    \"msticpy.sectools.ip_utils, get_ip_type\",\n",
    "    \"msticpy.sectools.ip_utils, get_whois_info\",\n",
    "]\n",
    "nbinit.init_notebook(\n",
    "    namespace=globals(),\n",
    "    extra_imports=extra_imports,\n",
    ");\n",
    "WIDGET_DEFAULTS = {\n",
    "    \"layout\": widgets.Layout(width=\"95%\"),\n",
    "    \"style\": {\"description_width\": \"initial\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove"
    ]
   },
   "source": [
    "### Get WorkspaceId and Authenticate to Log Analytics \n",
    "&lt;details&gt;\n",
    "    <summary> <u>Details...</u></summary>\n",
    "If you are using user/device authentication, run the following cell. \n",
    "- Click the 'Copy code to clipboard and authenticate' button.\n",
    "- This will pop up an Azure Active Directory authentication dialog (in a new tab or browser window). The device code will have been copied to the clipboard. \n",
    "- Select the text box and paste (Ctrl-V/Cmd-V) the copied value. \n",
    "- You should then be redirected to a user authentication page where you should authenticate with a user account that has permission to query your Log Analytics workspace.\n",
    "\n",
    "Use the following syntax if you are authenticating using an Azure Active Directory AppId and Secret:\n",
    "```\n",
    "%kql loganalytics://tenant(aad_tenant).workspace(WORKSPACE_ID).clientid(client_id).clientsecret(client_secret)\n",
    "```\n",
    "instead of\n",
    "```\n",
    "%kql loganalytics://code().workspace(WORKSPACE_ID)\n",
    "```\n",
    "\n",
    "Note: you may occasionally see a JavaScript error displayed at the end of the authentication - you can safely ignore this.<br>\n",
    "On successful authentication you should see a ```popup schema``` button.\n",
    "To find your Workspace Id go to [Log Analytics](https://ms.portal.azure.com/#blade/HubsExtension/Resources/resourceType/Microsoft.OperationalInsights%2Fworkspaces). Look at the workspace properties to find the ID.\n",
    "&lt;/details&gt;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T00:57:50.958560Z",
     "start_time": "2020-05-16T00:57:50.945560Z"
    }
   },
   "outputs": [],
   "source": [
    "# To list configured workspaces run WorkspaceConfig.list_workspaces()\n",
    "# WorkspaceConfig.list_workspaces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:07:40.087301Z",
     "start_time": "2020-05-16T00:58:30.041315Z"
    },
    "tags": [
     "todo"
    ]
   },
   "outputs": [],
   "source": [
    "# Authentication\n",
    "ws_config = WorkspaceConfig()\n",
    "qry_prov = QueryProvider(data_environment=\"LogAnalytics\")\n",
    "qry_prov.connect(connection_str=ws_config.code_connect_str)\n",
    "table_index = qry_prov.schema_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "# Office 365 Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Analytics Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T00:13:44.706841Z",
     "start_time": "2020-05-16T00:13:44.691841Z"
    }
   },
   "outputs": [],
   "source": [
    "if 'OfficeActivity' not in table_index:\n",
    "    display(Markdown('<font color=\"red\"><h2>Warning. Office Data not available.</h2></font><br>'\n",
    "                     'Either Office 365 data has not been imported into the workspace or'\n",
    "                     ' the OfficeActivity table is empty.<br>'\n",
    "                     'This workbook is not useable with the current workspace.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:49:50.212900Z",
     "start_time": "2020-05-16T01:49:50.137902Z"
    }
   },
   "outputs": [],
   "source": [
    "# set the origin time to the time of our alert\n",
    "md(\"For large O365 user bases, use short time ranges to keep the query times reasonable.\")\n",
    "o365_query_times = nbwidgets.QueryTime(\n",
    "    units='hours', before=6, after=0, max_before=72, max_after=12)\n",
    "o365_query_times.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:52:48.738859Z",
     "start_time": "2020-05-16T01:52:48.733859Z"
    }
   },
   "outputs": [],
   "source": [
    "# Queries\n",
    "office_ops_query = '''\n",
    "OfficeActivity\n",
    "| where TimeGenerated >= datetime({start})\n",
    "| where TimeGenerated <= datetime({end})\n",
    "| where UserType == 'Regular'\n",
    "'''\n",
    "\n",
    "office_ops_summary_query = '''\n",
    "OfficeActivity \n",
    "| where TimeGenerated >= datetime({start})\n",
    "| where TimeGenerated <= datetime({end})\n",
    "| where UserType == 'Regular'\n",
    "| extend RecordOp = strcat(RecordType, '-', Operation)\n",
    "| summarize OperationCount=count() by RecordType, Operation, UserId, UserAgent, ClientIP, bin(TimeGenerated, 1h)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "## Tenant-wide Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "### Summary of O365 Activity Types\n",
    "#### <font>Warning this query can be time consuming for large O365 subscriptions</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:52:58.127604Z",
     "start_time": "2020-05-16T01:52:52.998622Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Getting data...', end=' ')\n",
    "o365_query = office_ops_summary_query.format(start = o365_query_times.start, \n",
    "                                             end=o365_query_times.end)\n",
    "%kql -query o365_query\n",
    "office_ops_summary_df = _kql_raw_result_.to_dataframe()\n",
    "print('done.')\n",
    "(office_ops_summary_df\n",
    " .assign(UserId = lambda x: x.UserId.str.lower())\n",
    " .groupby(['RecordType', 'Operation'])\n",
    " .aggregate({'ClientIP': 'nunique',\n",
    "             'UserId': 'nunique',\n",
    "             'OperationCount': 'sum'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "### Variability of IP Address for users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:17:05.322665Z",
     "start_time": "2020-05-16T01:17:05.298668Z"
    }
   },
   "outputs": [],
   "source": [
    "unique_ip_op_ua = (\n",
    "    office_ops_summary_df.assign(UserId = lambda x: x.UserId.str.lower())\n",
    "    .groupby(['UserId', 'Operation'])\n",
    "    .aggregate({'ClientIP': 'nunique', 'OperationCount': 'sum'})\n",
    "    .reset_index()\n",
    "    .rename(columns={\"ClientIP\": \"ClientIPCount\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:21:12.670387Z",
     "start_time": "2020-05-16T01:21:03.701387Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "multi_ip_users = unique_ip_op_ua[unique_ip_op_ua[\"ClientIPCount\"] > 1]\n",
    "if len(unique_ip_op_ua) > 0:\n",
    "    height = max(math.log10(len(multi_ip_users.UserId.unique())) * 10, 8)\n",
    "    aspect = 10 / height\n",
    "    user_ip_op = sns.catplot(x=\"ClientIPCount\", y=\"UserId\", hue='Operation', data=multi_ip_users, height=height, aspect=aspect)\n",
    "    md('Variability of IP Address Usage by user')\n",
    "else:\n",
    "    md('No IP Addresses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "### Accounts with multiple IPs and Geolocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:26:11.150486Z",
     "start_time": "2020-05-16T01:26:10.871487Z"
    }
   },
   "outputs": [],
   "source": [
    "iplocation = GeoLiteLookup()\n",
    "restrict_cols = ['RecordType', 'TimeGenerated', 'Operation',\n",
    "                 'UserId', 'ClientIP', 'UserAgent']\n",
    "office_ops_summary = office_ops_summary_df[restrict_cols].assign(UserId = lambda x: x.UserId.str.lower())\n",
    "unique_ip_op_ua['ClientIPCount'] = unique_ip_op_ua['ClientIPCount']\n",
    "office_ops_merged = pd.merge(unique_ip_op_ua.query('ClientIPCount > 1').drop(columns='ClientIPCount'), \n",
    "                             office_ops_summary,\n",
    "                             on=['UserId', 'Operation'])\n",
    "\n",
    "if not office_ops_merged.empty:\n",
    "    client_ips = (\n",
    "        office_ops_merged\n",
    "        .query('ClientIP != \"<null>\" & ClientIP != \"\"')['ClientIP']\n",
    "        .drop_duplicates()\n",
    "        .tolist()\n",
    "    )\n",
    "    ip_entities = []\n",
    "    for ip in client_ips:\n",
    "        ip_entity = entities.IpAddress(Address=ip)\n",
    "        iplocation.lookup_ip(ip_entity=ip_entity)\n",
    "        if ip_entity.Location:\n",
    "            ip_dict = {'Address': ip_entity.Address}\n",
    "            ip_dict.update(ip_entity.Location.properties)\n",
    "            ip_entities.append(pd.Series(ip_dict))\n",
    "\n",
    "    ip_locs_df = pd.DataFrame(data=ip_entities)\n",
    "    ip_locs_df\n",
    "\n",
    "    office_ops_summary_ip_loc = pd.merge(office_ops_merged, \n",
    "                                         ip_locs_df, left_on='ClientIP', \n",
    "                                         right_on='Address', how='left')\n",
    "\n",
    "    display(\n",
    "        office_ops_summary_ip_loc\n",
    "        .groupby(['UserId', 'CountryCode', 'City'])\n",
    "        .aggregate({'ClientIP': 'nunique', 'OperationCount': 'sum'})\n",
    "        .reset_index()\n",
    "        .sort_values(\"ClientIP\", ascending=False)\n",
    "        .query(\"ClientIP > 1\")\n",
    "    )\n",
    "else:\n",
    "    md(\"No operations with > 1 IP Address\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "### Choose threshold to show User Logons where User has logged on from &gt; N IP Address in period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:26:26.039785Z",
     "start_time": "2020-05-16T01:26:26.025787Z"
    }
   },
   "outputs": [],
   "source": [
    "th_wgt = widgets.IntSlider(value=1, min=1, max=50, step=1, description='Set IP Count Threshold', **WIDGET_DEFAULTS)\n",
    "th_wgt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "### Matrix of Selected Operation Types by Location and IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:27:22.043604Z",
     "start_time": "2020-05-16T01:26:39.421506Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Getting data...', end=' ')\n",
    "o365_query = office_ops_query.format(start=o365_query_times.start, \n",
    "                                     end=o365_query_times.end)\n",
    "# %kql -query o365_query\n",
    "# office_ops_df = _kql_raw_result_.to_dataframe()\n",
    "office_ops_df = qry_prov.exec_query(o365_query)\n",
    "print('done.') \n",
    "\n",
    "# Get Locations for distinct IPs\n",
    "client_ips = office_ops_df.query('ClientIP != \"<null>\" & ClientIP != \"\"')['ClientIP'].drop_duplicates().tolist()\n",
    "ip_entities = []\n",
    "for ip in client_ips:\n",
    "    ip_entity = entities.IpAddress(Address=ip)\n",
    "    iplocation.lookup_ip(ip_entity=ip_entity)\n",
    "    if ip_entity.Location:\n",
    "        ip_dict = {'Address': ip_entity.Address}\n",
    "        ip_dict.update(ip_entity.Location.properties)\n",
    "        ip_entities.append(pd.Series(ip_dict))\n",
    "\n",
    "ip_locs_df = pd.DataFrame(data=ip_entities)\n",
    "\n",
    "# Get rid of unneeded columns\n",
    "restrict_cols = ['OfficeId', 'RecordType', 'TimeGenerated', 'Operation',\n",
    "                 'OrganizationId', 'UserType', 'UserKey', 'OfficeWorkload',\n",
    "                 'ResultStatus', 'OfficeObjectId', 'UserId', 'ClientIP',\n",
    "                 'ActorIpAddress', 'UserAgent']\n",
    "office_ops_restr = office_ops_df[restrict_cols]\n",
    "\n",
    "if client_ips:\n",
    "    # Merge main DF with IP location data\n",
    "    office_ops_locs = pd.merge(\n",
    "        office_ops_restr,\n",
    "        ip_locs_df,\n",
    "        how='right',\n",
    "        left_on='ClientIP',\n",
    "        right_on='Address',\n",
    "        indicator=True\n",
    "    )\n",
    "\n",
    "    limit_op_types = ['FileDownloaded', 'FileModified','FileUploaded',\n",
    "                      'MailboxLogin']\n",
    "\n",
    "    office_ops_locs = office_ops_locs[office_ops_locs.Operation.isin(limit_op_types)]\n",
    "\n",
    "    # Calculate operations grouped by location and operation type\n",
    "    cm = sns.light_palette(\"yellow\", as_cmap=True)\n",
    "    country_by_op_count = (office_ops_locs[['Operation', 'RecordType', 'CountryCode', 'City']]\n",
    "                            .groupby(['CountryCode', 'City', 'Operation'])\n",
    "                            .count())\n",
    "    display(country_by_op_count.unstack().fillna(0).rename(columns={'RecordType':'OperationCount'}))\n",
    "    #         .style.background_gradient(cmap=cm))\n",
    "\n",
    "    # Group by Client IP, Country, Operation\n",
    "    clientip_by_op_count = (office_ops_locs[['ClientIP', 'Operation', 'RecordType', 'CountryCode']]\n",
    "                            .groupby(['ClientIP', 'CountryCode', 'Operation'])\n",
    "                            .count())\n",
    "\n",
    "    (clientip_by_op_count.unstack().fillna(0).rename(columns={'RecordType':'OperationCount'}))\n",
    "    #  .style.background_gradient(cmap=cm))\n",
    "else:\n",
    "    md(\"No client IPs found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "### Geolocation Map of Client IPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:27:44.018242Z",
     "start_time": "2020-05-16T01:27:42.735241Z"
    }
   },
   "outputs": [],
   "source": [
    "from msticpy.nbtools.foliummap import FoliumMap\n",
    "folium_map = FoliumMap(zoom_start=3)\n",
    "\n",
    "def get_row_ip_loc(row):\n",
    "    try:\n",
    "        _, ip_entity = iplocation.lookup_ip(ip_address=row.ClientIP)\n",
    "        return ip_entity\n",
    "    except ValueError:\n",
    "        return None\n",
    "    \n",
    "off_ip_locs = (office_ops_df[['ClientIP']]\n",
    "                   .drop_duplicates()\n",
    "                   .apply(get_row_ip_loc, axis=1)\n",
    "                   .tolist())\n",
    "ip_locs = [ip_list[0] for ip_list in off_ip_locs if ip_list]\n",
    "    \n",
    "display(HTML('<h3>External IP Addresses seen in Office Activity</h3>'))\n",
    "display(HTML('Numbered circles indicate multiple items - click to expand.'))\n",
    "\n",
    "\n",
    "icon_props = {'color': 'purple'}\n",
    "folium_map.add_ip_cluster(ip_entities=ip_locs,\n",
    "                          **icon_props)\n",
    "folium_map.center_map()\n",
    "display(folium_map.folium_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "### Graphical Activity Timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:27:55.044908Z",
     "start_time": "2020-05-16T01:27:51.212910Z"
    }
   },
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    display(Markdown('### Change in rate of Activity Class (RecordType) and Operation'))\n",
    "    sns.relplot(data=office_ops_summary_df, x='TimeGenerated', y='OperationCount', kind='line', aspect=2, \n",
    "                hue='RecordType')\n",
    "    sns.relplot(data=office_ops_summary_df.query('RecordType == \"SharePointFileOperation\"'), \n",
    "                x='TimeGenerated', y='OperationCount', hue='Operation', kind='line', aspect=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "### Users With largest Activity Type Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:35:06.031920Z",
     "start_time": "2020-05-16T01:35:05.353920Z"
    }
   },
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    display(Markdown('### Identify Users/IPs with largest operation count'))\n",
    "    office_ops = (\n",
    "        office_ops_summary_df\n",
    "        .query(\"OperationCount > 5\")\n",
    "        .assign(\n",
    "            Account=lambda x: (x.UserId.str.extract('([^@]+)@.*', expand=False)).str.lower())\n",
    "        .sort_values(\"OperationCount\", ascending=False)\n",
    "    )\n",
    "    limit_op_types = ['FileDownloaded', 'FileModified','FileUploaded',\n",
    "                      'MailboxLogin']\n",
    "    office_ops = office_ops[office_ops.Operation.isin(limit_op_types)]\n",
    "    \n",
    "    sns.catplot(data=office_ops, y='Account', x='OperationCount', \n",
    "                hue='Operation', aspect=2)\n",
    "    display(office_ops.pivot_table('OperationCount', index=['Account'], \n",
    "                                   columns='Operation')) #.style.bar(color='orange', align='mid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:35:21.811305Z",
     "start_time": "2020-05-16T01:35:21.567307Z"
    }
   },
   "outputs": [],
   "source": [
    "off_ops_df = office_ops_df[['OfficeId', 'RecordType', 'TimeGenerated', 'Operation',\n",
    "       'OrganizationId', 'UserType', 'UserKey', 'OfficeWorkload',\n",
    "       'ResultStatus', 'OfficeObjectId', 'UserId', 'ClientIP','UserAgent']]\n",
    "(pd.merge(off_ops_df, ip_locs_df, how='left', left_on='ClientIP', right_on='Address')\n",
    " [['TimeGenerated', 'Operation', 'RecordType', 'OfficeWorkload',\n",
    "   'ResultStatus', 'UserId', 'ClientIP', 'UserAgent', 'CountryCode',\n",
    "   'CountryName', 'State', 'City', 'Longitude', 'Latitude'\n",
    "  ]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "## Office User Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:35:36.322501Z",
     "start_time": "2020-05-16T01:35:36.272495Z"
    }
   },
   "outputs": [],
   "source": [
    "# set the origin time to the time of our alert\n",
    "o365_query_times_user = nbwidgets.QueryTime(units='days',\n",
    "                           before=10, after=1, max_before=60, max_after=20, auto_display=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:35:42.273892Z",
     "start_time": "2020-05-16T01:35:42.112892Z"
    }
   },
   "outputs": [],
   "source": [
    "distinct_users = office_ops_df[['UserId']].sort_values('UserId')['UserId'].str.lower().drop_duplicates().tolist()\n",
    "distinct_users\n",
    "user_select = nbwidgets.SelectString(description='Select User Id', item_list=distinct_users, auto_display=True)\n",
    "                               # (items=distinct_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "### Activity Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:36:57.613215Z",
     "start_time": "2020-05-16T01:36:28.890742Z"
    }
   },
   "outputs": [],
   "source": [
    "# Provides a summary view of a given account's activity\n",
    "# For use when investigating an account that has been identified as having associated suspect activity or been otherwise compromised. \n",
    "# All office activity by UserName using UI to set Time range\n",
    "# Tags: #Persistence, #Discovery, #Lateral Movement, #Collection\n",
    "\n",
    "user_activity_query = '''\n",
    "OfficeActivity\n",
    "| where TimeGenerated >= datetime({start})\n",
    "| where TimeGenerated <= datetime({end})\n",
    "| where UserKey has \"{user}\" or UserId has \"{user}\"\n",
    "'''\n",
    "print('Getting data...', end=' ')\n",
    "o365_query = user_activity_query.format(start=o365_query_times_user.start, \n",
    "                                        end=o365_query_times_user.end,\n",
    "                                        user=user_select.value)\n",
    "%kql -query o365_query\n",
    "user_activity_df = _kql_raw_result_.to_dataframe()\n",
    "print('done.')\n",
    "user_activity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "### Operation Breakdown for User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:37:09.274863Z",
     "start_time": "2020-05-16T01:37:07.067302Z"
    }
   },
   "outputs": [],
   "source": [
    "my_df = (user_activity_df[['OfficeId', 'RecordType', 'TimeGenerated', 'Operation',\n",
    "                           'ResultStatus', 'UserId', 'ClientIP','UserAgent']]\n",
    "         .groupby(['Operation', 'ResultStatus', 'ClientIP'])\n",
    "         .aggregate({'OfficeId': 'count'})\n",
    "         .rename(columns={'OfficeId': 'OperationCount', 'ClientIP': 'IPCount'})\n",
    "         .reset_index())\n",
    "sns.catplot(x='OperationCount', y=\"Operation\", hue=\"ClientIP\", jitter=False, data=my_df, aspect=2.5);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "### IP Count for Different User Operations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:37:24.368273Z",
     "start_time": "2020-05-16T01:37:24.066273Z"
    }
   },
   "outputs": [],
   "source": [
    "my_df2 = (user_activity_df[['OfficeId', 'RecordType', 'TimeGenerated', 'Operation',\n",
    "                           'ResultStatus', 'UserId', 'ClientIP','UserAgent']]\n",
    "         .groupby(['Operation'])\n",
    "         .aggregate({'OfficeId': 'count', 'ClientIP': 'nunique'})\n",
    "         .rename(columns={'OfficeId': 'OperationCount', 'ClientIP': 'IPCount'})\n",
    "         .reset_index())\n",
    "sns.barplot(x='IPCount', y=\"Operation\", data=my_df2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "### Activity Timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:39:53.519748Z",
     "start_time": "2020-05-16T01:39:53.048747Z"
    }
   },
   "outputs": [],
   "source": [
    "num_ops = user_activity_df[\"Operation\"].nunique()\n",
    "nbdisplay.display_timeline(data=user_activity_df,\n",
    "                           title='Office Operations',\n",
    "                           source_columns=['OfficeWorkload', 'Operation', 'ClientIP', 'ResultStatus'],\n",
    "                           group_by=\"Operation\",\n",
    "                           height=25 * num_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "### User IP GeoMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:39:59.097697Z",
     "start_time": "2020-05-16T01:39:58.876675Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_row_ip_loc(row):\n",
    "    try:\n",
    "        _, ip_entity = iplocation.lookup_ip(ip_address=row.ClientIP)\n",
    "        return ip_entity\n",
    "    except ValueError:\n",
    "        return None\n",
    "    \n",
    "from msticpy.nbtools.foliummap import FoliumMap\n",
    "folium_map = FoliumMap(zoom_start=3)\n",
    "off_ip_locs = (user_activity_df[['ClientIP']]\n",
    "                   .drop_duplicates()\n",
    "                   .apply(get_row_ip_loc, axis=1)\n",
    "                   .tolist())\n",
    "ip_locs = [ip_list[0] for ip_list in off_ip_locs if ip_list]\n",
    "    \n",
    "display(HTML('<h3>External IP Addresses seen in Office Activity</h3>'))\n",
    "display(HTML('Numbered circles indicate multiple items - click to expand.'))\n",
    "\n",
    "\n",
    "icon_props = {'color': 'purple'}\n",
    "folium_map.add_ip_cluster(ip_entities=ip_locs,\n",
    "                          **icon_props)\n",
    "folium_map.center_map()\n",
    "display(folium_map.folium_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "### Check for User IPs in Azure Network Flow Data\n",
    "The full data is available in the Dataframe ```az_net_query_byip```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:46:23.169433Z",
     "start_time": "2020-05-16T01:46:23.150433Z"
    }
   },
   "outputs": [],
   "source": [
    "if 'AzureNetworkAnalytics_CL' not in table_index:\n",
    "    md(\"\"\"\n",
    "    <font color=\"orange\">\n",
    "    <h2>Warning. Azure network flow data not available.</h2></font><br>\n",
    "    This section of the notebook is not useable with the current workspace.\n",
    "    \"\"\"\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:44:23.645211Z",
     "start_time": "2020-05-16T01:44:20.392588Z"
    }
   },
   "outputs": [],
   "source": [
    "if 'AzureNetworkAnalytics_CL' not in table_index:\n",
    "    display(Markdown('<font color=\"orange\"><h2>Warning. Azure network flow data not available.</h2></font><br>'\n",
    "                     'This section of the notebook is not useable with the current workspace.'))\n",
    "    \n",
    "# Build the query parameters\n",
    "all_user_ips = user_activity_df['ClientIP'].tolist()\n",
    "all_user_ips = [ip for ip in all_user_ips if ip and ip != '<null>']\n",
    "# Some Office IPs have dest port appended to address\n",
    "ipv4_ips = [ip.split(\":\")[0] for ip in all_user_ips if \".\" in ip]\n",
    "ipv6_ips = [ip for ip in all_user_ips if \".\" not in ip]\n",
    "all_ips = list(set(ipv4_ips + ipv6_ips))\n",
    "\n",
    "az_net_comms_df = (\n",
    "    qry_prov\n",
    "    .Network\n",
    "    .list_azure_network_flows_by_ip(start=o365_query_times_user.start,\n",
    "                                    end=o365_query_times_user.end,\n",
    "                                    ip_address_list=all_ips)\n",
    ")\n",
    "net_default_cols = ['FlowStartTime', 'FlowEndTime', 'VMName', 'VMIPAddress', \n",
    "                'PublicIPs', 'SrcIP', 'DestIP', 'L4Protocol', 'L7Protocol',\n",
    "                'DestPort', 'FlowDirection', 'AllowedOutFlows', \n",
    "                'AllowedInFlows']\n",
    "\n",
    "# %kql -query az_net_query_byip\n",
    "# az_net_comms_df = _kql_raw_result_.to_dataframe()\n",
    "if az_net_comms_df.empty:\n",
    "    md_warn(\"No network flow data available in AzureNetworkAnalytics_CL table\"\n",
    "           + \"\\nRemainder of cell will not work.\")\n",
    "    raise ValueError(\"No network flow data available in AzureNetworkAnalytics_CL table\")\n",
    "\n",
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    az_net_comms_df['TotalAllowedFlows'] = az_net_comms_df['AllowedOutFlows'] + az_net_comms_df['AllowedInFlows']\n",
    "    sns.catplot(x=\"L7Protocol\", y=\"TotalAllowedFlows\", col=\"FlowDirection\", data=az_net_comms_df)\n",
    "    sns.relplot(x=\"FlowStartTime\", y=\"TotalAllowedFlows\", \n",
    "                col=\"FlowDirection\", kind=\"line\", \n",
    "                hue=\"L7Protocol\", data=az_net_comms_df).set_xticklabels(rotation=50)\n",
    "\n",
    "cols = ['VMName', 'VMIPAddress', 'PublicIPs', 'SrcIP', 'DestIP', 'L4Protocol',\n",
    "        'L7Protocol', 'DestPort', 'FlowDirection', 'AllExtIPs', 'TotalAllowedFlows']\n",
    "flow_index = az_net_comms_df[cols].copy()\n",
    "def get_source_ip(row):\n",
    "    if row.FlowDirection == 'O':\n",
    "        return row.VMIPAddress if row.VMIPAddress else row.SrcIP\n",
    "    else:\n",
    "        return row.AllExtIPs if row.AllExtIPs else row.DestIP\n",
    "    \n",
    "def get_dest_ip(row):\n",
    "    if row.FlowDirection == 'O':\n",
    "        return row.AllExtIPs if row.AllExtIPs else row.DestIP\n",
    "    else:\n",
    "        return row.VMIPAddress if row.VMIPAddress else row.SrcIP\n",
    "\n",
    "flow_index['source'] = flow_index.apply(get_source_ip, axis=1)\n",
    "flow_index['target'] = flow_index.apply(get_dest_ip, axis=1)\n",
    "flow_index['value'] = flow_index['L7Protocol']\n",
    "\n",
    "cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    display(flow_index[['source', 'target', 'value', 'L7Protocol', \n",
    "                        'FlowDirection', 'TotalAllowedFlows']]\n",
    "            .groupby(['source', 'target', 'value', 'L7Protocol', 'FlowDirection'])\n",
    "            .sum().unstack().style.background_gradient(cmap=cm))\n",
    "\n",
    "nbdisp.display_timeline(data=az_net_comms_df.query('AllowedOutFlows > 0'),\n",
    "                         overlay_data=az_net_comms_df.query('AllowedInFlows > 0'),\n",
    "                         title='Network Flows (out=blue, in=green)',\n",
    "                         time_column='FlowStartTime',\n",
    "                         source_columns=['FlowType', 'AllExtIPs', 'L7Protocol', 'FlowDirection'],\n",
    "                         height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "## Rare Combinations of Country/UserAgent/Operation Type\n",
    "The dataframe below lists combinations in the time period that had less than 3 instances. This might help you to spot relatively unusual activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:47:49.358082Z",
     "start_time": "2020-05-16T01:47:14.392043Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from msticpy.sectools.eventcluster import (dbcluster_events, \n",
    "                                           add_process_features, \n",
    "                                           char_ord_score,\n",
    "                                           token_count,\n",
    "                                           delim_count)\n",
    "\n",
    "restrict_cols = ['OfficeId', 'RecordType', 'TimeGenerated', 'Operation',\n",
    "                 'OrganizationId', 'UserType', 'UserKey', 'OfficeWorkload',\n",
    "                 'ResultStatus', 'OfficeObjectId', 'UserId', 'ClientIP','UserAgent']\n",
    "feature_office_ops = office_ops_df[restrict_cols]\n",
    "feature_office_ops = ( pd.merge(feature_office_ops, \n",
    "                                ip_locs_df, how='left', \n",
    "                                left_on='ClientIP', right_on='Address')\n",
    "                      .fillna(''))\n",
    "\n",
    "# feature_office_ops = office_ops_df.copy()\n",
    "\n",
    "feature_office_ops['country_num'] = feature_office_ops.apply(lambda x: char_ord_score(x.CountryCode) if x.CountryCode else 0, axis=1)\n",
    "feature_office_ops['ua_tokens'] = feature_office_ops.apply(lambda x: char_ord_score(x.UserAgent), axis=1)\n",
    "feature_office_ops['user_num'] = feature_office_ops.apply(lambda x: char_ord_score(x.UserId), axis=1)\n",
    "feature_office_ops['op_num'] = feature_office_ops.apply(lambda x: char_ord_score(x.Operation), axis=1)\n",
    "\n",
    "# you might need to play around with the max_cluster_distance parameter.\n",
    "# decreasing this gives more clusters.\n",
    "(clustered_ops, dbcluster, x_data) = dbcluster_events(data=feature_office_ops,\n",
    "                                                      cluster_columns=['country_num',\n",
    "                                                                       'op_num',\n",
    "                                                                       'ua_tokens'],\n",
    "                                                      time_column='TimeGenerated',\n",
    "                                                      max_cluster_distance=0.0001)\n",
    "print('Number of input events:', len(feature_office_ops))\n",
    "print('Number of clustered events:', len(clustered_ops))\n",
    "display(Markdown('#### Rarest combinations'))\n",
    "display(clustered_ops[['TimeGenerated', 'RecordType',\n",
    "                        'Operation', 'UserId', 'UserAgent', 'ClusterSize',\n",
    "                        'OfficeObjectId', 'CountryName']]\n",
    "    .query('ClusterSize <= 2')\n",
    "    .sort_values('ClusterSize', ascending=True))\n",
    "display(Markdown('#### Most common operations'))\n",
    "display((clustered_ops[['RecordType', 'Operation', 'ClusterSize']]\n",
    "    .sort_values('ClusterSize', ascending=False)\n",
    "    .head(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a></a>[Contents](#contents)\n",
    "# Appendices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "### `msticpyconfig.yaml` configuration File\n",
    "You can configure primary and secondary TI providers and any required parameters in the `msticpyconfig.yaml` file. This is read from the current directory or you can set an environment variable (`MSTICPYCONFIG`) pointing to its location.\n",
    "\n",
    "To configure this file see the [ConfigureNotebookEnvironment notebook](https://github.com/Azure/Azure-Sentinel-Notebooks/blob/master/ConfiguringNotebookEnvironment.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:59:13.369607Z",
     "start_time": "2019-10-31T23:59:13.342533Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('List of current DataFrames in Notebook')\n",
    "print('-' * 50)\n",
    "current_vars = list(locals().keys())\n",
    "for var_name in current_vars:\n",
    "    if isinstance(locals()[var_name], pd.DataFrame) and not var_name.startswith('_'):\n",
    "        print(var_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "tags": [
     "todo"
    ]
   },
   "source": [
    "## Saving Data to Excel\n",
    "To save the contents of a pandas DataFrame to an Excel spreadsheet\n",
    "use the following syntax\n",
    "```\n",
    "writer = pd.ExcelWriter('myWorksheet.xlsx')\n",
    "my_data_frame.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "318.996px",
    "width": "320.994px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents2",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "351px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "406.193px",
    "left": "1468.4px",
    "right": "20px",
    "top": "120px",
    "width": "456.572px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
