{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Explorer - Linux Host\n",
    " <details>\n",
    "     <summary>&nbsp;<u>Details...</u></summary>\n",
    "\n",
    " **Notebook Version:** 1.0<br>\n",
    " **Python Version:** Python 3.6 (including Python 3.6 - AzureML)<br>\n",
    " **Required Packages**: kqlmagic, msticpy, pandas, pandas_bokeh, numpy, matplotlib, networkx, seaborn, datetime, ipywidgets, ipython, dnspython, ipwhois, folium, maxminddb_geolite2<br>\n",
    " **Platforms Supported**:\n",
    " - Azure Notebooks Free Compute\n",
    " - Azure Notebooks DSVM\n",
    " - OS Independent\n",
    "\n",
    " **Data Sources Required**:\n",
    " - Log Analytics/Azure Sentinel - Syslog, Secuirty Alerts, Auditd, Azure Network Analytics.\n",
    " - (Optional) - AlienVault OTX (requires account and API key)\n",
    " </details>\n",
    "\n",
    "This Notebooks brings together a series of tools and techniques to enable threat hunting within the context of a singular Linux host. The notebook utilizes a range of data sources to achieve this but in order to support the widest possible range of scenarios this Notebook prioritizes using common Syslog data. If there is detailed auditd data available for a host you may wish to edit the Notebook to rely primarily on this dataset, as it currently stands auditd is used when available to provide insight not otherwise available via Syslog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Notebook-Initialization\" data-toc-modified-id=\"Notebook-Initialization-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Notebook Initialization</a></span><ul class=\"toc-item\"><li><span><a href=\"#Get-WorkspaceId-and-Authenticate-to-Log-Analytics\" data-toc-modified-id=\"Get-WorkspaceId-and-Authenticate-to-Log-Analytics-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Get WorkspaceId and Authenticate to Log Analytics</a></span></li></ul></li><li><span><a href=\"#Set-Hunting-Time-Frame\" data-toc-modified-id=\"Set-Hunting-Time-Frame-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Set Hunting Time Frame</a></span><ul class=\"toc-item\"><li><span><a href=\"#Select-Host-to-Investigate\" data-toc-modified-id=\"Select-Host-to-Investigate-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Select Host to Investigate</a></span></li></ul></li><li><span><a href=\"#Host-Summary\" data-toc-modified-id=\"Host-Summary-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Host Summary</a></span><ul class=\"toc-item\"><li><span><a href=\"#Host-Alerts\" data-toc-modified-id=\"Host-Alerts-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Host Alerts</a></span></li></ul></li><li><span><a href=\"#Re-scope-Hunting-Time-Frame\" data-toc-modified-id=\"Re-scope-Hunting-Time-Frame-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Re-scope Hunting Time Frame</a></span></li><li><span><a href=\"#How-to-use-this-Notebook\" data-toc-modified-id=\"How-to-use-this-Notebook-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>How to use this Notebook</a></span></li><li><span><a href=\"#Host-Logon-Events\" data-toc-modified-id=\"Host-Logon-Events-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Host Logon Events</a></span><ul class=\"toc-item\"><li><span><a href=\"#Logon-Sessions\" data-toc-modified-id=\"Logon-Sessions-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Logon Sessions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Session-Details\" data-toc-modified-id=\"Session-Details-6.1.1\"><span class=\"toc-item-num\">6.1.1&nbsp;&nbsp;</span>Session Details</a></span></li><li><span><a href=\"#Raw-data-from-user-session\" data-toc-modified-id=\"Raw-data-from-user-session-6.1.2\"><span class=\"toc-item-num\">6.1.2&nbsp;&nbsp;</span>Raw data from user session</a></span></li></ul></li><li><span><a href=\"#Process-Tree-from-session\" data-toc-modified-id=\"Process-Tree-from-session-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Process Tree from session</a></span></li><li><span><a href=\"#Sudo-Session-Investigation\" data-toc-modified-id=\"Sudo-Session-Investigation-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Sudo Session Investigation</a></span></li></ul></li><li><span><a href=\"#User-Activity\" data-toc-modified-id=\"User-Activity-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>User Activity</a></span></li><li><span><a href=\"#Application-Activity\" data-toc-modified-id=\"Application-Activity-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Application Activity</a></span><ul class=\"toc-item\"><li><span><a href=\"#Display-process-tree\" data-toc-modified-id=\"Display-process-tree-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Display process tree</a></span></li><li><span><a href=\"#Application-Logs-with-associated-Threat-Intelligence\" data-toc-modified-id=\"Application-Logs-with-associated-Threat-Intelligence-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span>Application Logs with associated Threat Intelligence</a></span></li></ul></li><li><span><a href=\"#Network-Activity\" data-toc-modified-id=\"Network-Activity-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Network Activity</a></span><ul class=\"toc-item\"><li><span><a href=\"#Choose-ASNs/IPs-to-Check-for-Threat-Intel-Reports\" data-toc-modified-id=\"Choose-ASNs/IPs-to-Check-for-Threat-Intel-Reports-9.1\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>Choose ASNs/IPs to Check for Threat Intel Reports</a></span></li></ul></li><li><span><a href=\"#Configuration\" data-toc-modified-id=\"Configuration-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Configuration</a></span><ul class=\"toc-item\"><li><span><a href=\"#msticpyconfig.yaml-configuration-File\" data-toc-modified-id=\"msticpyconfig.yaml-configuration-File-10.1\"><span class=\"toc-item-num\">10.1&nbsp;&nbsp;</span><code>msticpyconfig.yaml</code> configuration File</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hunting Hypothesis: \n",
    "Our broad initial hunting hypothesis is that a particular Linux host in our environment has been compromised, we will need to hunt from a range of different positions to validate or disprove this hypothesis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Notebook initialization\n",
    "The next cell:\n",
    "- Checks for the correct Python version\n",
    "- Checks versions and optionally installs required packages\n",
    "- Imports the required packages into the notebook\n",
    "- Sets a number of configuration options.\n",
    "\n",
    "This should complete without errors. If you encounter errors or warnings look at the following two notebooks:\n",
    "- [TroubleShootingNotebooks](https://github.com/Azure/Azure-Sentinel-Notebooks/blob/master/TroubleShootingNotebooks.ipynb)\n",
    "- [ConfiguringNotebookEnvironment](https://github.com/Azure/Azure-Sentinel-Notebooks/blob/master/ConfiguringNotebookEnvironment.ipynb)\n",
    "\n",
    "If you are running in the Azure Sentinel Notebooks environment (Azure Notebooks or Azure ML) you can run live versions of these notebooks:\n",
    "- [Run TroubleShootingNotebooks](./TroubleShootingNotebooks.ipynb)\n",
    "- [Run ConfiguringNotebookEnvironment](./ConfiguringNotebookEnvironment.ipynb)\n",
    "\n",
    "You may also need to do some additional configuration to successfully use functions such as Threat Intelligence service lookup and Geo IP lookup. \n",
    "There are more details about this in the `ConfiguringNotebookEnvironment` notebook and in these documents:\n",
    "- [msticpy configuration](https://msticpy.readthedocs.io/en/latest/getting_started/msticpyconfig.html)\n",
    "- [Threat intelligence provider configuration](https://msticpy.readthedocs.io/en/latest/data_acquisition/TIProviders.html#configuration-file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T23:58:35.616818Z",
     "start_time": "2020-05-15T23:58:35.383819Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "REQ_PYTHON_VER=(3, 6)\n",
    "REQ_MSTICPY_VER=(0, 5, 0)\n",
    "\n",
    "display(HTML(\"<h3>Starting Notebook setup...</h3>\"))\n",
    "if Path(\"./utils/nb_check.py\").is_file():\n",
    "    from utils.nb_check import check_python_ver, check_mp_ver\n",
    "\n",
    "    check_python_ver(min_py_ver=REQ_PYTHON_VER)\n",
    "    try:\n",
    "        check_mp_ver(min_msticpy_ver=REQ_MSTICPY_VER)\n",
    "    except ImportError:\n",
    "        !pip install --upgrade msticpy\n",
    "        if \"msticpy\" in sys.modules:\n",
    "            importlib.reload(msticpy)\n",
    "        else:\n",
    "            import msticpy\n",
    "        check_mp_ver(REQ_PYTHON_VER)\n",
    "            \n",
    "\n",
    "# If not using Azure Notebooks, install msticpy with\n",
    "# !pip install msticpy\n",
    "from msticpy.nbtools import nbinit\n",
    "extra_imports = [\n",
    "    \"msticpy.nbtools, observationlist\",\n",
    "    \"msticpy.nbtools.foliummap, get_map_center\",\n",
    "    \"pyvis.network, Network\",\n",
    "    \"re\",\n",
    "    \"ipwhois, IPWhois\",\n",
    "    \"pandas_bokeh\",\n",
    "    \"bokeh.palettes, viridis\",\n",
    "    \"dns, reversename\",\n",
    "    \"dns, resolver\"\n",
    "]\n",
    "additional_packages = [\n",
    "    \"oauthlib\", \"pyvis\", \"python-whois\", \"pandas_bokeh\"\n",
    "]\n",
    "nbinit.init_notebook(\n",
    "    namespace=globals(),\n",
    "    additional_packages=additional_packages,\n",
    "    extra_imports=extra_imports,\n",
    ");\n",
    "\n",
    "WIDGET_DEFAULTS = {\n",
    "    \"layout\": widgets.Layout(width=\"95%\"),\n",
    "    \"style\": {\"description_width\": \"initial\"},\n",
    "}\n",
    "\n",
    "from msticpy.sectools import auditdextract\n",
    "from msticpy.sectools.cmd_line import *\n",
    "from msticpy.sectools.ip_utils import convert_to_ip_entities\n",
    "from msticpy.sectools.syslog_utils import *\n",
    "from msticpy.sectools.syslog_utils import create_host_record, cluster_syslog_logons_df, risky_sudo_sessions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-05T18:05:09.026Z"
    }
   },
   "source": [
    "### Get WorkspaceId and Authenticate to Log Analytics\n",
    " <details>\n",
    "    <summary> <u>Details...</u></summary>\n",
    "If you are using user/device authentication, run the following cell. \n",
    "- Click the 'Copy code to clipboard and authenticate' button.\n",
    "- This will pop up an Azure Active Directory authentication dialog (in a new tab or browser window). The device code will have been copied to the clipboard. \n",
    "- Select the text box and paste (Ctrl-V/Cmd-V) the copied value. \n",
    "- You should then be redirected to a user authentication page where you should authenticate with a user account that has permission to query your Log Analytics workspace.\n",
    "\n",
    "Use the following syntax if you are authenticating using an Azure Active Directory AppId and Secret:\n",
    "```\n",
    "%kql loganalytics://tenant(aad_tenant).workspace(WORKSPACE_ID).clientid(client_id).clientsecret(client_secret)\n",
    "```\n",
    "instead of\n",
    "```\n",
    "%kql loganalytics://code().workspace(WORKSPACE_ID)\n",
    "```\n",
    "\n",
    "Note: you may occasionally see a JavaScript error displayed at the end of the authentication - you can safely ignore this.<br>\n",
    "On successful authentication you should see a ```popup schema``` button.\n",
    "To find your Workspace Id go to [Log Analytics](https://ms.portal.azure.com/#blade/HubsExtension/Resources/resourceType/Microsoft.OperationalInsights%2Fworkspaces). Look at the workspace properties to find the ID.\n",
    " </details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T23:58:49.319665Z",
     "start_time": "2020-05-15T23:58:49.309664Z"
    }
   },
   "outputs": [],
   "source": [
    "#See if we have an Azure Sentinel Workspace defined in our config file, if not let the user specify Workspace and Tenant IDs\n",
    "from msticpy.nbtools.wsconfig import WorkspaceConfig\n",
    "ws_config = WorkspaceConfig()\n",
    "try:\n",
    "    ws_id = ws_config['workspace_id']\n",
    "    ten_id = ws_config['tenant_id']\n",
    "    display(HTML(\"Workspace details collected from config file\"))\n",
    "    config = True\n",
    "except:\n",
    "    display(HTML('Please go to your Log Analytics workspace, copy the workspace ID'\n",
    "                 ' and/or tenant Id and paste here to enable connection to the workspace and querying of it..<br> '))\n",
    "    ws_id = mnbwidgets.GetEnvironmentKey(env_var='WORKSPACE_ID',\n",
    "                                        prompt='Please enter your Log Analytics Workspace Id:', auto_display=True)\n",
    "    ten_id = nbwidgets.GetEnvironmentKey(env_var='TENANT_ID',\n",
    "                                         prompt='Please enter your Log Analytics Tenant Id:', auto_display=True)\n",
    "    config = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T23:59:18.090694Z",
     "start_time": "2020-05-15T23:58:52.515672Z"
    }
   },
   "outputs": [],
   "source": [
    "# Establish a query provider for Azure Sentinel and connect to it\n",
    "if config is False:\n",
    "    ws_id = ws_id.value\n",
    "    ten_id = ten_id.value\n",
    "qry_prov = QueryProvider('LogAnalytics')\n",
    "qry_prov.connect(connection_str=ws_config.code_connect_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Hunting Time Frame\n",
    "To begin the hunt we need to et the time frame in which you wish to test your compromised host hunting hypothesis within. Use the widget below to select your start and end time for the hunt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T23:59:18.217691Z",
     "start_time": "2020-05-15T23:59:18.155693Z"
    }
   },
   "outputs": [],
   "source": [
    "query_times = nbwidgets.QueryTime(units='day',\n",
    "                                  max_before=20, max_after=1, before=3)\n",
    "query_times.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Host to Investigate\n",
    "Select the host you want to test your hunting hypothesis against, only hosts with Syslog data within the time frame you specified are available. If the host you wish to select is not present try adjusting your time frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T23:59:30.667719Z",
     "start_time": "2020-05-15T23:59:30.645721Z"
    }
   },
   "outputs": [],
   "source": [
    "host_text = widgets.Text(\n",
    "    description=\"Enter the Host name to search for:\", **WIDGET_DEFAULTS\n",
    ")\n",
    "display(host_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T23:59:47.945809Z",
     "start_time": "2020-05-15T23:59:45.525517Z"
    }
   },
   "outputs": [],
   "source": [
    "hostname = None\n",
    "items = []\n",
    "hosts_query = f\"\"\" Syslog | where TimeGenerated between (datetime({query_times.start}) .. datetime({query_times.end})) \n",
    "                | where Computer contains \"{host_text.value}\" | distinct Computer | limit 490000\"\"\"\n",
    "print(\"Collecting details on avaliable hosts...\")\n",
    "hosts_df = qry_prov._query_provider.query(query=hosts_query)\n",
    "if isinstance(hosts_df, pd.DataFrame) and not hosts_df.empty:\n",
    "    items = hosts_df[\"Computer\"].unique().tolist()\n",
    "\n",
    "if len(items) > 1:\n",
    "    print(f\"Multiple matches for '{host_text.value}'. Please select a host from the list.\")\n",
    "    choose_host = nbwidgets.SelectString(\n",
    "        item_list=items,\n",
    "        description=\"Select the host.\",\n",
    "        auto_display=True,\n",
    "    )\n",
    "    \n",
    "elif not hosts_df.empty:\n",
    "    hostname = items[0]\n",
    "    md(f\"Unique host found: {hostname}\")\n",
    "else:\n",
    "    md(f\"Host not found: {host_text.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Host Summary\n",
    "Below is a overview of the selected host based on available data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T00:00:21.714769Z",
     "start_time": "2020-05-15T23:59:56.711836Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Collecting host details. This may take a few minutes...\")\n",
    "if not hostname:\n",
    "    hostname = choose_host.value\n",
    "# Collect data on the host\n",
    "syslog_query = f\"\"\" Syslog | where TimeGenerated between (datetime({query_times.start}) .. datetime({query_times.end})) \n",
    "                | where Computer contains \"{hostname}\" \"\"\"\n",
    "all_syslog = qry_prov.exec_query(query=syslog_query)\n",
    "syslog_data = all_syslog[all_syslog['Computer'] == f'{hostname}']\n",
    "heartbeat_query = f\"\"\"Heartbeat | where TimeGenerated >= datetime({query_times.start}) | where TimeGenerated <= datetime({query_times.end})| where Computer == '{hostname}' | top 1 by TimeGenerated desc nulls last\"\"\"\n",
    "if \"AzureNetworkAnalytics_CL\" in qry_prov.schema:\n",
    "    aznet_query = f\"\"\"AzureNetworkAnalytics_CL | where TimeGenerated >= datetime({query_times.start}) | where TimeGenerated <= datetime({query_times.end}) | where VirtualMachine_s has '{hostname}' | where ResourceType == 'NetworkInterface' | top 1 by TimeGenerated desc | project PrivateIPAddresses = PrivateIPAddresses_s, PublicIPAddresses = PublicIPAddresses_s\"\"\"\n",
    "    az_net_df = qry_prov.exec_query(query=aznet_query)\n",
    "host_hb = qry_prov.exec_query(query=heartbeat_query)\n",
    "\n",
    "# Create host entity record, with Azure network data if any is avaliable\n",
    "if isinstance(az_net_df, pd.DataFrame):\n",
    "    host_entity = create_host_record(\n",
    "        syslog_df=syslog_data, heartbeat_df=host_hb, az_net_df=az_net_df)\n",
    "else:\n",
    "    host_entity = create_host_record(\n",
    "        syslog_df=syslog_data, heartbeat_df=host_hb)\n",
    "\n",
    "display(\n",
    "    Markdown(\n",
    "        \"***Host Details***\\n\\n\"\n",
    "        f\"**Hostname**: {host_entity.computer} \\n\\n\"\n",
    "        f\"**OS**: {host_entity.OSType} {host_entity.OSName}\\n\\n\"\n",
    "        f\"**IP Address**: {host_entity.IPAddress.Address}\\n\\n\"\n",
    "        f\"**Location**: {host_entity.IPAddress.Location.CountryName}\\n\\n\"\n",
    "        f\"**Installed Applications**: {host_entity.Applications}\\n\\n\"\n",
    "    )\n",
    ")\n",
    "rel_alert_select = None\n",
    "sudo_events = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Host Alerts\n",
    "This section provides an overview of any security alerts in Azure Sentinel related to this host, this will help scope and guide our hunt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T00:00:27.549794Z",
     "start_time": "2020-05-16T00:00:25.664615Z"
    }
   },
   "outputs": [],
   "source": [
    "related_alerts = qry_prov.SecurityAlert.list_related_alerts(\n",
    "    query_times, host_name=hostname)\n",
    "\n",
    "if isinstance(related_alerts, pd.DataFrame) and not related_alerts.empty:\n",
    "    host_alert_items = (related_alerts[['AlertName', 'TimeGenerated']]\n",
    "                        .groupby('AlertName').TimeGenerated.agg('count').to_dict())\n",
    "\n",
    "    def print_related_alerts(alertDict, entityType, entityName):\n",
    "        if len(alertDict) > 0:\n",
    "            md(f\"### Found {len(alertDict)} different alert types related to this {entityType} (\\'{entityName}\\')\")\n",
    "            for (k, v) in alertDict.items():\n",
    "                md(f\"- {k}, Count of alerts: {v}\")\n",
    "        else:\n",
    "            md(f\"No alerts for {entityType} entity \\'{entityName}\\'\")\n",
    "\n",
    "\n",
    "# Display alerts on timeline to aid in visual grouping\n",
    "    print_related_alerts(host_alert_items, 'host', host_entity.HostName)\n",
    "    x = nbdisplay.display_timeline(\n",
    "        data=related_alerts, source_columns=[\"AlertName\"], title=\"Host alerts over time\", height=300, color=\"red\")\n",
    "else:\n",
    "    md('No related alerts found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T00:00:31.720767Z",
     "start_time": "2020-05-16T00:00:31.664768Z"
    }
   },
   "outputs": [],
   "source": [
    "rel_alert_select = None\n",
    "\n",
    "def show_full_alert(selected_alert):\n",
    "    global security_alert, alert_ip_entities\n",
    "    security_alert = SecurityAlert(\n",
    "        rel_alert_select.selected_alert)\n",
    "    nbdisplay.display_alert(security_alert, show_entities=True)\n",
    "\n",
    "# Show selected alert when selected\n",
    "if isinstance(related_alerts, pd.DataFrame) and not related_alerts.empty:\n",
    "    related_alerts['CompromisedEntity'] = related_alerts['Computer']\n",
    "    md('### Click on alert to view details.')\n",
    "    rel_alert_select = nbwidgets.AlertSelector(alerts=related_alerts,\n",
    "                                               action=show_full_alert)\n",
    "    rel_alert_select.display()\n",
    "else:\n",
    "    md('No related alerts found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-scope Hunting Time Frame\n",
    "Based on the security alerts for this host we can choose to re-scope our hunting time frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T00:01:56.991980Z",
     "start_time": "2020-05-16T00:01:56.936979Z"
    }
   },
   "outputs": [],
   "source": [
    "if rel_alert_select is None or rel_alert_select.selected_alert is None:\n",
    "    start = query_times.start\n",
    "else:\n",
    "    start = rel_alert_select.selected_alert['TimeGenerated']\n",
    "\n",
    "# Set new investigation time windows based on the selected alert\n",
    "invest_times = nbwidgets.QueryTime(units='hours',\n",
    "                                       max_before=24, max_after=12, before=6, origin_time=start)\n",
    "invest_times.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use this Notebook\n",
    "Whilst this notebook is linear in layout it doesn't need to be linear in usage. We have selected our host to investigate and set an initial hunting time-frame to work within. We can now start to test more specific hunting hypothesis with the aim of validating our broader initial hunting hypothesis. To do this we can start by looking at:\n",
    "- <a>Host Logon Events</a>\n",
    "- <a>User Activity</a>\n",
    "- <a>Application Activity</a>\n",
    "- <a>Network Activity</a>\n",
    "\n",
    "You can choose to start below with a hunt in host logon events or choose to jump to one of the other sections listed above. The order in which you choose to run each of these major sections doesn't matter, they are each self contained. You may also choose to rerun sections based on your findings from running other sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Host Logon Events\n",
    "**Hypothesis:** That an attacker has gained legitimate access to the host via compromised credentials and has logged into the host to conduct malicious activity. \n",
    "\n",
    "This section provides an overview of logon activity for the host within our hunting time frame, the purpose of this is to allow for the identification of anomalous logons or attempted logons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T00:02:12.485265Z",
     "start_time": "2020-05-16T00:02:10.553617Z"
    }
   },
   "outputs": [],
   "source": [
    "# Collect logon events for this, seperate them into sucessful and unsucessful and cluster sucessful one into sessions\n",
    "logon_events = qry_prov.LinuxSyslog.user_logon(invest_times, host_name=hostname)\n",
    "remote_logons = None\n",
    "failed_logons = None\n",
    "logon_sessions_df = None\n",
    "if isinstance(logon_events, pd.DataFrame) and not logon_events.empty:\n",
    "    try:\n",
    "        remote_logons = (logon_events[logon_events['LogonResult'] == 'Success'])\n",
    "        failed_logons = (logon_events[logon_events['LogonResult'] == 'Failure'])\n",
    "        logon_sessions_df = cluster_syslog_logons_df(logon_events)\n",
    "    except:\n",
    "        print(\"No logon sessions in this timeframe\")\n",
    "else:\n",
    "    print(\"No logon events in this timeframe\")\n",
    "\n",
    "\n",
    "if (remote_logons is not None and not remote_logons.empty) or (failed_logons is not None and not failed_logons.empty):\n",
    "    # Provide a timeline of sucessful and failed logon attempts to aid identification of potential brute force attacks\n",
    "    display(Markdown('### Timeline of sucessful host logons.'))\n",
    "    tl_data = {\"Remote Logons\": {\"data\": remote_logons, \"source_columns\": ['User', 'ProcessName', 'SourceIP'], \"color\": \"Green\"},\n",
    "               \"Failed Logons\": {\"data\": failed_logons, \"source_columns\": ['User', 'ProcessName', 'SourceIP'], \"time_column\": \"TimeGenerated\", \"color\": \"Red\"}}\n",
    "    logon_timeline = nbdisplay.display_timeline(\n",
    "        data=tl_data, height=300, alert=rel_alert_select.selected_alert)\n",
    "    palette = viridis(5)\n",
    "    # Graph out failed/sucessful logons by account and by logon process\n",
    "    all_df = pd.DataFrame(dict(successful=remote_logons['ProcessName'].value_counts(\n",
    "    ), failed=failed_logons['ProcessName'].value_counts())).fillna(0)\n",
    "    fail_data = pd.value_counts(failed_logons['User'].values, sort=True).head(\n",
    "        10).reset_index(name='value').rename(columns={'User': 'Count'})\n",
    "    fail_pie = None\n",
    "    sucess_pie = None\n",
    "    if not fail_data.empty:\n",
    "        fail_pie = fail_data.plot_bokeh.pie(x='index', y=\"value\", colormap=palette,\n",
    "                                            show_figure=False, title=\"Relative Frequencies of Failed Logons by Account\")\n",
    "    sucess_data = pd.value_counts(remote_logons['User'].values, sort=False).reset_index(\n",
    "        name='value').rename(columns={'User': 'Count'})\n",
    "    if not sucess_data.empty:\n",
    "        sucess_pie = sucess_data.plot_bokeh.pie(x='index', colormap=palette, y=\"value\",\n",
    "                                                show_figure=False, title=\"Relative Frequencies of Sucessful Logons by Account\")\n",
    "    processes = all_df.index.values.tolist()\n",
    "    fail_sucess_data = pd.DataFrame({'processes': processes,\n",
    "                                     'sucess': all_df['successful'].values.tolist(),\n",
    "                                     'failure': all_df['failed'].values.tolist()})\n",
    "\n",
    "    process_bar = fail_sucess_data.plot_bokeh.bar(\n",
    "        x=\"processes\", colormap=palette,  show_figure=False, title=\"Failed and Sucessful logon attempts by process\")\n",
    "    pandas_bokeh.plot_grid(\n",
    "        [[fail_pie, sucess_pie], [process_bar]], plot_width=450, plot_height=300)\n",
    "\n",
    "    # Convert logon IPs to IP entities in order to get location\n",
    "    ip_entity = entityschema.IpAddress()\n",
    "    #Is there a better way to do this rather than reseting the list each time.\n",
    "    ip_list = []\n",
    "    for ip_logon in remote_logons['SourceIP']:\n",
    "        ip_list.extend(convert_to_ip_entities(ip_logon))\n",
    "    ip_fail_list = []\n",
    "    for ip_fail in failed_logons['SourceIP']:\n",
    "        ip_fail_list.extend(convert_to_ip_entities(ip_fail))\n",
    "\n",
    "    # Get center location of all IP locaitons to set map default\n",
    "    location = get_map_center(ip_list + ip_fail_list)\n",
    "    folium_map = FoliumMap(location=location, zoom_start=4)\n",
    "\n",
    "    # Map logon locations to allow for identification of anomolous locations\n",
    "    if len(ip_fail_list) > 0:\n",
    "        display(HTML('<h3>Map of Originating Location of Logon Attempts</h3>'))\n",
    "        icon_props = {'color': 'red'}\n",
    "        folium_map.add_ip_cluster(ip_entities=ip_fail_list, **icon_props)\n",
    "    if len(ip_list) > 0:\n",
    "        icon_props = {'color': 'green'}\n",
    "        folium_map.add_ip_cluster(ip_entities=ip_list, **icon_props)\n",
    "    display(folium_map.folium_map)\n",
    "    display(Markdown('<p style=\"color:red\">Warning: the folium mapping library '\n",
    "                         'does not display correctly in some browsers.</p><br>'\n",
    "                         'If you see a blank image please retry with a different browser.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logon Sessions\n",
    "Based on the detail above if you wish to focus your hunt on a particular user jump to the [User Activity](#user) section. Alternatively to further further refine our hunt we need to select a logon session to view in more detail. Select a session from the list below to continue. Sessions that occurred at the time an alert was raised for this host, or where the user has a abnormal ratio of failed to successful login attempts are highlighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T00:02:19.836782Z",
     "start_time": "2020-05-16T00:02:19.732781Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "def to_utc(time):\n",
    "    ts = (time - np.datetime64('1970-01-01T00:00:00')) / np.timedelta64(1, 's')\n",
    "    time = dt.datetime.utcfromtimestamp(ts) \n",
    "    return time\n",
    "if logon_sessions_df is not None:\n",
    "    logon_sessions_df[\"Alerts during session?\"] = np.nan\n",
    "    # check if any alerts occur during logon window.\n",
    "    logon_sessions_df['Start (UTC)'] = [(to_utc(time) - dt.timedelta(seconds=5)) for time in logon_sessions_df['Start']]\n",
    "    logon_sessions_df['End (UTC)'] = [(to_utc(time) + dt.timedelta(seconds=5)) for time in logon_sessions_df['End']]\n",
    "\n",
    "    for TimeGenerated in related_alerts['TimeGenerated']:\n",
    "        logon_sessions_df.loc[(TimeGenerated >= logon_sessions_df['Start (UTC)']) & (TimeGenerated <= logon_sessions_df['End (UTC)']), \"Alerts during session?\"] = \"Yes\"\n",
    "\n",
    "    logon_sessions_df.loc[logon_sessions_df['User'] == 'root', \"Root?\"] = \"Yes\"\n",
    "    logon_sessions_df.replace(np.nan, \"No\", inplace=True)\n",
    "\n",
    "    ratios = []\n",
    "    for _, row in logon_sessions_df.iterrows():\n",
    "        suc_fail = logon_events.apply(lambda x: True if x['User'] == row['User'] and x[\"LogonResult\"] == 'Success' else(\n",
    "            False if x['User'] == row['User'] and x[\"LogonResult\"] == 'Failure' else None), axis=1)\n",
    "        numofsucess = len(suc_fail[suc_fail == True].index)\n",
    "        numoffail = len(suc_fail[suc_fail == False].index)\n",
    "        if numoffail == 0:\n",
    "            ratio = 1\n",
    "        else:\n",
    "            ratio = numofsucess/numoffail\n",
    "        ratios.append(ratio)\n",
    "    logon_sessions_df[\"Sucessful to failed logon ratio\"] = ratios\n",
    "\n",
    "    def color_cells(val):\n",
    "        if isinstance(val, str):\n",
    "            color = 'yellow' if val == \"Yes\" else 'white'\n",
    "        elif isinstance(val, float):\n",
    "            color = 'yellow' if val > 0.5 else 'white'\n",
    "        else:\n",
    "            color = 'white'\n",
    "        return 'background-color: %s' % color \n",
    "\n",
    "    display(logon_sessions_df[['User','Start (UTC)', 'End (UTC)', 'Alerts during session?', 'Sucessful to failed logon ratio', 'Root?']]\n",
    "                        .style.applymap(color_cells).hide_index())\n",
    "\n",
    "    logon_items = logon_sessions_df[['User','Start (UTC)', 'End (UTC)']].to_string(header=False,\n",
    "                      index=False,\n",
    "                      index_names=False).split('\\n')\n",
    "    logon_sessions_df[\"Key\"] = logon_items\n",
    "    logon_sessions_df.set_index('Key', inplace=True)\n",
    "    logon_dict = logon_sessions_df[['User','Start (UTC)', 'End (UTC)']].to_dict('index')\n",
    "\n",
    "    logon_selection = nbwidgets.SelectString(description='Select logon session to investigate: ',\n",
    "                                                 item_dict=logon_dict , width='80%', auto_display=True)\n",
    "else:\n",
    "    md(\"No logon sessions during this timeframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T00:02:33.394888Z",
     "start_time": "2020-05-16T00:02:24.256128Z"
    }
   },
   "outputs": [],
   "source": [
    "def view_syslog(selected_facility):\n",
    "    display(syslog_events.query('Facility == @selected_facility'))\n",
    "\n",
    "# Produce a summary of user modification actions taken\n",
    "def action_count(x):\n",
    "    if \"Add\" in x:\n",
    "        return len(add_events.replace(\"\", np.nan).dropna(subset=['User'])['User'].unique().tolist())\n",
    "    elif \"Modify\" in x:\n",
    "        return len(mod_events.replace(\"\", np.nan).dropna(subset=['User'])['User'].unique().tolist())\n",
    "    elif \"Delete\" in x:\n",
    "        return len(del_events.replace(\"\", np.nan).dropna(subset=['User'])['User'].unique().tolist())\n",
    "    else:\n",
    "        return \"\"\n",
    "sudo_sessions = None\n",
    "tooltip_cols = ['SyslogMessage']\n",
    "if logon_sessions_df is not None:\n",
    "    #Collect data based on the session selected for investigation\n",
    "    invest_sess = {'StartTimeUtc': logon_selection.value.get('Start (UTC)'), 'EndTimeUtc': logon_selection.value.get(\n",
    "        'End (UTC)'), 'Account': logon_selection.value.get('User'), 'Host': hostname}\n",
    "    session = entityschema.HostLogonSession(invest_sess)\n",
    "    syslog_events = qry_prov.LinuxSyslog.all_syslog(\n",
    "        start=session.StartTimeUtc, end=session.EndTimeUtc, host_name=session.Host)\n",
    "    sudo_events = qry_prov.LinuxSyslog.sudo_activity(\n",
    "        start=session.StartTimeUtc, end=session.EndTimeUtc, host_name=session.Host, user=session.Account)\n",
    "\n",
    "    if isinstance(sudo_events, pd.DataFrame) and not sudo_events.empty:\n",
    "        sudo_events[['Command', 'CommandCall']].replace('', np.nan, inplace=True)\n",
    "        try:\n",
    "            sudo_sessions = cluster_syslog_logons_df(logon_events=(sudo_events))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Display summary of cron activity in session\n",
    "    cron_events = qry_prov.LinuxSyslog.cron_activity(\n",
    "        start=session.StartTimeUtc, end=session.EndTimeUtc, host_name=session.Host)\n",
    "    if not isinstance(cron_events, pd.DataFrame):\n",
    "        display(HTML(\n",
    "            f'<h3> No Cron activity for {session.Host} between {session.StartTimeUtc} and {session.EndTimeUtc}</h3>'))\n",
    "        crn_tl_data = {}\n",
    "    else:\n",
    "\n",
    "        cron_events['CMD'].replace('', np.nan, inplace=True)\n",
    "\n",
    "        crn_tl_data = {\"Cron Exections\": {\"data\": cron_events[['TimeGenerated', 'CMD', 'CronUser', 'SyslogMessage']].dropna(), \"source_columns\": tooltip_cols, \"color\": \"Blue\"},\n",
    "                       \"Cron Edits\": {\"data\": cron_events.loc[cron_events['SyslogMessage'].str.contains('EDIT')], \"source_columns\": tooltip_cols, \"color\": \"Green\"}}\n",
    "\n",
    "        display(HTML('<h2> Most common commands run by cron:</h2>'))\n",
    "        display(HTML(\n",
    "            'This shows how often each cron job was exected within the specified time window'))\n",
    "        cron_commands = (cron_events[['EventTime', 'CMD']]\n",
    "                         .groupby(['CMD']).count()\n",
    "                         .dropna()\n",
    "                         .style\n",
    "                         .set_table_attributes('width=900px, text-align=center')\n",
    "                         .background_gradient(cmap='Reds', low=0.5, high=1)\n",
    "                         .format(\"{0:0>1.0f}\"))\n",
    "        display(cron_commands)\n",
    "\n",
    "    # Display summary of user and group creations, deletions and modifications during the session\n",
    "    user_activity = qry_prov.LinuxSyslog.user_group_activity(\n",
    "        start=session.StartTimeUtc, end=session.EndTimeUtc, host_name=session.Host)\n",
    "\n",
    "    if not isinstance(user_activity, pd.DataFrame) and not use_activity.empty:\n",
    "        display(HTML(\n",
    "            f' No user or group moidifcations for {session.Host} between {session.StartTimeUtc} and {session.EndTimeUtc}'))\n",
    "    else:\n",
    "        add_events = user_activity[user_activity['UserGroupAction'].str.contains(\n",
    "            'Add')]\n",
    "        del_events = user_activity[user_activity['UserGroupAction'].str.contains(\n",
    "            'Delete')]\n",
    "        mod_events = user_activity[user_activity['UserGroupAction'].str.contains(\n",
    "            'Modify')]\n",
    "        user_activity['Count'] = user_activity.groupby('UserGroupAction')['UserGroupAction'].transform('count')\n",
    "        if add_events.empty and del_events.empty and mod_events.empty:\n",
    "            display(HTML('<h2> Users and groups added or deleted:</h2<>'))\n",
    "            display(HTML(\n",
    "                f'No users or groups were added or deleted on {host_entity.HostName} between {query_times.start} and {query_times.end}'))\n",
    "            user_tl_data = {}\n",
    "        else:\n",
    "            display(HTML(\"<h2>Users added, modified or deleted</h2>\"))\n",
    "            display(user_activity[['UserGroupAction','Count']].drop_duplicates().style.hide_index())\n",
    "            account_actions = pd.DataFrame({\"User Additions\": [add_events.replace(\"\", np.nan).dropna(subset=['User'])['User'].unique().tolist()],\n",
    "                                            \"User Modifications\": [mod_events.replace(\"\", np.nan).dropna(subset=['User'])['User'].unique().tolist()],\n",
    "                                            \"User Deletions\": [del_events.replace(\"\", np.nan).dropna(subset=['User'])['User'].unique().tolist()]})\n",
    "            display(account_actions.style.hide_index())\n",
    "            user_tl_data = {\"User adds\": {\"data\": add_events, \"source_columns\": tooltip_cols, \"color\": \"Orange\"},\n",
    "                            \"User deletes\": {\"data\": del_events, \"source_columns\": tooltip_cols, \"color\": \"Red\"},\n",
    "                            \"User modfications\": {\"data\": mod_events, \"source_columns\": tooltip_cols, \"color\": \"Grey\"}}\n",
    "        # Display sudo activity during session\n",
    "        if sudo_sessions is None:\n",
    "            md(f\"No Sudo sessions for {session.Host} between {logon_selection.value.get('Start (UTC)')} and {logon_selection.value.get('End (UTC)')}\")\n",
    "            sudo_tl_data = {}\n",
    "        else:\n",
    "            sudo_start = sudo_events[sudo_events[\"SyslogMessage\"].str.contains(\n",
    "                \"pam_unix.+session opened\")].rename(columns={\"Sudoer\": \"User\"})\n",
    "            sudo_tl_data = {\"Host logons\": {\"data\": remote_logons, \"source_columns\": tooltip_cols, \"color\": \"Cyan\"},\n",
    "                            \"Sudo sessions\": {\"data\": sudo_start, \"source_columns\": tooltip_cols, \"color\": \"Purple\"}}\n",
    "            try:\n",
    "                risky_actions = cmd_line.risky_cmd_line(events=sudo_events, log_type=\"Syslog\")\n",
    "                suspicious_events = cmd_speed(\n",
    "                    cmd_events=sudo_events, time=60, events=2, cmd_field=\"Command\")\n",
    "            except:\n",
    "                risky_actions = None\n",
    "                suspicious_events = None\n",
    "            if risky_actions is None and suspicious_events is None:\n",
    "                pass\n",
    "            else:\n",
    "                risky_sessions = risky_sudo_sessions(\n",
    "                    risky_actions=risky_actions, sudo_sessions=sudo_sessions, suspicious_actions=suspicious_events)\n",
    "                for key in risky_sessions:\n",
    "                    if key in sudo_sessions:\n",
    "                        sudo_sessions[f\"{key} - {risky_sessions[key]}\"] = sudo_sessions.pop(\n",
    "                            key)\n",
    "\n",
    "        if sudo_events.empty:\n",
    "            md(f\"No sucessful sudo activity for {hostname} between {logon_selection.value.get('Start (UTC)')} and {logon_selection.value.get('End (UTC)')}\")\n",
    "        else:\n",
    "            sudo_events.replace(\"\", np.nan, inplace=True)\n",
    "            display(HTML('<h2> Frequency of sudo commands</h2>'))\n",
    "            display(HTML('This shows how many times each command has been run with sudo. /bin/bash is usally associated with the use of \"sudo -i\"'))\n",
    "            sudo_commands = (sudo_events[['EventTime', 'CommandCall']]\n",
    "                             .groupby(['CommandCall'])\n",
    "                             .count()\n",
    "                             .dropna()\n",
    "                             .style\n",
    "                             .set_table_attributes('width=900px, text-align=center')\n",
    "                             .background_gradient(cmap='Reds', low=.5, high=1)\n",
    "                             .format(\"{0:0>3.0f}\"))\n",
    "            display(sudo_commands)\n",
    "\n",
    "    # Display a timeline of all activity during session\n",
    "    crn_tl_data.update(user_tl_data)\n",
    "    crn_tl_data.update(sudo_tl_data)\n",
    "    display(HTML('<h2> Session Timeline.</h2>'))\n",
    "    nbdisplay.display_timeline(\n",
    "        data=crn_tl_data, title='Session Timeline', height=300)\n",
    "else:\n",
    "    md(\"No logon sessions during this timeframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw data from user session\n",
    "Use this syslog message data to further investigate suspicous activity during the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T00:04:55.506355Z",
     "start_time": "2020-05-16T00:04:52.200963Z"
    }
   },
   "outputs": [],
   "source": [
    "if logon_sessions_df is not None:\n",
    "    #Return syslog data and present it to the use for investigation\n",
    "    session_syslog = qry_prov.LinuxSyslog.all_syslog(\n",
    "        start=session.StartTimeUtc, end=session.EndTimeUtc, host_name=session.Host)\n",
    "    if session_syslog.empty:\n",
    "        display(HTML(\n",
    "            f' No syslog for {session.Host} between {session.StartTimeUtc} and {session.EndTimeUtc}'))\n",
    "\n",
    "\n",
    "    def view_sudo(selected_cmd):\n",
    "        display(sudo_events.query('CommandCall == @selected_cmd')[\n",
    "                ['TimeGenerated', 'SyslogMessage', 'Sudoer', 'SudoTo', 'Command', 'CommandCall']])\n",
    "\n",
    "    # Show syslog messages associated with selected sudo command\n",
    "    display(HTML(\"<h3>View all messages assocated with a sudo command</h3>\"))\n",
    "    items = sudo_events['CommandCall'].dropna().unique().tolist()\n",
    "    cmd_w = widgets.Dropdown(\n",
    "        options=items, description='Select sudo command facility to examine', disabled=False, **WIDGET_DEFAULTS)\n",
    "    display(widgets.interactive(view_sudo, selected_cmd=cmd_w))\n",
    "else:\n",
    "    md(\"No logon sessions during this timeframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T00:04:56.376353Z",
     "start_time": "2020-05-16T00:04:56.284354Z"
    }
   },
   "outputs": [],
   "source": [
    "if logon_sessions_df is not None:\n",
    "    # Display syslog messages from the session witht he facility selected\n",
    "    items = syslog_events['Facility'].dropna().unique().tolist()\n",
    "    display(HTML(\"<h3>View all messages assocated with a syslog facility</h3>\"))\n",
    "    sess_w = widgets.Dropdown(\n",
    "        options=items, description='Select syslog facility to examine', disabled=False, **WIDGET_DEFAULTS)\n",
    "    display(widgets.interactive(view_syslog, selected_facility=sess_w))\n",
    "else:\n",
    "    md(\"No logon sessions during this timeframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Tree from session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T00:05:06.090478Z",
     "start_time": "2020-05-16T00:04:57.481284Z"
    }
   },
   "outputs": [],
   "source": [
    "if logon_sessions_df is not None:\n",
    "    display(HTML(\"<h3>Process Trees from session</h3>\"))\n",
    "    print(\"Building process tree, this may take some time...\")\n",
    "    # Find the table with auditd data in\n",
    "    regex = '.*audit.*\\_cl?'\n",
    "    matches = ((re.match(regex, key, re.IGNORECASE)) for key in qry_prov.schema)\n",
    "    for match in matches:\n",
    "        if match != None:\n",
    "            audit_table = match.group(0)\n",
    "\n",
    "    # Retrieve auditd data\n",
    "    if audit_table:\n",
    "        audit_data = qry_prov.LinuxAudit.auditd_all(\n",
    "            start=session.StartTimeUtc, end=session.EndTimeUtc, host_name=hostname\n",
    "        )\n",
    "        if isinstance(audit_data, pd.DataFrame) and not audit_data.empty:\n",
    "            audit_events = auditdextract.extract_events_to_df(\n",
    "                data=audit_data\n",
    "            )\n",
    "\n",
    "            process_tree = auditdextract.generate_process_tree(audit_data=audit_events)\n",
    "            process_tree.mp_process_tree.plot()\n",
    "        else:\n",
    "            display(HTML(\"No auditd data avaliable to build process tree\"))\n",
    "    else:\n",
    "        display(HTML(\"No auditd data avaliable to build process tree\"))\n",
    "else:\n",
    "    md(\"No logon sessions during this timeframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click [here](#app) to start a process/application focused hunt or continue with session based hunt below by selecting a sudo session to investigate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sudo Session Investigation\n",
    "Sudo activity is often required by an attacker to conduct actions on target, and more granular data is avalibale for sudo sessions allowing for deeper level hunting within these sesions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T00:05:14.828475Z",
     "start_time": "2020-05-16T00:05:14.794474Z"
    }
   },
   "outputs": [],
   "source": [
    "if logon_sessions_df is not None and sudo_sessions is not None:\n",
    "    sudo_items = sudo_sessions[['User','Start', 'End']].to_string(header=False,\n",
    "                      index=False,\n",
    "                      index_names=False).split('\\n')\n",
    "    sudo_sessions[\"Key\"] = sudo_items\n",
    "    sudo_sessions.set_index('Key', inplace=True)\n",
    "    sudo_dict = sudo_sessions[['User','Start', 'End']].to_dict('index')\n",
    "\n",
    "    sudo_selection = nbwidgets.SelectString(description='Select sudo session to investigate: ',\n",
    "                                                item_dict=sudo_dict, width='100%', height='300px', auto_display=True)\n",
    "else:\n",
    "    sudo_selection = None\n",
    "    md(\"No logon sessions during this timeframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load TILookup class\n",
    "> **Note**: to use TILookup you will need configuration settings in your msticpyconfig.yaml\n",
    "> <br>see [TIProviders documenation](https://msticpy.readthedocs.io/en/latest/TIProviders.html)\n",
    "> <br>and [Configuring Notebook Environment notebook](./ConfiguringNotebookEnvironment.ipynb)\n",
    "> <br>or [ConfiguringNotebookEnvironment (GitHub static view)](https://github.com/Azure/Azure-Sentinel-Notebooks/blob/master/ConfiguringNotebookEnvironment.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tilookup = TILookup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T00:05:25.237213Z",
     "start_time": "2020-05-16T00:05:21.813842Z"
    }
   },
   "outputs": [],
   "source": [
    "#Collect data associated with the sudo session selected\n",
    "from msticpy.sectools.tiproviders.ti_provider_base import TISeverity\n",
    "\n",
    "def ti_check_sev(severity, threshold):\n",
    "    severity = TISeverity.parse(severity)\n",
    "    threshold = TISeverity.parse(threshold)\n",
    "    return severity.value >= threshold.value\n",
    "\n",
    "if sudo_selection:\n",
    "    sudo_sess = {'StartTimeUtc': sudo_selection.value.get('Start'), 'EndTimeUtc': sudo_selection.value.get(\n",
    "        'End'), 'Account': sudo_selection.value.get('User'), 'Host': hostname}\n",
    "    sudo_session = entityschema.HostLogonSession(sudo_sess)\n",
    "    sudo_events = qry_prov.LinuxSyslog.sudo_activity(start=sudo_session.StartTimeUtc.round(\n",
    "        '-1s') - pd.Timedelta(seconds=1), end=(sudo_session.EndTimeUtc.round('1s')+ pd.Timedelta(seconds=1)), host_name=sudo_session.Host)\n",
    "    if isinstance(sudo_events, pd.DataFrame) and not sudo_events.empty:\n",
    "        display(sudo_events.replace('', np.nan).dropna(axis=0, subset=['Command'])[\n",
    "                ['TimeGenerated', 'Command', 'CommandCall', 'SyslogMessage']])\n",
    "        # Extract IOCs from the data\n",
    "        ioc_extractor = iocextract.IoCExtract()\n",
    "        os_family = host_entity.OSType if host_entity.OSType else 'Linux'\n",
    "        print('Extracting IoCs.......')\n",
    "        ioc_df = ioc_extractor.extract(data=sudo_events,\n",
    "                                       columns=['SyslogMessage'],\n",
    "                                       os_family=os_family,\n",
    "                                       ioc_types=['ipv4', 'ipv6', 'dns', 'url',\n",
    "                                                  'md5_hash', 'sha1_hash', 'sha256_hash'])\n",
    "        if len(ioc_df) > 0:\n",
    "            ioc_count = len(\n",
    "                ioc_df[[\"IoCType\", \"Observable\"]].drop_duplicates())\n",
    "            md(f\"Found {ioc_count} IOCs\")\n",
    "            #Lookup the extracted IOCs in TI feed\n",
    "            ti_resps = tilookup.lookup_iocs(data=ioc_df[[\"IoCType\", \"Observable\"]].drop_duplicates(\n",
    "            ).reset_index(), obs_col='Observable', ioc_type_col='IoCType')\n",
    "            i = 0\n",
    "            ti_hits = []\n",
    "            ti_resps.reset_index(drop=True, inplace=True)\n",
    "            while i < len(ti_resps):\n",
    "                if ti_resps['Result'][i] == True and ti_check_sev(ti_resps['Severity'][i], 1):\n",
    "                    ti_hits.append(ti_resps['Ioc'][i])\n",
    "                    i += 1\n",
    "                else:\n",
    "                    i += 1\n",
    "            md(f\"Found {len(ti_hits)} IoCs in Threat Intelligence\")\n",
    "            for ioc in ti_hits:\n",
    "                md(f\"Messages containing IoC found in TI feed: {ioc}\")\n",
    "                display(sudo_events[sudo_events['SyslogMessage'].str.contains(\n",
    "                    ioc)][['TimeGenerated', 'SyslogMessage']])\n",
    "        else:\n",
    "           md(\"No IoC patterns found in Syslog Messages.\")\n",
    "    else:\n",
    "        md('No sudo messages for this session')\n",
    "\n",
    "\n",
    "else:\n",
    "    md(\"No Sudo session to investigate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T23:54:07.485475Z",
     "start_time": "2019-09-23T23:54:07.480507Z"
    }
   },
   "source": [
    "Jump to:\n",
    "- <a>Host Logon Events</a>\n",
    "- <a>Application Activity</a>\n",
    "- <a>Network Activity</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>\n",
    "## User Activity\n",
    "**Hypothesis:** That an attacker has gained  access to the host and is using a user account to conduct actions on the host.\n",
    "\n",
    "This section provides an overview of activity by user within our hunting time frame, the purpose of this is to allow for the identification  of anomalous activity by a user. This hunt can be driven be investigation of suspected users or as a hunt across all users seen on the host."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T00:05:40.283882Z",
     "start_time": "2020-05-16T00:05:38.659404Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get list of users with logon or sudo sessions on host\n",
    "logon_events = qry_prov.LinuxSyslog.user_logon(query_times, host_name=hostname)\n",
    "users = logon_events['User'].replace('', np.nan).dropna().unique().tolist()\n",
    "all_users = list(users)\n",
    "\n",
    "\n",
    "if isinstance(sudo_events, pd.DataFrame) and not sudo_events.empty:\n",
    "    sudoers = sudo_events['Sudoer'].replace(\n",
    "        '', np.nan).dropna().unique().tolist()\n",
    "    all_users.extend(x for x in sudoers if x not in all_users)\n",
    "\n",
    "# Pick Users\n",
    "if not logon_events.empty:\n",
    "    user_select = nbwidgets.SelectString(description='Select user to investigate: ',\n",
    "                                             item_list=all_users, width='75%', auto_display=True)\n",
    "else:\n",
    "    md(\"There was no user activity in the timeframe specified.\")\n",
    "    user_select = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T00:05:43.703387Z",
     "start_time": "2020-05-16T00:05:41.635697Z"
    }
   },
   "outputs": [],
   "source": [
    "folium_user_map = FoliumMap()\n",
    "\n",
    "def view_sudo(cmd):\n",
    "    display(user_sudo_hold.query('CommandCall == @cmd')[\n",
    "            ['TimeGenerated', 'HostName', 'Command', 'CommandCall', 'SyslogMessage']])\n",
    "user_sudo_hold = None\n",
    "if user_select is not None:\n",
    "    # Get all syslog relating to these users\n",
    "    username = user_select.value\n",
    "    user_events = all_syslog[all_syslog['SyslogMessage'].str.contains(username)]\n",
    "    logon_sessions = cluster_syslog_logons_df(logon_events)\n",
    "\n",
    "    # Display all logons associated with the user\n",
    "    display(HTML(f\"<h1> User Logon Activity for {username}</h1>\"))\n",
    "    user_logon_events = logon_events.loc[logon_events['User'] == username]\n",
    "    try:\n",
    "        user_logon_sessions = cluster_syslog_logons_df(user_logon_events)\n",
    "    except:\n",
    "        user_logon_sessions = None\n",
    "    \n",
    "    user_remote_logons = (\n",
    "        user_logon_events[user_logon_events['LogonResult'] == 'Success']\n",
    "    )\n",
    "    user_failed_logons = (\n",
    "        user_logon_events[user_logon_events['LogonResult'] == 'Failure']\n",
    "    )\n",
    "    if not user_remote_logons.empty:\n",
    "        for _, row in logon_sessions_df.iterrows():\n",
    "            end = row['End']\n",
    "        user_sudo_events = qry_prov.LinuxSyslog.sudo_activity(start=user_remote_logons.sort_values(\n",
    "            by='TimeGenerated')['TimeGenerated'].head(1).values[0], end=end, host_name=hostname, user=username)\n",
    "    else: \n",
    "        user_sudo_events = None\n",
    "\n",
    "    if user_logon_sessions is None and user_remote_logons.empty and user_failed_logons.empty:\n",
    "        pass\n",
    "    else:\n",
    "        display(HTML(\n",
    "            f\"{len(user_remote_logons)} sucessfull logons and {len(user_failed_logons)} failed logons for {username}\"))\n",
    "\n",
    "        display(Markdown('### Timeline of host logon attempts.'))\n",
    "        tooltip_cols = ['SyslogMessage']\n",
    "        dfs = {\"User Logons\" :user_remote_logons, \"Failed Logons\": user_failed_logons, \"Sudo Events\" :user_sudo_events}\n",
    "        user_tl_data = {}\n",
    "\n",
    "        for k,v in dfs.items():\n",
    "            if v is not None and not v.empty:\n",
    "                user_tl_data.update({k :{\"data\":v,\"source_columns\":tooltip_cols}})\n",
    "\n",
    "        nbdisplay.display_timeline(\n",
    "            data=user_tl_data, title=\"User logon timeline\", height=300)\n",
    "\n",
    "        palette = viridis(2)\n",
    "        # Graph out failed/sucessful logons by account and by logon process\n",
    "        all_user_df = pd.DataFrame(dict(successful=user_remote_logons['ProcessName'].value_counts(\n",
    "        ), failed=user_failed_logons['ProcessName'].value_counts())).fillna(0).T\n",
    "\n",
    "        user_processes = all_user_df.columns.values.tolist()\n",
    "\n",
    "        fail_sucess_user_data = pd.DataFrame({'processes': user_processes,\n",
    "                                         'sucess': all_user_df.loc['successful'].values.tolist(),\n",
    "                                         'failure': all_user_df.loc['failed'].astype(int).values.tolist()})\n",
    "\n",
    "        user_process_bar = fail_sucess_user_data.plot_bokeh.bar(\n",
    "            x=\"processes\", colormap=palette,  show_figure=False, title=\"Failed and Sucessful logon attempts by process\")\n",
    "        user_logons = pd.DataFrame({\"Sucessful Logons\" : [int(all_user_df.loc['successful'].sum())],\n",
    "                                \"Failed Logons\" : [int(all_user_df.loc['failed'].sum())]}).T\n",
    "\n",
    "        user_ratio_pie =user_logons.plot_bokeh.pie(colormap = palette,\n",
    "                                                show_figure = False, title = \"Relative Frequencies of Sucessful Logons by Account\")\n",
    "\n",
    "        pandas_bokeh.plot_grid([[user_ratio_pie, user_process_bar], \n",
    "                               []], plot_width = 450, plot_height = 300)\n",
    "\n",
    "\n",
    "         # Convert logon IPs to IP entities in order to get location\n",
    "        ip_entity = entityschema.IpAddress()\n",
    "        \n",
    "        user_ip_list = []\n",
    "        for ip_logon in user_remote_logons['SourceIP']:\n",
    "            user_ip_list.extend(convert_to_ip_entities(ip_logon))\n",
    "        user_ip_fail_list = []\n",
    "        for ip_logon in user_failed_logons['SourceIP']:\n",
    "            user_ip_fail_list.extend(convert_to_ip_entities(ip_logon))\n",
    "            \n",
    "        folium_user_map=FoliumMap(location=location, zoom_start=3)\n",
    "        if not user_ip_list and not user_ip_fail_list:\n",
    "            print(\"No user events\")\n",
    "        elif not user_ip_list and user_ip_fail_list:\n",
    "            icon_props={'color': 'red'}\n",
    "            folium_user_map.add_ip_cluster(ip_entities=user_ip_fail_list, **icon_props)\n",
    "        elif not user_ip_fail_list and user_ip_list:\n",
    "            icon_props = {'color': 'green'}\n",
    "            folium_user_map.add_ip_cluster(ip_entities=user_ip_list, **icon_props)\n",
    "        else:\n",
    "            icon_props = {'color': 'red'}\n",
    "            folium_user_map.add_ip_cluster(ip_entities=user_ip_fail_list, **icon_props)\n",
    "            icon_props = {'color': 'green'}\n",
    "            folium_user_map.add_ip_cluster(ip_entities=user_ip_list, **icon_props)\n",
    "\n",
    "        folium_user_map.center_map()\n",
    "        display(HTML('<h3>Map of Originating Location of Logon Attempts</h3>'))\n",
    "        display(folium_user_map)\n",
    "        display(Markdown('<p style=\"color:red\">Warning: the folium mapping library '\n",
    "                         'does not display correctly in some browsers.</p><br>'\n",
    "                         'If you see a blank image please retry with a different browser.'))\n",
    "\n",
    "\n",
    "\n",
    "    #Display sudo activity of the user \n",
    "    if not isinstance(user_sudo_events, pd.DataFrame) or user_sudo_events.empty:\n",
    "        display(HTML(f\"No sucessful sudo activity for {username}\"))\n",
    "    else:\n",
    "        user_sudo_hold = user_sudo_events\n",
    "        user_sudo_commands = (user_sudo_events[['EventTime', 'CommandCall']].replace('', np.nan).groupby(['CommandCall']).count().dropna().style.set_table_attributes('width=900px, text-align=center').background_gradient(cmap='Reds', low=.5, high=1).format(\"{0:0>3.0f}\"))\n",
    "        display(user_sudo_commands)\n",
    "        display(HTML(\"Select a sudo command to investigate in more detail\"))\n",
    "        cmd = widgets.Dropdown(options=user_sudo_events['CommandCall'].replace(\n",
    "                '', np.nan).dropna().unique().tolist(), description='Cmd:', disabled=False)\n",
    "        display(widgets.interactive(view_sudo, cmd=cmd))\n",
    "else:\n",
    "    md(\"No user session selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T00:05:50.586733Z",
     "start_time": "2020-05-16T00:05:50.564733Z"
    }
   },
   "outputs": [],
   "source": [
    "# If the user has sudo activity extract and IOCs from the logs and look them up in TI feeds\n",
    "if user_sudo_hold is not None or user_sudo_hold is not isinstance(user_sudo_hold, pd.DataFrame) or user_sudo_hold.empty:\n",
    "    print(f\"No sudo messages data\")\n",
    "else:\n",
    "    # Extract IOCs\n",
    "    ioc_extractor = iocextract.IoCExtract()\n",
    "    os_family = host_entity.OSType if host_entity.OSType else 'Linux'\n",
    "    print('Extracting IoCs.......')\n",
    "    ioc_df = ioc_extractor.extract(data=user_sudo_hold,\n",
    "                                   columns=['SyslogMessage'],\n",
    "                                   os_family=os_family,\n",
    "                                   ioc_types=['ipv4', 'ipv6', 'dns', 'url', 'md5_hash', 'sha1_hash', 'sha256_hash'])\n",
    "    if len(ioc_df) > 0:\n",
    "        ioc_count = len(ioc_df[[\"IoCType\", \"Observable\"]].drop_duplicates())\n",
    "        display(HTML(f\"Found {ioc_count} IOCs\"))\n",
    "        ti_resps = tilookup.lookup_iocs(data=ioc_df[[\"IoCType\", \"Observable\"]].drop_duplicates(\n",
    "        ).reset_index(), obs_col='Observable', ioc_type_col='IoCType')\n",
    "        i = 0\n",
    "        ti_hits = []\n",
    "        ti_resps.reset_index(drop=True, inplace=True)\n",
    "        while i < len(ti_resps):\n",
    "            if ti_resps['Result'][i] == True and ti_check_sev(ti_resps['Severity'][i], 1):\n",
    "                ti_hits.append(ti_resps['Ioc'][i])\n",
    "                i += 1\n",
    "            else:\n",
    "                i += 1\n",
    "        display(HTML(f\"Found {len(ti_hits)} IoCs in Threat Intelligence\"))\n",
    "        for ioc in ti_hits:\n",
    "            display(HTML(f\"Messages containing IoC found in TI feed: {ioc}\"))\n",
    "            display(user_sudo_hold[user_sudo_hold['SyslogMessage'].str.contains(\n",
    "                ioc)][['TimeGenerated', 'SyslogMessage']])\n",
    "    else:\n",
    "        display(HTML(\"No IoC patterns found in Syslog Message.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jump to:\n",
    "- <a>Host Logon Events</a>\n",
    "- <a>User Activity</a>\n",
    "- <a>Network Activity</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>\n",
    "## Application Activity\n",
    "\n",
    "**Hypothesis:** That an attacker has compromised an application running on the host and is using the applications process to conduct actions on the host.\n",
    "\n",
    "This section provides an overview of activity by application within our hunting time frame, the purpose of this is to allow for the identification of anomalous activity by an application. This hunt can be driven be investigation of suspected applications or as a hunt across all users seen on the host."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T00:05:57.509366Z",
     "start_time": "2020-05-16T00:05:57.455366Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get list of Applications\n",
    "apps = all_syslog['ProcessName'].replace('', np.nan).dropna().unique().tolist()\n",
    "system_apps = ['sudo', 'CRON', 'systemd-resolved', 'snapd',\n",
    "               '50-motd-news', 'systemd-logind', 'dbus-deamon', 'crontab']\n",
    "if len(host_entity.Applications) > 0:\n",
    "    installed_apps = []\n",
    "    installed_apps.extend(x for x in apps if x not in system_apps)\n",
    "\n",
    "    # Pick Applications\n",
    "    app_select = nbwidgets.SelectString(description='Select sudo session to investigate: ',\n",
    "                                            item_list=installed_apps, width='75%', auto_display=True)\n",
    "else:\n",
    "    display(HTML(\"No applications other than stand OS applications present\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T00:06:05.972032Z",
     "start_time": "2020-05-16T00:06:05.838032Z"
    }
   },
   "outputs": [],
   "source": [
    "from bokeh.models import ColumnDataSource, RangeTool\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.layouts import column\n",
    "output_notebook()\n",
    "# Get all syslog relating to these Applications\n",
    "app = app_select.value\n",
    "app_data = all_syslog.loc[all_syslog['ProcessName'] == app]\n",
    "\n",
    "# App log volume over time\n",
    "if isinstance(app_data, pd.DataFrame) and not app_data.empty:\n",
    "    app_data_volume = app_data.set_index(\n",
    "        \"TimeGenerated\").resample('5T').count()\n",
    "    source = ColumnDataSource(\n",
    "        data=dict(date=app_data_volume.index, count=app_data_volume['SyslogMessage']))\n",
    "    p = figure(plot_height=300, plot_width=900, tools=\"xpan\", toolbar_location=None,\n",
    "               x_axis_type=\"datetime\", x_axis_location=\"above\", y_minor_ticks=2,\n",
    "               title=\"Application syslog volume over time\",\n",
    "               background_fill_color=\"#efefef\", x_range=(app_data_volume.index[int(len(app_data_volume.index)*.33)], app_data_volume.index[int(len(app_data_volume.index)*.66)]))\n",
    "    p.line('date', 'count', source=source)\n",
    "    p.yaxis.axis_label = 'Message volume'\n",
    "    select = figure(title=\"Drag the middle and edges of the selection box to change the range above\",\n",
    "                    plot_height=130, plot_width=900, y_range=p.y_range,\n",
    "                    x_axis_type=\"datetime\", y_axis_type=None,\n",
    "                    tools=\"\", toolbar_location=None, background_fill_color=\"#efefef\")\n",
    "    range_tool = RangeTool(x_range=p.x_range)\n",
    "    range_tool.overlay.fill_color = \"navy\"\n",
    "    range_tool.overlay.fill_alpha = 0.2\n",
    "    select.line('date', 'count', source=source)\n",
    "    select.ygrid.grid_line_color = None\n",
    "    select.add_tools(range_tool)\n",
    "    select.toolbar.active_multi = range_tool\n",
    "    show(column(p, select))\n",
    "    app_high_sev = app_data[app_data['SeverityLevel'].isin(\n",
    "        ['emerg', 'alert', 'crit', 'err', 'warning'])]\n",
    "    if app_high_sev.empty:\n",
    "        print(f\"No high severity syslog messages for {app}\")\n",
    "    else:\n",
    "        app_high_sev = app_high_sev.set_index(\n",
    "            \"TimeGenerated\").resample('5T').count()\n",
    "        hs_source = ColumnDataSource(\n",
    "            data=dict(date=app_high_sev.index, count=app_high_sev['SyslogMessage']))\n",
    "        hs_p = figure(plot_height=300, plot_width=900, tools=\"xpan\", toolbar_location=None,\n",
    "                      x_axis_type=\"datetime\", x_axis_location=\"above\", y_minor_ticks=2,\n",
    "                      title=\"High Severity application syslog volume over time\",\n",
    "                      background_fill_color=\"#FCF1CB\", x_range=(app_high_sev.index[int(len(app_high_sev.index)*.33)], app_high_sev.index[int(len(app_high_sev.index)*.66)]), y_range=(0, app_data_volume['SyslogMessage'].max()))\n",
    "        hs_p.line('date', 'count', source=hs_source, line_color='red')\n",
    "        hs_p.yaxis.axis_label = 'Message volume'\n",
    "        hs_select = figure(title=\"Drag the middle and edges of the selection box to change the range above\",\n",
    "                           plot_height=130, plot_width=900, y_range=hs_p.y_range,\n",
    "                           x_axis_type=\"datetime\", y_axis_type=None,\n",
    "                           tools=\"\", toolbar_location=None, background_fill_color=\"#FCF1CB\")\n",
    "        hs_range_tool = RangeTool(x_range=hs_p.x_range)\n",
    "        hs_range_tool.overlay.fill_color = \"orange\"\n",
    "        hs_range_tool.overlay.fill_alpha = 0.2\n",
    "        hs_select.line('date', 'count', source=hs_source, line_color='red')\n",
    "        hs_select.ygrid.grid_line_color = None\n",
    "        hs_select.add_tools(hs_range_tool)\n",
    "        hs_select.toolbar.active_multi = hs_range_tool\n",
    "        show(column(hs_p, hs_select))\n",
    "else:\n",
    "    display(HTML(\"No data for this application\"))\n",
    "# Check for mallicious stuff\n",
    "risky_messages = risky_cmd_line(events=app_data, log_type=\"Syslog\", cmd_field=\"SyslogMessage\")\n",
    "if not risky_messages:\n",
    "    pass\n",
    "else:\n",
    "    print(risky_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display process tree\n",
    "Due to the large volume of data involved you may wish to make you query window smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T00:06:27.934589Z",
     "start_time": "2020-05-16T00:06:27.885591Z"
    }
   },
   "outputs": [],
   "source": [
    "if rel_alert_select is None or rel_alert_select.selected_alert is None:\n",
    "    start = query_times.start\n",
    "else:\n",
    "    start = rel_alert_select.selected_alert['TimeGenerated']\n",
    "\n",
    "# Set new investigation time windows based on the selected alert\n",
    "proc_invest_times = nbwidgets.QueryTime(units='hours',\n",
    "                                       max_before=6, max_after=3, before=2, origin_time=start)\n",
    "proc_invest_times.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T00:07:32.371549Z",
     "start_time": "2020-05-16T00:06:33.042022Z"
    }
   },
   "outputs": [],
   "source": [
    "audit_table = None\n",
    "app_audit_data = None\n",
    "app = app_select.value\n",
    "regex = '.*audit.*\\_cl?'\n",
    "# Find the table with auditd data in and collect the data\n",
    "matches = ((re.match(regex, key, re.IGNORECASE)) for key in qry_prov.schema)\n",
    "for match in matches:\n",
    "    if match != None:\n",
    "        audit_table = match.group(0)\n",
    "\n",
    "#Check if the amount of data expected to be returned is a reasonable size, if not prompt before continuing\n",
    "if audit_table != None:\n",
    "    if isinstance(app_audit_data, pd.DataFrame):\n",
    "        pass\n",
    "    else:\n",
    "        print('Collecting audit data, please wait this may take some time....')\n",
    "        app_audit_query_count = f\"\"\"{audit_table} \n",
    "                    | where TimeGenerated >= datetime({proc_invest_times.start}) \n",
    "                    | where TimeGenerated <= datetime({proc_invest_times.end}) \n",
    "                    | where Computer == '{hostname}'\n",
    "                    | summarize count()\n",
    "                   \"\"\"\n",
    "        \n",
    "        count_check = qry_prov.exec_query(query=app_audit_query_count)\n",
    "\n",
    "        if count_check['count_'].iloc[0] > 100000 and not count_check.empty:\n",
    "            size = count_check['count_'].iloc[0]\n",
    "            print(\n",
    "                f\"You are returning a very large dataset ({size} rows).\",\n",
    "                \"It is reccomended that you consider scoping the size\\n\",\n",
    "                \"of your query down.\\n\",\n",
    "                \"Are you sure you want to proceed?\"\n",
    "            )\n",
    "            response = (input(\"Y/N\") or \"N\")\n",
    "        \n",
    "#         app_audit_query = f\"\"\"{audit_table} \n",
    "#                     | where TimeGenerated >= datetime({proc_invest_times.start}) \n",
    "#                     | where TimeGenerated <= datetime({proc_invest_times.end}) \n",
    "#                     | where Computer == '{hostname}'\n",
    "#                     | where RawData contains \"sshd\"\n",
    "#                     \"\"\"\n",
    "        if (\n",
    "            (count_check['count_'].iloc[0] < 100000)\n",
    "            or (count_check['count_'].iloc[0] > 100000\n",
    "                and response.casefold().startswith(\"y\"))\n",
    "        ):\n",
    "            print(\"querying audit data...\")\n",
    "            audit_data = qry_prov.LinuxAudit.auditd_all(\n",
    "                start=proc_invest_times.start, end=proc_invest_times.end, host_name=hostname\n",
    "                )\n",
    "            if isinstance(audit_data, pd.DataFrame) and not audit_data.empty:\n",
    "                print(\"building process tree...\")\n",
    "                audit_events = auditdextract.extract_events_to_df(\n",
    "                    data=audit_data\n",
    "                )\n",
    "                \n",
    "                process_tree = auditdextract.generate_process_tree(audit_data=audit_events)\n",
    "                plot_lim = 1000\n",
    "                if len(process_tree) > plot_lim:\n",
    "                    md_warn(f\"More than {plot_lim} processes to plot, limiting to top {plot_lim}.\")\n",
    "                    process_tree[:plot_lim].mp_process_tree.plot(legend_col=\"exe\")\n",
    "                else:\n",
    "                    process_tree.mp_process_tree.plot(legend_col=\"exe\")\n",
    "                size = audit_events.size\n",
    "                print(f\"Collected {size} rows of data\")\n",
    "        else:\n",
    "            print(\"Resize query window\")\n",
    "    \n",
    "else:\n",
    "    display(HTML(\"No audit events avalaible\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T00:07:41.084063Z",
     "start_time": "2020-05-16T00:07:40.662062Z"
    }
   },
   "outputs": [],
   "source": [
    "display(HTML(f\"<h3>Process tree for {app}</h3>\"))\n",
    "#Generate process tree with auditd data around the selected process\n",
    "# from msticpy.sectools import auditdextract\n",
    "# if isinstance(audit_events, pd.DataFrame) and not audit_events.empty:\n",
    "#     audit_events = auditdextract.extract_events_to_df(\n",
    "#             data=app_audit_data, input_column='RawData')\n",
    "#     if not audit_events[audit_events[\"exe\"].str.contains(app, na=False)].empty:\n",
    "#         procs = auditdextract.cluster_auditd_processes(audit_data=audit_events, app=app)\n",
    "#         display(Markdown(f'{len(procs)} process events'))\n",
    "#         process_tree = auditdextract.generate_process_tree(audit_data = audit_events, processes = procs)\n",
    "#         nbdisplay.display_process_tree(process_tree)\n",
    "\n",
    "#     else:\n",
    "#         display(f\"No process tree data avaliable for {app}\")\n",
    "#         process_tree = None\n",
    "if not process_tree[process_tree[\"exe\"].str.contains(app, na=False)].empty:    \n",
    "    app_roots = process_tree[process_tree[\"exe\"].str.contains(app)].apply(lambda x: ptree.get_root(process_tree, x), axis=1)\n",
    "    trees = []\n",
    "    for root in app_roots[\"source_index\"].unique():\n",
    "        trees.append(process_tree[process_tree[\"path\"].str.startswith(root)])\n",
    "    app_proc_trees = pd.concat(trees)\n",
    "    app_proc_trees.mp_process_tree.plot(legend_col=\"exe\", show_table=True)\n",
    "else:\n",
    "    display(f\"No process tree data avaliable for {app}\")\n",
    "    process_tree = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application Logs with associated Threat Intelligence\n",
    "These logs are associated with the process being investigated and include IOCs that appear in our TI feeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T00:08:25.051755Z",
     "start_time": "2020-05-16T00:08:03.604431Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract IOCs from syslog assocated with the selected process\n",
    "ioc_extractor = iocextract.IoCExtract()\n",
    "os_family = host_entity.OSType if host_entity.OSType else 'Linux'\n",
    "md('Extracting IoCs...')\n",
    "ioc_df = ioc_extractor.extract(data=app_data,\n",
    "                               columns=['SyslogMessage'],\n",
    "                               os_family=os_family,\n",
    "                               ioc_types=['ipv4', 'ipv6', 'dns', 'url',\n",
    "                                          'md5_hash', 'sha1_hash', 'sha256_hash'])\n",
    "\n",
    "if process_tree is not None and not process_tree.empty:\n",
    "    app_process_tree = app_proc_trees.dropna(subset=['cmdline'])\n",
    "    audit_ioc_df = ioc_extractor.extract(data=app_process_tree,\n",
    "                                         columns=['cmdline'],\n",
    "                                         os_family=os_family,\n",
    "                                         ioc_types=['ipv4', 'ipv6', 'dns', 'url',\n",
    "                                                    'md5_hash', 'sha1_hash', 'sha256_hash'])\n",
    "\n",
    "    ioc_df = ioc_df.append(audit_ioc_df)\n",
    "# Look up IOCs in TI feeds\n",
    "if len(ioc_df) > 0:\n",
    "    ioc_count = len(ioc_df[[\"IoCType\", \"Observable\"]].drop_duplicates())\n",
    "    md(f\"Found {ioc_count} IOCs\")\n",
    "    md(\"Looking up threat intel...\")\n",
    "    ti_resps = tilookup.lookup_iocs(data=ioc_df[[\n",
    "                                     \"IoCType\", \"Observable\"]].drop_duplicates().reset_index(drop=True), obs_col='Observable')\n",
    "    i = 0\n",
    "    ti_hits = []\n",
    "    ti_resps.reset_index(drop=True, inplace=True)\n",
    "    while i < len(ti_resps):\n",
    "        if ti_resps['Result'][i] == True and ti_check_sev(ti_resps['Severity'][i], 1):\n",
    "            ti_hits.append(ti_resps['Ioc'][i])\n",
    "            i += 1\n",
    "        else:\n",
    "            i += 1\n",
    "    display(HTML(f\"Found {len(ti_hits)} IoCs in Threat Intelligence\"))\n",
    "    for ioc in ti_hits:\n",
    "        display(HTML(f\"Messages containing IoC found in TI feed: {ioc}\"))\n",
    "        display(app_data[app_data['SyslogMessage'].str.contains(\n",
    "            ioc)][['TimeGenerated', 'SyslogMessage']])\n",
    "else:\n",
    "    display(Markdown(\"### No IoC patterns found in Syslog Message.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T23:55:34.409792Z",
     "start_time": "2019-09-23T23:55:34.404795Z"
    }
   },
   "source": [
    "Jump to:\n",
    "- <a>Host Logon Events</a>\n",
    "- <a>User Activity</a>\n",
    "- <a>Application Activity</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Activity\n",
    "**Hypothesis:** That an attacker is remotely communicating with the host in order to compromise the host or for C2 or data exfiltration purposes after compromising the host.\n",
    "\n",
    "This section provides an overview of network activity to and from the host during hunting time frame, the purpose of this is to allow for the identification of anomalous network traffic. If you wish to investigate a specific IP in detail it is recommended that you use the IP Explorer Notebook (include link)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T00:08:58.079873Z",
     "start_time": "2020-05-16T00:08:41.302405Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get list of IPs from Syslog and Azure Network Data\n",
    "ioc_extractor = iocextract.IoCExtract()\n",
    "os_family = host_entity.OSType if host_entity.OSType else 'Linux'\n",
    "print('Finding IP Addresses this may take a few minutes.......')\n",
    "syslog_ips = ioc_extractor.extract(data=syslog_data,\n",
    "                                   columns=['SyslogMessage'],\n",
    "                                   os_family=os_family,\n",
    "                                   ioc_types=['ipv4', 'ipv6'])\n",
    "\n",
    "\n",
    "if 'AzureNetworkAnalytics_CL' not in qry_prov.schema:\n",
    "    az_net_comms_df = None\n",
    "    az_ips = None\n",
    "else:\n",
    "    if hasattr(host_entity, 'private_ips') and hasattr(host_entity, 'public_ips'):\n",
    "        all_host_ips = host_entity.private_ips + \\\n",
    "            host_entity.public_ips + [host_entity.IPAddress]\n",
    "    else:\n",
    "        all_host_ips = [host_entity.IPAddress]\n",
    "    host_ips = {'\\'{}\\''.format(i.Address) for i in all_host_ips}\n",
    "    host_ip_list = ','.join(host_ips)\n",
    "\n",
    "    az_ip_where = f\"\"\"| where (VMIPAddress in (\"{host_ip_list}\") or SrcIP in (\"{host_ip_list}\") or DestIP in (\"{host_ip_list}\")) and (AllowedOutFlows > 0 or AllowedInFlows > 0)\"\"\"\n",
    "    az_net_comms_df = qry_prov.AzureNetwork.az_net_analytics(\n",
    "        start=query_times.start, end=query_times.end, host_name=hostname, where_clause=az_ip_where)\n",
    "    if isinstance(az_net_comms_df, pd.DataFrame) and not az_net_comms_df.empty:\n",
    "        az_ips = az_net_comms_df.query(\"PublicIPs != @host_entity.IPAddress\")\n",
    "    else:\n",
    "        az_ips = None\n",
    "if len(syslog_ips):\n",
    "    IPs = syslog_ips[['IoCType', 'Observable']].drop_duplicates('Observable')\n",
    "    display(f\"Found {len(IPs)} IP Addresses assoicated with the host\")\n",
    "else:\n",
    "    display(Markdown(\"### No IoC patterns found in Syslog Message.\"))\n",
    "    \n",
    "if az_ips is not None:\n",
    "    ips = az_ips['PublicIps'].drop_duplicates(\n",
    "    ) + syslog_ips['Observable'].drop_duplicates()\n",
    "else:\n",
    "    ips = syslog_ips['Observable'].drop_duplicates()\n",
    "\n",
    "if isinstance(az_net_comms_df, pd.DataFrame) and not az_net_comms_df.empty:\n",
    "    import warnings\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "\n",
    "        az_net_comms_df['TotalAllowedFlows'] = az_net_comms_df['AllowedOutFlows'] + \\\n",
    "            az_net_comms_df['AllowedInFlows']\n",
    "        sns.catplot(x=\"L7Protocol\", y=\"TotalAllowedFlows\",\n",
    "                    col=\"FlowDirection\", data=az_net_comms_df)\n",
    "        sns.relplot(x=\"FlowStartTime\", y=\"TotalAllowedFlows\",\n",
    "                    col=\"FlowDirection\", kind=\"line\",\n",
    "                    hue=\"L7Protocol\", data=az_net_comms_df).set_xticklabels(rotation=50)\n",
    "\n",
    "    nbdisplay.display_timeline(data=az_net_comms_df.query('AllowedOutFlows > 0'),\n",
    "                               overlay_data=az_net_comms_df.query(\n",
    "                                   'AllowedInFlows > 0'),\n",
    "                               title='Network Flows (out=blue, in=green)',\n",
    "                               time_column='FlowStartTime',\n",
    "                               source_columns=[\n",
    "                                   'FlowType', 'AllExtIPs', 'L7Protocol', 'FlowDirection'],\n",
    "                               height=300)\n",
    "else:\n",
    "    print('No Azure network data for specified time range.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose ASNs/IPs to Check for Threat Intel Reports\n",
    "Choose from the list of Selected ASNs for the IPs you wish to check on. Then select the IP(s) that you wish to check against Threat Intelligence data.\n",
    "The Source list is populated with all ASNs found in the syslog and network flow data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T00:09:14.771199Z",
     "start_time": "2020-05-16T00:09:04.783620Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from functools import lru_cache\n",
    "from ipwhois import IPWhois\n",
    "from ipaddress import ip_address\n",
    "\n",
    "#Lookup each IP in whois data and extract the ASN\n",
    "@lru_cache(maxsize=1024)\n",
    "def whois_desc(ip_lookup, progress=False):\n",
    "    try:\n",
    "        ip = ip_address(ip_lookup)\n",
    "    except ValueError:\n",
    "        return \"Not an IP Address\"\n",
    "    if ip.is_private:\n",
    "        return \"private address\"\n",
    "    if not ip.is_global:\n",
    "        return \"other address\"\n",
    "    whois = IPWhois(ip)\n",
    "    whois_result = whois.lookup_whois()\n",
    "    if progress:\n",
    "        print(\".\", end=\"\")\n",
    "    return whois_result[\"asn_description\"]\n",
    "\n",
    "# Summarise network data by ASN\n",
    "ASN_List = []\n",
    "print(\"WhoIs Lookups\")\n",
    "ASNs = ips.apply(lambda x: whois_desc(x, True))\n",
    "IP_ASN = pd.DataFrame(dict(IPs=ips, ASN=ASNs)).reset_index()\n",
    "x = IP_ASN.groupby([\"ASN\"]).count().drop(\n",
    "    'index', axis=1).sort_values('IPs', ascending=False)\n",
    "display(x)\n",
    "ASN_List = x.index\n",
    "\n",
    "# Select an ASN to investigate in more detail\n",
    "selection = widgets.SelectMultiple(\n",
    "    options=ASN_List,\n",
    "    width=900,\n",
    "    description='Select ASN to investigate',\n",
    "    disabled=False\n",
    ")\n",
    "selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T00:09:26.062183Z",
     "start_time": "2020-05-16T00:09:26.045183Z"
    }
   },
   "outputs": [],
   "source": [
    "# For every IP associated with the selected ASN look them up in TI feeds\n",
    "ip_invest_list = None\n",
    "for ASN in selection.value:\n",
    "    if ip_invest_list is None:\n",
    "        ip_invest_list = (IP_ASN[IP_ASN[\"ASN\"] == ASN]['IPs'].tolist())\n",
    "    else:\n",
    "        ip_invest_list + (IP_ASN[IP_ASN[\"ASN\"] == ASN]['IPs'].tolist())\n",
    "\n",
    "if ip_invest_list is not None:\n",
    "    ioc_ip_list = []\n",
    "    if len(ip_invest_list) > 0:\n",
    "        ti_resps = tilookup.lookup_iocs(data=ip_invest_list, providers=[\"OTX\"])\n",
    "        i = 0\n",
    "        ti_hits = []\n",
    "        while i < len(ti_resps):\n",
    "            if ti_resps['Details'][i]['pulse_count'] > 0:\n",
    "                ti_hits.append(ti_resps['IoC'][i])\n",
    "                i += 1\n",
    "            else:\n",
    "                i += 1\n",
    "        display(HTML(f\"Found {len(ti_hits)} IoCs in Threat Intelligence\"))\n",
    "        for ioc in ti_hits:\n",
    "            ioc_ip_list.append(ioc)\n",
    "\n",
    "    #Show IPs found in TI feeds for further investigation        \n",
    "    if len(ioc_ip_list) > 0: \n",
    "        display(HTML(\"Select an IP whcih appeared in TI to investigate further\"))\n",
    "        ip_selection = nbwidgets.SelectString(description='Select IP Address to investigate: ', item_list = ioc_ip_list, width='95%', auto_display=True)\n",
    "    else: \n",
    "        ip_selection = None\n",
    "else:\n",
    "    md(\"No IPs to investigate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T00:09:28.758531Z",
     "start_time": "2020-05-16T00:09:28.740532Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get all syslog for the IPs\n",
    "if ip_selection is not None:\n",
    "    display(HTML(\"Syslog data associated with this IP Address\"))\n",
    "    sys_hits = all_syslog[all_syslog['SyslogMessage'].str.contains(\n",
    "        ip_selection.value)]\n",
    "    display(sys_hits)\n",
    "    os_family = host_entity.OSType if host_entity.OSType else 'Linux'\n",
    "\n",
    "    display(HTML(\"TI result for this IP Address\"))\n",
    "    display(ti_resps[ti_resps['IoC'] == ip_selection.value])\n",
    "else:\n",
    "    md(\"No IP address selected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "### `msticpyconfig.yaml` configuration File\n",
    "You can configure primary and secondary TI providers and any required parameters in the `msticpyconfig.yaml` file. This is read from the current directory or you can set an environment variable (`MSTICPYCONFIG`) pointing to its location.\n",
    "\n",
    "To configure this file see the [ConfigureNotebookEnvironment notebook](https://github.com/Azure/Azure-Sentinel-Notebooks/blob/master/ConfiguringNotebookEnvironment.ipynb)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "683px",
    "width": "424px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "374.667px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
