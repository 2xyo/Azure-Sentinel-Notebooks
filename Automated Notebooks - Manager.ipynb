{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import nbformat\n",
    "from azure.mgmt.resource import ResourceManagementClient\n",
    "from azure.storage.fileshare import ShareFileClient, ShareServiceClient\n",
    "from azure.storage.queue import QueueServiceClient\n",
    "\n",
    "import papermill as pm\n",
    "from msticpy.common.azure_auth import az_connect\n",
    "from msticpy.common.keyvault_client import BHKeyVaultClient\n",
    "from msticpy.data.azure_sentinel import AzureSentinel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a log file that tracks notebook executions\n",
    "log_file = open(\"notebook_execution.log\", \"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate with details relating to your environment\n",
    "# Tenant ID\n",
    "ten_id = \"YOUR TENANT ID\"\n",
    "# The name of the Key Vault containing AFS key\n",
    "vault_name = \"YOUR KV NAME\"\n",
    "# The secret name that the AFS key is stored in\n",
    "kv_sec_name = \"YOUR SECRET NAME\"\n",
    "# Subscription ID of the Azure Sentinel Workspace to get incidents from\n",
    "subscriptionId = \"YOUR SUBSCRIPTION ID\"\n",
    "# The name of the Resource Group of the Azure Sentinel Workspace to get incidents from\n",
    "resourceGroupName = \"YOUR RG NAME\"\n",
    "# The name of the Azure Sentinel Workspace to get incidents from\n",
    "workspaceName = \"YOUR WORKSPACE NAME\"\n",
    "# The name of the Azure Sentinel Workspace ID to get incidents from\n",
    "ws_id = \"YOUR WORKSPACE ID\"\n",
    "# The name of the Azure Storage Queue account used (if used)\n",
    "q_account = \"YOUR QUEUE ACCOUNT\"\n",
    "# The name of the Azure Storage Queue account used (if used)\n",
    "q_name = \"YOUR QUEUE NAME\"\n",
    "# Details of the Azure Machine Learning workspace to be used (sub_id = Subscription ID, RG = Resource Group name, AMLWorkspace = AML Workspace Name)\n",
    "AML_details = {\n",
    "    \"sub_id\": \"YOUR SUB ID\",\n",
    "    \"RG\": \"YOUR RG NAME\",\n",
    "    \"AMLWorkspace\": \"YOUR WORKSPACE NAME\",\n",
    "    \"ten_id\": ten_id,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate to Azure using Azure CLI or Managed Identity\n",
    "creds = az_connect([\"cli\", \"msi\"])\n",
    "token = creds.modern.get_token(\"https://management.azure.com/.default\")\n",
    "\n",
    "\n",
    "def get_api_headers():\n",
    "    token = creds.modern.get_token(\"https://management.azure.com/.default\")\n",
    "    \"\"\"Return authorization header with current token.\"\"\"\n",
    "    return {\n",
    "        \"Authorization\": f\"Bearer {token.token}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "\n",
    "\n",
    "# Access key vault and get Azure Storage access key\n",
    "kv_c = BHKeyVaultClient(tenant_id=ten_id, vault_name=vault_name)\n",
    "afs_cred = kv_c.get_secret(kv_sec_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Azure Sentinel\n",
    "azs = AzureSentinel()\n",
    "azs.connect()\n",
    "log_file.write(\"Successfully connected to Azure Sentinel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get recent Incidents from API\n",
    "incidents = azs.get_incidents(\n",
    "    sub_id=subscriptionId, res_grp=resourceGroupName, ws_name=workspaceName\n",
    ")\n",
    "incident_ids = incidents[\"name\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using Queue method get incidents from queue - uncomment following cells to use this method\n",
    "# queue_service_client = QueueServiceClient(\n",
    "# account_url=q_account, credential=creds.modern, api_version=\"2019-07-07\"\n",
    "# )\n",
    "# q_client = queue_service_client.get_queue_client(q_name)\n",
    "# messages = q_client.receive_messages()\n",
    "# incident_ids = [message[\"content\"] for message in messages]\n",
    "# q_client.clear_messages()\n",
    "# incident_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a local archive to avoid processing of incidents more than once.\n",
    "try:\n",
    "    with open(\"incident_archive\", \"r\") as input_file:\n",
    "        incident_archive = input_file.read().splitlines()\n",
    "except FileNotFoundError:\n",
    "    incident_archive = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incident_file = open(\"incident_archive\", \"w\")\n",
    "out_files = []\n",
    "\n",
    "# For each incident, if it has not already been processed then run the incident triage notebook with that ID\n",
    "if incident_ids:\n",
    "    for incident_id in incident_ids:\n",
    "        if incident_id not in incident_archive:\n",
    "            log_file.write(f\"{datetime.now()} - Processing incident {incident_id}\\n\")\n",
    "            print(f\"Running notebook for {incident_id}\")\n",
    "            out_path = Path.cwd().joinpath(f\"out/{incident_id}.ipynb\")\n",
    "            # If execution error occurs continue but record this in the log\n",
    "            try:\n",
    "                pm.execute_notebook(\n",
    "                    \"AutoIncidentTriage.ipynb\",\n",
    "                    str(out_path),\n",
    "                    parameters={\n",
    "                        \"incident_id\": incident_id,\n",
    "                        \"ten_id\": ten_id,\n",
    "                        \"ws_id\": ws_id,\n",
    "                    },\n",
    "                    kernel=\"papermill\",\n",
    "                )\n",
    "                out_files.append(out_path)\n",
    "            except pm.PapermillExecutionError:\n",
    "                log_file.write(\n",
    "                    f\"{datetime.now()} - Unable to process incident {incident_id} - skipping \\n\"\n",
    "                )\n",
    "            # Once processed add incident to archive\n",
    "            incident_file.write(incident_id + \"\\n\")\n",
    "        else:\n",
    "            log_file.write(\n",
    "                f\"{datetime.now()} - Incident {incident_id} has already been processed - skipping \\n\"\n",
    "            )\n",
    "\n",
    "incident_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to move a notebook from local path to Azure File Storage\n",
    "def move_to_afs(path, incident_id):\n",
    "    with open(path) as notebook:\n",
    "        notebook = notebook.read()\n",
    "        account = get_storage_acct()\n",
    "        notebook_name = path.name\n",
    "        share_name = get_share(account)\n",
    "        file_client = ShareFileClient(\n",
    "            account_url=f\"{account}.file.core.windows.net\",\n",
    "            share_name=share_name,\n",
    "            file_path=f\"Users/pebryan/{notebook_name}\",\n",
    "            credential=afs_cred,\n",
    "        )\n",
    "        file_client.upload_file(notebook)\n",
    "        path = f\"https://ml.azure.com/fileexplorerAzNB?wsid=/subscriptions/{AML_details['sub_id']}/resourcegroups/{AML_details['RG']}/workspaces/AzureMLWorkspace&tid={AML_details['ten_id']}&activeFilePath=Users/pebryan/{notebook_name}\"\n",
    "        write_to_incident(incident_id, path)\n",
    "        update_incident(incident_id)\n",
    "\n",
    "\n",
    "# Function to find the Azure Storage Account used by Azure ML\n",
    "def get_storage_acct():\n",
    "    res_client = ResourceManagementClient(creds.legacy, AML_details[\"sub_id\"])\n",
    "    res = res_client.resources.get(\n",
    "        AML_details[\"RG\"],\n",
    "        \"\",\n",
    "        \"Microsoft.MachineLearningServices/workspaces\",\n",
    "        \"\",\n",
    "        AML_details[\"AMLWorkspace\"],\n",
    "        \"2021-01-01\",\n",
    "    )\n",
    "    account = res.properties[\"storageAccount\"].split(\"/\")[-1]\n",
    "    return account\n",
    "\n",
    "\n",
    "# Function to get the correct file share to store notebook in\n",
    "def get_share(account):\n",
    "    ssc = ShareServiceClient(f\"{account}.file.core.windows.net\", afs_cred)\n",
    "    for share in list(ssc.list_shares()):\n",
    "        if share[\"name\"].startswith(\"code-\"):\n",
    "            return share[\"name\"]\n",
    "\n",
    "\n",
    "# Function to write a comment to the Azure Sentinel Incident that contains a link to the notebook\n",
    "def write_to_incident(incidentId, path):\n",
    "    html = f\"<a href='{path}'>View incident triage notebook in AML</a>\"\n",
    "    log_file.write(\n",
    "        f\"{datetime.now()} - Adding link to notebook for incident: {incidentId} \\n\"\n",
    "    )\n",
    "    azs.post_comment(\n",
    "        incident_id=incidentId,\n",
    "        comment=html,\n",
    "        sub_id=subscriptionId,\n",
    "        res_grp=resourceGroupName,\n",
    "        ws_name=workspaceName,\n",
    "    )\n",
    "\n",
    "\n",
    "# Function to update incident severity to High if triage determines a risk\n",
    "def update_incident(incidentId):\n",
    "    log_file.write(f\"{datetime.now()} - Updating severity for {incidentId} \\n\")\n",
    "    azs.update_incident(\n",
    "        incident_id=incidentId,\n",
    "        update_items={\"severity\": \"High\", \"status\": \"New\"},\n",
    "        sub_id=subscriptionId,\n",
    "        res_grp=resourceGroupName,\n",
    "        ws_name=workspaceName,\n",
    "    )\n",
    "\n",
    "\n",
    "# For each processed incident check if there was valuable output in the notebook and process it\n",
    "if out_files:\n",
    "    print(\"Uploading notebooks...\")\n",
    "    for path in out_files:\n",
    "        incident_id = str(path.name).split(\".\")[0]\n",
    "        try:\n",
    "            nb = nbformat.read(path, as_version=2)\n",
    "            for cell in nb[\"worksheets\"][0][\"cells\"]:\n",
    "                if \"output\" in cell[\"metadata\"][\"tags\"] and cell[\"outputs\"]:\n",
    "                    log_file.write(\n",
    "                        f\"{datetime.now()} - Storing notebook for {incident_id} in AML \\n\"\n",
    "                    )\n",
    "                    move_to_afs(path, incident_id)\n",
    "                    break\n",
    "            os.remove(str(path))\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "    print(\"Uploads complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "papermill",
   "language": "python",
   "name": "papermill"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
